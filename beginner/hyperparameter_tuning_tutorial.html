
<!DOCTYPE html>

<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Hyperparameter tuning with Ray Tune — PyTorch Tutorials 1.7.1 documentation</title>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="../_static/gallery.css" rel="stylesheet" type="text/css"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="../intermediate/pruning_tutorial.html" rel="next" title="Pruning Tutorial"/>
<link href="profiler.html" rel="prev" title="Profiling your PyTorch Module"/>
<script src="../_static/js/modernizr.min.js"></script>
<!-- Preload the theme fonts -->
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-book.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" rel="preload" type="font/woff2"/>
<!-- Preload the katex fonts -->
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" rel="preload" type="font/woff2"/>
<link crossorigin="anonymous" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" rel="stylesheet"/>
</head>
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="container">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/ecosystem">Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/mobile">Mobile</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="resource-option with-down-orange-arrow">
                Docs
              </a>
<div class="resources-dropdown-menu">
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
<span class="dropdown-title">PyTorch</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
<span class="dropdown-title">torchaudio</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
<span class="dropdown-title">torchtext</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
<span class="dropdown-title">torchvision</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/elastic/">
<span class="dropdown-title">TorchElastic</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
<span class="dropdown-title">TorchServe</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
<span class="dropdown-title">PyTorch on XLA Devices</span>
<p></p>
</a>
</div>
</div></li>
<li>
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="resource-option with-down-arrow">
                Resources
              </a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/features">
<span class="dropdown-title">About</span>
<p>Learn about PyTorch’s features and capabilities</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
<span class="dropdown-title">Community</span>
<p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/resources">
<span class="dropdown-title">Developer Resources</span>
<p>Find resources and get questions answered</p>
</a>
<a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
<span class="dropdown-title">Forums</span>
<p>A place to discuss PyTorch code, issues, install, research</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/hub">
<span class="dropdown-title">Models (Beta)</span>
<p>Discover, publish, and reuse pre-trained models</p>
</a>
</div>
</div>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#"></a>
</div>
</div>
</div>
<body class="pytorch-body">
<div class="table-of-contents-link-wrapper">
<span>Table of Contents</span>
<a class="toggle-table-of-contents" data-behavior="toggle-table-of-contents" href="#"></a>
</div>
<nav class="pytorch-left-menu" data-toggle="wy-nav-shift" id="pytorch-left-menu">
<div class="pytorch-side-scroll">
<div aria-label="main navigation" class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation">
<div class="pytorch-left-menu-search">
<div class="version">
                  1.7.1
                </div>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input name="q" placeholder="Search Tutorials" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div>
<p class="caption"><span class="caption-text">PyTorch Recipes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../recipes/recipes_index.html">See All Recipes</a></li>
</ul>
<p class="caption"><span class="caption-text">Learning PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_with_examples.html">Learning PyTorch with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn_tutorial.html">What is <cite>torch.nn</cite> <em>really</em>?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tensorboard_tutorial.html">Visualizing Models, Data, and Training with TensorBoard</a></li>
</ul>
<p class="caption"><span class="caption-text">Image/Video</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchvision_tutorial.html">TorchVision Object Detection Finetuning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="fgsm_tutorial.html">Adversarial Example Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Audio</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="audio_preprocessing_tutorial.html">Audio I/O and Pre-Processing with torchaudio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/speech_command_recognition_with_torchaudio.html">SyntaxError</a></li>
</ul>
<p class="caption"><span class="caption-text">Text</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="transformer_tutorial.html">Sequence-to-Sequence Modeling with nn.Transformer and TorchText</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">NLP From Scratch: Classifying Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">NLP From Scratch: Generating Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">NLP From Scratch: Translation with a Sequence to Sequence Network and Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="text_sentiment_ngrams_tutorial.html">Text Classification with TorchText</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchtext_translation.html">Language Translation with TorchText</a></li>
</ul>
<p class="caption"><span class="caption-text">Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/mario_rl_tutorial.html">Train a Mario-playing RL Agent</a></li>
</ul>
<p class="caption"><span class="caption-text">Deploying PyTorch Models in Production</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/flask_rest_api_tutorial.html">Deploying PyTorch in Python via a REST API with Flask</a></li>
<li class="toctree-l1"><a class="reference internal" href="Intro_to_TorchScript_tutorial.html">Introduction to TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_export.html">Loading a TorchScript Model in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/super_resolution_with_onnxruntime.html">(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime</a></li>
</ul>
<p class="caption"><span class="caption-text">Frontend APIs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/named_tensor_tutorial.html">(prototype) Introduction to Named Tensors in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/memory_format_tutorial.html">(beta) Channels Last Memory Format in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_frontend.html">Using the PyTorch C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_ops.html">Extending TorchScript with Custom C++ Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_classes.html">Extending TorchScript with Custom C++ Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch-script-parallelism.html">Dynamic Parallelism in TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_autograd.html">Autograd in C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dispatcher.html">Registering a Dispatched Operator in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/extend_dispatcher.html">Extending dispatcher for a new backend in C++</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Optimization</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="profiler.html">Profiling your PyTorch Module</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Hyperparameter tuning with Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pruning_tutorial.html">Pruning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dynamic_quantization_tutorial.html">(beta) Dynamic Quantization on an LSTM Word Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dynamic_quantization_bert_tutorial.html">(beta) Dynamic Quantization on BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/quantized_transfer_learning_tutorial.html">(beta) Quantized Transfer Learning for Computer Vision Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Parallel and Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dist_overview.html">PyTorch Distributed Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/model_parallel_tutorial.html">Single-Machine Model Parallel Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_tutorial.html">Getting Started with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_param_server_tutorial.html">Implementing a Parameter Server Using Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_pipeline_parallel_tutorial.html">Distributed Pipeline Parallelism Using RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_async_execution.html">Implementing Batch RPC Processing Using Asynchronous Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/rpc_ddp_tutorial.html">Combining Distributed DataParallel with Distributed RPC Framework</a></li>
</ul>
</div>
</div>
</nav>
<div class="pytorch-container">
<div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
<div class="pytorch-breadcrumbs-wrapper">
<div aria-label="breadcrumbs navigation" role="navigation">
<ul class="pytorch-breadcrumbs">
<li>
<a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>
<li>Hyperparameter tuning with Ray Tune</li>
<li class="pytorch-breadcrumbs-aside">
<a href="../_sources/beginner/hyperparameter_tuning_tutorial.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"/></a>
</li>
</ul>
</div>
</div>
<div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
</div>
<section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
<div class="pytorch-content-left">
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">beginner/hyperparameter_tuning_tutorial</div>
<div id="google-colab-link">
<img class="call-to-action-img" src="../_static/images/pytorch-colab.svg"/>
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</div>
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
<div id="github-view-link">
<img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</div>
<div class="rst-content">
<div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
<div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-beginner-hyperparameter-tuning-tutorial-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="hyperparameter-tuning-with-ray-tune">
<span id="sphx-glr-beginner-hyperparameter-tuning-tutorial-py"></span><h1>Hyperparameter tuning with Ray Tune<a class="headerlink" href="#hyperparameter-tuning-with-ray-tune" title="Permalink to this headline">¶</a></h1>
<p>Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.</p>
<p>Fortunately, there are tools that help with finding the best combination of parameters.
<a class="reference external" href="https://docs.ray.io/en/latest/tune.html">Ray Tune</a> is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through <a class="reference external" href="https://ray.io/">Ray’s distributed machine learning engine</a>.</p>
<p>In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend <a class="reference external" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html">this tutorial from the PyTorch documentation</a> for training
a CIFAR10 image classifier.</p>
<p>As you will see, we only need to add some slight modifications. In particular, we
need to</p>
<ol class="arabic simple">
<li>wrap data loading and training in functions,</li>
<li>make some network parameters configurable,</li>
<li>add checkpointing (optional),</li>
<li>and define the search space for the model tuning</li>
</ol>
<div class="line-block">
<div class="line"><br/></div>
</div>
<p>To run this tutorial, please make sure the following packages are
installed:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">ray[tune]</span></code>: Distributed hyperparameter tuning library</li>
<li><code class="docutils literal notranslate"><span class="pre">torchvision</span></code>: For the data transformers</li>
</ul>
<div class="section" id="setup-imports">
<h2>Setup / Imports<a class="headerlink" href="#setup-imports" title="Permalink to this headline">¶</a></h2>
<p>Let’s start with the imports:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">random_split</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">ray</span> <span class="kn">import</span> <span class="n">tune</span>
<span class="kn">from</span> <span class="nn">ray.tune</span> <span class="kn">import</span> <span class="n">CLIReporter</span>
<span class="kn">from</span> <span class="nn">ray.tune.schedulers</span> <span class="kn">import</span> <span class="n">ASHAScheduler</span>
</pre></div>
</div>
<p>Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.</p>
</div>
<div class="section" id="data-loaders">
<h2>Data loaders<a class="headerlink" href="#data-loaders" title="Permalink to this headline">¶</a></h2>
<p>We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="n">data_dir</span><span class="o">=</span><span class="s2">"./data"</span><span class="p">):</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
    <span class="p">])</span>

    <span class="n">trainset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span>
        <span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

    <span class="n">testset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span>
        <span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">trainset</span><span class="p">,</span> <span class="n">testset</span>
</pre></div>
</div>
</div>
<div class="section" id="configurable-neural-network">
<h2>Configurable neural network<a class="headerlink" href="#configurable-neural-network" title="Permalink to this headline">¶</a></h2>
<p>We can only tune those parameters that are configurable. In this example, we can specify
the layer sizes of the fully connected layers:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">l1</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span> <span class="n">l2</span><span class="o">=</span><span class="mi">84</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="n">l1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">l1</span><span class="p">,</span> <span class="n">l2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">l2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
<div class="section" id="the-train-function">
<h2>The train function<a class="headerlink" href="#the-train-function" title="Permalink to this headline">¶</a></h2>
<p>Now it gets interesting, because we introduce some changes to the example <a class="reference external" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html">from the PyTorch
documentation</a>.</p>
<p>We wrap the training script in a function <code class="docutils literal notranslate"><span class="pre">train_cifar(config,</span> <span class="pre">checkpoint_dir=None,</span> <span class="pre">data_dir=None)</span></code>.
As you can guess, the <code class="docutils literal notranslate"><span class="pre">config</span></code> parameter will receive the hyperparameters we would like to
train with. The <code class="docutils literal notranslate"><span class="pre">checkpoint_dir</span></code> parameter is used to restore checkpoints. The <code class="docutils literal notranslate"><span class="pre">data_dir</span></code> specifies
the directory where we load and store the data, so multiple runs can share the same data source.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"l1"</span><span class="p">],</span> <span class="n">config</span><span class="p">[</span><span class="s2">"l2"</span><span class="p">])</span>

<span class="k">if</span> <span class="n">checkpoint_dir</span><span class="p">:</span>
    <span class="n">model_state</span><span class="p">,</span> <span class="n">optimizer_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">))</span>
    <span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_state</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">optimizer_state</span><span class="p">)</span>
</pre></div>
</div>
<p>The learning rate of the optimizer is made configurable, too:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">],</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
<p>We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.</p>
<div class="section" id="adding-multi-gpu-support-with-dataparallel">
<h3>Adding (multi) GPU support with DataParallel<a class="headerlink" href="#adding-multi-gpu-support-with-dataparallel" title="Permalink to this headline">¶</a></h3>
<p>Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch’s abstractions in Ray Tune. Thus, we can wrap our model in <code class="docutils literal notranslate"><span class="pre">nn.DataParallel</span></code>
to support data parallel training on multiple GPUs:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="s2">"cpu"</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda:0"</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>By using a <code class="docutils literal notranslate"><span class="pre">device</span></code> variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">trainloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports <a class="reference external" href="https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus">fractional GPUs</a>
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We’ll come back
to that later.</p>
</div>
<div class="section" id="communicating-with-ray-tune">
<h3>Communicating with Ray Tune<a class="headerlink" href="#communicating-with-ray-tune" title="Permalink to this headline">¶</a></h3>
<p>The most interesting part is the communication with Ray Tune:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tune</span><span class="o">.</span><span class="n">checkpoint_dir</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="k">as</span> <span class="n">checkpoint_dir</span><span class="p">:</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">((</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()),</span> <span class="n">path</span><span class="p">)</span>

<span class="n">tune</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="p">(</span><span class="n">val_loss</span> <span class="o">/</span> <span class="n">val_steps</span><span class="p">),</span> <span class="n">accuracy</span><span class="o">=</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
</pre></div>
</div>
<p>Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.</p>
<p>The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
<a class="reference external" href="https://docs.ray.io/en/master/tune/tutorials/tune-advanced-tutorial.html">Population Based Training</a>.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set.</p>
</div>
<div class="section" id="full-training-function">
<h3>Full training function<a class="headerlink" href="#full-training-function" title="Permalink to this headline">¶</a></h3>
<p>The full code example looks like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_cifar</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">checkpoint_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"l1"</span><span class="p">],</span> <span class="n">config</span><span class="p">[</span><span class="s2">"l2"</span><span class="p">])</span>

    <span class="n">device</span> <span class="o">=</span> <span class="s2">"cpu"</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda:0"</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">],</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">checkpoint_dir</span><span class="p">:</span>
        <span class="n">model_state</span><span class="p">,</span> <span class="n">optimizer_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
            <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">))</span>
        <span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_state</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">optimizer_state</span><span class="p">)</span>

    <span class="n">trainset</span><span class="p">,</span> <span class="n">testset</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>

    <span class="n">test_abs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainset</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
    <span class="n">train_subset</span><span class="p">,</span> <span class="n">val_subset</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span>
        <span class="n">trainset</span><span class="p">,</span> <span class="p">[</span><span class="n">test_abs</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainset</span><span class="p">)</span> <span class="o">-</span> <span class="n">test_abs</span><span class="p">])</span>

    <span class="n">trainloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">train_subset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">]),</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">valloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">val_subset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">]),</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>  <span class="c1"># loop over the dataset multiple times</span>
        <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">epoch_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">trainloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
            <span class="c1"># get the inputs; data is a list of [inputs, labels]</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># zero the parameter gradients</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># forward + backward + optimize</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># print statistics</span>
            <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">epoch_steps</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">2000</span> <span class="o">==</span> <span class="mi">1999</span><span class="p">:</span>  <span class="c1"># print every 2000 mini-batches</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">"[</span><span class="si">%d</span><span class="s2">, </span><span class="si">%5d</span><span class="s2">] loss: </span><span class="si">%.3f</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                                                <span class="n">running_loss</span> <span class="o">/</span> <span class="n">epoch_steps</span><span class="p">))</span>
                <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="c1"># Validation loss</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">val_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">valloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">val_steps</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">with</span> <span class="n">tune</span><span class="o">.</span><span class="n">checkpoint_dir</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="k">as</span> <span class="n">checkpoint_dir</span><span class="p">:</span>
            <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">((</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()),</span> <span class="n">path</span><span class="p">)</span>

        <span class="n">tune</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="p">(</span><span class="n">val_loss</span> <span class="o">/</span> <span class="n">val_steps</span><span class="p">),</span> <span class="n">accuracy</span><span class="o">=</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Finished Training"</span><span class="p">)</span>
</pre></div>
</div>
<p>As you can see, most of the code is adapted directly from the original example.</p>
</div>
</div>
<div class="section" id="test-set-accuracy">
<h2>Test set accuracy<a class="headerlink" href="#test-set-accuracy" title="Permalink to this headline">¶</a></h2>
<p>Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_accuracy</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">"cpu"</span><span class="p">):</span>
    <span class="n">trainset</span><span class="p">,</span> <span class="n">testset</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>

    <span class="n">testloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">testset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">testloader</span><span class="p">:</span>
            <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
            <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
</pre></div>
</div>
<p>The function also expects a <code class="docutils literal notranslate"><span class="pre">device</span></code> parameter, so we can do the
test set validation on a GPU.</p>
</div>
<div class="section" id="configuring-the-search-space">
<h2>Configuring the search space<a class="headerlink" href="#configuring-the-search-space" title="Permalink to this headline">¶</a></h2>
<p>Lastly, we need to define Ray Tune’s search space. Here is an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"l1"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">sample_from</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mi">2</span><span class="o">**</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)),</span>
    <span class="s2">"l2"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">sample_from</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mi">2</span><span class="o">**</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)),</span>
    <span class="s2">"lr"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">),</span>
    <span class="s2">"batch_size"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">tune.sample_from()</span></code> function makes it possible to define your own sample
methods to obtain hyperparameters. In this example, the <code class="docutils literal notranslate"><span class="pre">l1</span></code> and <code class="docutils literal notranslate"><span class="pre">l2</span></code> parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The <code class="docutils literal notranslate"><span class="pre">lr</span></code> (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.</p>
<p>At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the <code class="docutils literal notranslate"><span class="pre">ASHAScheduler</span></code> which will terminate bad
performing trials early.</p>
<p>We wrap the <code class="docutils literal notranslate"><span class="pre">train_cifar</span></code> function with <code class="docutils literal notranslate"><span class="pre">functools.partial</span></code> to set the constant
<code class="docutils literal notranslate"><span class="pre">data_dir</span></code> parameter. We can also tell Ray Tune what resources should be
available for each trial:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gpus_per_trial</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># ...</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">partial</span><span class="p">(</span><span class="n">train_cifar</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="n">data_dir</span><span class="p">),</span>
    <span class="n">resources_per_trial</span><span class="o">=</span><span class="p">{</span><span class="s2">"cpu"</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s2">"gpu"</span><span class="p">:</span> <span class="n">gpus_per_trial</span><span class="p">},</span>
    <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
    <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
    <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
    <span class="n">progress_reporter</span><span class="o">=</span><span class="n">reporter</span><span class="p">,</span>
    <span class="n">checkpoint_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>You can specify the number of CPUs, which are then available e.g.
to increase the <code class="docutils literal notranslate"><span class="pre">num_workers</span></code> of the PyTorch <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven’t been requested for them - so you don’t have to care about two trials
using the same set of resources.</p>
<p>Here we can also specify fractional GPUs, so something like <code class="docutils literal notranslate"><span class="pre">gpus_per_trial=0.5</span></code> is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.</p>
<p>After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.</p>
<p>The full main function looks like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_num_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gpus_per_trial</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">"./data"</span><span class="p">)</span>
    <span class="n">load_data</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">"l1"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">sample_from</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)),</span>
        <span class="s2">"l2"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">sample_from</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)),</span>
        <span class="s2">"lr"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">),</span>
        <span class="s2">"batch_size"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
    <span class="p">}</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">ASHAScheduler</span><span class="p">(</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">"loss"</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">"min"</span><span class="p">,</span>
        <span class="n">max_t</span><span class="o">=</span><span class="n">max_num_epochs</span><span class="p">,</span>
        <span class="n">grace_period</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">reduction_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">reporter</span> <span class="o">=</span> <span class="n">CLIReporter</span><span class="p">(</span>
        <span class="c1"># parameter_columns=["l1", "l2", "lr", "batch_size"],</span>
        <span class="n">metric_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"loss"</span><span class="p">,</span> <span class="s2">"accuracy"</span><span class="p">,</span> <span class="s2">"training_iteration"</span><span class="p">])</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
        <span class="n">partial</span><span class="p">(</span><span class="n">train_cifar</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="n">data_dir</span><span class="p">),</span>
        <span class="n">resources_per_trial</span><span class="o">=</span><span class="p">{</span><span class="s2">"cpu"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">"gpu"</span><span class="p">:</span> <span class="n">gpus_per_trial</span><span class="p">},</span>
        <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
        <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
        <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
        <span class="n">progress_reporter</span><span class="o">=</span><span class="n">reporter</span><span class="p">)</span>

    <span class="n">best_trial</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">get_best_trial</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">,</span> <span class="s2">"min"</span><span class="p">,</span> <span class="s2">"last"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Best trial config: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_trial</span><span class="o">.</span><span class="n">config</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Best trial final validation loss: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">best_trial</span><span class="o">.</span><span class="n">last_result</span><span class="p">[</span><span class="s2">"loss"</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Best trial final validation accuracy: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">best_trial</span><span class="o">.</span><span class="n">last_result</span><span class="p">[</span><span class="s2">"accuracy"</span><span class="p">]))</span>

    <span class="n">best_trained_model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">best_trial</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">"l1"</span><span class="p">],</span> <span class="n">best_trial</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">"l2"</span><span class="p">])</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s2">"cpu"</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda:0"</span>
        <span class="k">if</span> <span class="n">gpus_per_trial</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">best_trained_model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">best_trained_model</span><span class="p">)</span>
    <span class="n">best_trained_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">best_checkpoint_dir</span> <span class="o">=</span> <span class="n">best_trial</span><span class="o">.</span><span class="n">checkpoint</span><span class="o">.</span><span class="n">value</span>
    <span class="n">model_state</span><span class="p">,</span> <span class="n">optimizer_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">best_checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">))</span>
    <span class="n">best_trained_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_state</span><span class="p">)</span>

    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">test_accuracy</span><span class="p">(</span><span class="n">best_trained_model</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Best trial test set accuracy: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_acc</span><span class="p">))</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
    <span class="c1"># You can change the number of GPUs per trial here:</span>
    <span class="n">main</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_num_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gpus_per_trial</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz
Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
Files already downloaded and verified
== Status ==
Memory usage on this node: 4.0/240.1 GiB
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 1/10 (1 RUNNING)
+---------------------+----------+-------+--------------+------+------+------------+
| Trial name          | status   | loc   |   batch_size |   l1 |   l2 |         lr |
|---------------------+----------+-------+--------------+------+------+------------|
| DEFAULT_7be21_00000 | RUNNING  |       |            4 |   32 |   16 | 0.00134258 |
+---------------------+----------+-------+--------------+------+------+------------+


[2m[36m(pid=1581)[0m Files already downloaded and verified
[2m[36m(pid=1555)[0m Files already downloaded and verified
[2m[36m(pid=1535)[0m Files already downloaded and verified
[2m[36m(pid=1551)[0m Files already downloaded and verified
[2m[36m(pid=1533)[0m Files already downloaded and verified
[2m[36m(pid=1536)[0m Files already downloaded and verified
[2m[36m(pid=1580)[0m Files already downloaded and verified
[2m[36m(pid=1534)[0m Files already downloaded and verified
[2m[36m(pid=1582)[0m Files already downloaded and verified
[2m[36m(pid=1571)[0m Files already downloaded and verified
[2m[36m(pid=1581)[0m Files already downloaded and verified
[2m[36m(pid=1555)[0m Files already downloaded and verified
[2m[36m(pid=1535)[0m Files already downloaded and verified
[2m[36m(pid=1551)[0m Files already downloaded and verified
[2m[36m(pid=1533)[0m Files already downloaded and verified
[2m[36m(pid=1536)[0m Files already downloaded and verified
[2m[36m(pid=1580)[0m Files already downloaded and verified
[2m[36m(pid=1534)[0m Files already downloaded and verified
[2m[36m(pid=1582)[0m Files already downloaded and verified
[2m[36m(pid=1571)[0m Files already downloaded and verified
[2m[36m(pid=1580)[0m [1,  2000] loss: 2.266
[2m[36m(pid=1551)[0m [1,  2000] loss: 2.315
[2m[36m(pid=1533)[0m [1,  2000] loss: 2.184
[2m[36m(pid=1535)[0m [1,  2000] loss: 2.257
[2m[36m(pid=1555)[0m [1,  2000] loss: 1.942
[2m[36m(pid=1571)[0m [1,  2000] loss: 2.128
[2m[36m(pid=1582)[0m [1,  2000] loss: 1.988
[2m[36m(pid=1534)[0m [1,  2000] loss: 2.023
[2m[36m(pid=1581)[0m [1,  2000] loss: 1.974
[2m[36m(pid=1536)[0m [1,  2000] loss: 2.305
Result for DEFAULT_7be21_00001:
  accuracy: 0.2964
  date: 2021-02-17_18-47-13
  done: false
  experiment_id: 923357017bcd46d68a9ec9fe75ef1710
  experiment_tag: 1_batch_size=16,l1=8,l2=4,lr=0.01981
  hostname: 09ee4e08461a
  iterations_since_restore: 1
  loss: 1.8613842100143432
  node_ip: 172.17.0.2
  pid: 1581
  should_checkpoint: true
  time_since_restore: 27.194583415985107
  time_this_iter_s: 27.194583415985107
  time_total_s: 27.194583415985107
  timestamp: 1613587633
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 7be21_00001

== Status ==
Memory usage on this node: 9.4/240.1 GiB
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.8613842100143432
Resources requested: 20/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (10 RUNNING)
+---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status   | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING  |                 |            4 |   32 |   16 | 0.00134258  |         |            |                      |
| DEFAULT_7be21_00001 | RUNNING  | 172.17.0.2:1581 |           16 |    8 |    4 | 0.0198101   | 1.86138 |     0.2964 |                    1 |
| DEFAULT_7be21_00002 | RUNNING  |                 |            8 |  128 |   16 | 0.00538093  |         |            |                      |
| DEFAULT_7be21_00003 | RUNNING  |                 |            8 |   16 |    8 | 0.00088584  |         |            |                      |
| DEFAULT_7be21_00004 | RUNNING  |                 |           16 |  256 |   32 | 0.000269525 |         |            |                      |
| DEFAULT_7be21_00005 | RUNNING  |                 |            4 |   16 |    4 | 0.000221824 |         |            |                      |
| DEFAULT_7be21_00006 | RUNNING  |                 |            8 |   32 |   16 | 0.00196461  |         |            |                      |
| DEFAULT_7be21_00007 | RUNNING  |                 |            2 |  128 |   16 | 0.0099341   |         |            |                      |
| DEFAULT_7be21_00008 | RUNNING  |                 |            8 |   64 |   64 | 0.00241479  |         |            |                      |
| DEFAULT_7be21_00009 | RUNNING  |                 |            8 |    8 |    8 | 0.0125789   |         |            |                      |
+---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1580)[0m [1,  4000] loss: 1.086
[2m[36m(pid=1551)[0m [1,  4000] loss: 1.150
[2m[36m(pid=1533)[0m [1,  4000] loss: 0.939
Result for DEFAULT_7be21_00004:
  accuracy: 0.0995
  date: 2021-02-17_18-47-16
  done: true
  experiment_id: 1f42ee9bd96b44b8941b58b3d773524b
  experiment_tag: 4_batch_size=16,l1=256,l2=32,lr=0.00026952
  hostname: 09ee4e08461a
  iterations_since_restore: 1
  loss: 2.300075381088257
  node_ip: 172.17.0.2
  pid: 1536
  should_checkpoint: true
  time_since_restore: 29.599982023239136
  time_this_iter_s: 29.599982023239136
  time_total_s: 29.599982023239136
  timestamp: 1613587636
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 7be21_00004

[2m[36m(pid=1535)[0m [1,  4000] loss: 0.957
[2m[36m(pid=1534)[0m [1,  4000] loss: 0.948
[2m[36m(pid=1571)[0m [1,  4000] loss: 0.874
[2m[36m(pid=1582)[0m [1,  4000] loss: 0.818
[2m[36m(pid=1555)[0m [1,  4000] loss: 0.800
[2m[36m(pid=1551)[0m [1,  6000] loss: 0.759
[2m[36m(pid=1533)[0m [1,  6000] loss: 0.564
[2m[36m(pid=1580)[0m [1,  6000] loss: 0.727
Result for DEFAULT_7be21_00009:
  accuracy: 0.2673
  date: 2021-02-17_18-47-28
  done: false
  experiment_id: 8a49f70587814fed94af9ad792259380
  experiment_tag: 9_batch_size=8,l1=8,l2=8,lr=0.012579
  hostname: 09ee4e08461a
  iterations_since_restore: 1
  loss: 1.98523823928833
  node_ip: 172.17.0.2
  pid: 1534
  should_checkpoint: true
  time_since_restore: 41.67048716545105
  time_this_iter_s: 41.67048716545105
  time_total_s: 41.67048716545105
  timestamp: 1613587648
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 7be21_00009

== Status ==
Memory usage on this node: 8.8/240.1 GiB
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.98523823928833
Resources requested: 18/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (9 RUNNING, 1 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    |                 |            4 |   32 |   16 | 0.00134258  |         |            |                      |
| DEFAULT_7be21_00001 | RUNNING    | 172.17.0.2:1581 |           16 |    8 |    4 | 0.0198101   | 1.86138 |     0.2964 |                    1 |
| DEFAULT_7be21_00002 | RUNNING    |                 |            8 |  128 |   16 | 0.00538093  |         |            |                      |
| DEFAULT_7be21_00003 | RUNNING    |                 |            8 |   16 |    8 | 0.00088584  |         |            |                      |
| DEFAULT_7be21_00005 | RUNNING    |                 |            4 |   16 |    4 | 0.000221824 |         |            |                      |
| DEFAULT_7be21_00006 | RUNNING    |                 |            8 |   32 |   16 | 0.00196461  |         |            |                      |
| DEFAULT_7be21_00007 | RUNNING    |                 |            2 |  128 |   16 | 0.0099341   |         |            |                      |
| DEFAULT_7be21_00008 | RUNNING    |                 |            8 |   64 |   64 | 0.00241479  |         |            |                      |
| DEFAULT_7be21_00009 | RUNNING    | 172.17.0.2:1534 |            8 |    8 |    8 | 0.0125789   | 1.98524 |     0.2673 |                    1 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_7be21_00003:
  accuracy: 0.3551
  date: 2021-02-17_18-47-28
  done: false
  experiment_id: 4a196a9f207c408a8464941364bb63d4
  experiment_tag: 3_batch_size=8,l1=16,l2=8,lr=0.00088584
  hostname: 09ee4e08461a
  iterations_since_restore: 1
  loss: 1.7425096386909484
  node_ip: 172.17.0.2
  pid: 1535
  should_checkpoint: true
  time_since_restore: 42.17355513572693
  time_this_iter_s: 42.17355513572693
  time_total_s: 42.17355513572693
  timestamp: 1613587648
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 7be21_00003

Result for DEFAULT_7be21_00006:
  accuracy: 0.4111
  date: 2021-02-17_18-47-28
  done: false
  experiment_id: 6ce29aed25254bf0885e2d5d603c0bbd
  experiment_tag: 6_batch_size=8,l1=32,l2=16,lr=0.0019646
  hostname: 09ee4e08461a
  iterations_since_restore: 1
  loss: 1.5861479718208313
  node_ip: 172.17.0.2
  pid: 1571
  should_checkpoint: true
  time_since_restore: 42.2446928024292
  time_this_iter_s: 42.2446928024292
  time_total_s: 42.2446928024292
  timestamp: 1613587648
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 7be21_00006

Result for DEFAULT_7be21_00008:
  accuracy: 0.4585
  date: 2021-02-17_18-47-29
  done: false
  experiment_id: 8bc8b883eb8e4a2b8460566f62205761
  experiment_tag: 8_batch_size=8,l1=64,l2=64,lr=0.0024148
  hostname: 09ee4e08461a
  iterations_since_restore: 1
  loss: 1.4938029237270356
  node_ip: 172.17.0.2
  pid: 1582
  should_checkpoint: true
  time_since_restore: 42.25521969795227
  time_this_iter_s: 42.25521969795227
  time_total_s: 42.25521969795227
  timestamp: 1613587649
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 7be21_00008

Result for DEFAULT_7be21_00002:
  accuracy: 0.4434
  date: 2021-02-17_18-47-29
  done: false
  experiment_id: 8451a29d824f4ad7ac5700e5d04714eb
  experiment_tag: 2_batch_size=8,l1=128,l2=16,lr=0.0053809
  hostname: 09ee4e08461a
  iterations_since_restore: 1
  loss: 1.5181223117351532
  node_ip: 172.17.0.2
  pid: 1555
  should_checkpoint: true
  time_since_restore: 42.74570345878601
  time_this_iter_s: 42.74570345878601
  time_total_s: 42.74570345878601
  timestamp: 1613587649
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 7be21_00002

[2m[36m(pid=1581)[0m [2,  2000] loss: 1.881
Result for DEFAULT_7be21_00001:
  accuracy: 0.2824
  date: 2021-02-17_18-47-36
  done: false
  experiment_id: 923357017bcd46d68a9ec9fe75ef1710
  experiment_tag: 1_batch_size=16,l1=8,l2=4,lr=0.01981
  hostname: 09ee4e08461a
  iterations_since_restore: 2
  loss: 1.8086380647659301
  node_ip: 172.17.0.2
  pid: 1581
  should_checkpoint: true
  time_since_restore: 49.97949457168579
  time_this_iter_s: 22.784911155700684
  time_total_s: 49.97949457168579
  timestamp: 1613587656
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 7be21_00001

== Status ==
Memory usage on this node: 8.8/240.1 GiB
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8086380647659301 | Iter 1.000: -1.7425096386909484
Resources requested: 18/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (9 RUNNING, 1 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    |                 |            4 |   32 |   16 | 0.00134258  |         |            |                      |
| DEFAULT_7be21_00001 | RUNNING    | 172.17.0.2:1581 |           16 |    8 |    4 | 0.0198101   | 1.80864 |     0.2824 |                    2 |
| DEFAULT_7be21_00002 | RUNNING    | 172.17.0.2:1555 |            8 |  128 |   16 | 0.00538093  | 1.51812 |     0.4434 |                    1 |
| DEFAULT_7be21_00003 | RUNNING    | 172.17.0.2:1535 |            8 |   16 |    8 | 0.00088584  | 1.74251 |     0.3551 |                    1 |
| DEFAULT_7be21_00005 | RUNNING    |                 |            4 |   16 |    4 | 0.000221824 |         |            |                      |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.58615 |     0.4111 |                    1 |
| DEFAULT_7be21_00007 | RUNNING    |                 |            2 |  128 |   16 | 0.0099341   |         |            |                      |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.4938  |     0.4585 |                    1 |
| DEFAULT_7be21_00009 | RUNNING    | 172.17.0.2:1534 |            8 |    8 |    8 | 0.0125789   | 1.98524 |     0.2673 |                    1 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1551)[0m [1,  8000] loss: 0.553
[2m[36m(pid=1533)[0m [1,  8000] loss: 0.401
[2m[36m(pid=1580)[0m [1,  8000] loss: 0.546
[2m[36m(pid=1534)[0m [2,  2000] loss: 1.976
[2m[36m(pid=1535)[0m [2,  2000] loss: 1.676
[2m[36m(pid=1571)[0m [2,  2000] loss: 1.542
[2m[36m(pid=1582)[0m [2,  2000] loss: 1.439
[2m[36m(pid=1555)[0m [2,  2000] loss: 1.471
[2m[36m(pid=1551)[0m [1, 10000] loss: 0.417
[2m[36m(pid=1533)[0m [1, 10000] loss: 0.307
[2m[36m(pid=1581)[0m [3,  2000] loss: 1.841
[2m[36m(pid=1580)[0m [1, 10000] loss: 0.444
[2m[36m(pid=1534)[0m [2,  4000] loss: 0.979
[2m[36m(pid=1535)[0m [2,  4000] loss: 0.770
[2m[36m(pid=1571)[0m [2,  4000] loss: 0.727
[2m[36m(pid=1582)[0m [2,  4000] loss: 0.694
[2m[36m(pid=1555)[0m [2,  4000] loss: 0.727
Result for DEFAULT_7be21_00005:
  accuracy: 0.2069
  date: 2021-02-17_18-47-56
  done: true
  experiment_id: c0d497cefb31400bb55a04f7272204b8
  experiment_tag: 5_batch_size=4,l1=16,l2=4,lr=0.00022182
  hostname: 09ee4e08461a
  iterations_since_restore: 1
  loss: 2.0144215025901793
  node_ip: 172.17.0.2
  pid: 1551
  should_checkpoint: true
  time_since_restore: 70.35603165626526
  time_this_iter_s: 70.35603165626526
  time_total_s: 70.35603165626526
  timestamp: 1613587676
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 7be21_00005

== Status ==
Memory usage on this node: 8.7/240.1 GiB
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8086380647659301 | Iter 1.000: -1.8019469243526458
Resources requested: 18/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (9 RUNNING, 1 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    |                 |            4 |   32 |   16 | 0.00134258  |         |            |                      |
| DEFAULT_7be21_00001 | RUNNING    | 172.17.0.2:1581 |           16 |    8 |    4 | 0.0198101   | 1.80864 |     0.2824 |                    2 |
| DEFAULT_7be21_00002 | RUNNING    | 172.17.0.2:1555 |            8 |  128 |   16 | 0.00538093  | 1.51812 |     0.4434 |                    1 |
| DEFAULT_7be21_00003 | RUNNING    | 172.17.0.2:1535 |            8 |   16 |    8 | 0.00088584  | 1.74251 |     0.3551 |                    1 |
| DEFAULT_7be21_00005 | RUNNING    | 172.17.0.2:1551 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.58615 |     0.4111 |                    1 |
| DEFAULT_7be21_00007 | RUNNING    |                 |            2 |  128 |   16 | 0.0099341   |         |            |                      |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.4938  |     0.4585 |                    1 |
| DEFAULT_7be21_00009 | RUNNING    | 172.17.0.2:1534 |            8 |    8 |    8 | 0.0125789   | 1.98524 |     0.2673 |                    1 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_7be21_00000:
  accuracy: 0.4482
  date: 2021-02-17_18-47-57
  done: false
  experiment_id: 80a26b352e064e7f957a91a561e55491
  experiment_tag: 0_batch_size=4,l1=32,l2=16,lr=0.0013426
  hostname: 09ee4e08461a
  iterations_since_restore: 1
  loss: 1.5328676432192325
  node_ip: 172.17.0.2
  pid: 1533
  should_checkpoint: true
  time_since_restore: 70.92192029953003
  time_this_iter_s: 70.92192029953003
  time_total_s: 70.92192029953003
  timestamp: 1613587677
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 7be21_00000

Result for DEFAULT_7be21_00001:
  accuracy: 0.2556
  date: 2021-02-17_18-47-59
  done: false
  experiment_id: 923357017bcd46d68a9ec9fe75ef1710
  experiment_tag: 1_batch_size=16,l1=8,l2=4,lr=0.01981
  hostname: 09ee4e08461a
  iterations_since_restore: 3
  loss: 1.9175381092071533
  node_ip: 172.17.0.2
  pid: 1581
  should_checkpoint: true
  time_since_restore: 72.41441559791565
  time_this_iter_s: 22.43492102622986
  time_total_s: 72.41441559791565
  timestamp: 1613587679
  timesteps_since_restore: 0
  training_iteration: 3
  trial_id: 7be21_00001

[2m[36m(pid=1580)[0m [1, 12000] loss: 0.375
Result for DEFAULT_7be21_00009:
  accuracy: 0.1514
  date: 2021-02-17_18-48-05
  done: true
  experiment_id: 8a49f70587814fed94af9ad792259380
  experiment_tag: 9_batch_size=8,l1=8,l2=8,lr=0.012579
  hostname: 09ee4e08461a
  iterations_since_restore: 2
  loss: 2.227771428012848
  node_ip: 172.17.0.2
  pid: 1534
  should_checkpoint: true
  time_since_restore: 78.54550433158875
  time_this_iter_s: 36.875017166137695
  time_total_s: 78.54550433158875
  timestamp: 1613587685
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 7be21_00009

== Status ==
Memory usage on this node: 8.2/240.1 GiB
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.0182047463893893 | Iter 1.000: -1.7425096386909484
Resources requested: 16/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.53287 |     0.4482 |                    1 |
| DEFAULT_7be21_00001 | RUNNING    | 172.17.0.2:1581 |           16 |    8 |    4 | 0.0198101   | 1.91754 |     0.2556 |                    3 |
| DEFAULT_7be21_00002 | RUNNING    | 172.17.0.2:1555 |            8 |  128 |   16 | 0.00538093  | 1.51812 |     0.4434 |                    1 |
| DEFAULT_7be21_00003 | RUNNING    | 172.17.0.2:1535 |            8 |   16 |    8 | 0.00088584  | 1.74251 |     0.3551 |                    1 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.58615 |     0.4111 |                    1 |
| DEFAULT_7be21_00007 | RUNNING    |                 |            2 |  128 |   16 | 0.0099341   |         |            |                      |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.4938  |     0.4585 |                    1 |
| DEFAULT_7be21_00009 | RUNNING    | 172.17.0.2:1534 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_7be21_00003:
  accuracy: 0.4511
  date: 2021-02-17_18-48-06
  done: false
  experiment_id: 4a196a9f207c408a8464941364bb63d4
  experiment_tag: 3_batch_size=8,l1=16,l2=8,lr=0.00088584
  hostname: 09ee4e08461a
  iterations_since_restore: 2
  loss: 1.4976928141593933
  node_ip: 172.17.0.2
  pid: 1535
  should_checkpoint: true
  time_since_restore: 79.59795546531677
  time_this_iter_s: 37.424400329589844
  time_total_s: 79.59795546531677
  timestamp: 1613587686
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 7be21_00003

Result for DEFAULT_7be21_00006:
  accuracy: 0.5153
  date: 2021-02-17_18-48-06
  done: false
  experiment_id: 6ce29aed25254bf0885e2d5d603c0bbd
  experiment_tag: 6_batch_size=8,l1=32,l2=16,lr=0.0019646
  hostname: 09ee4e08461a
  iterations_since_restore: 2
  loss: 1.3453772943496705
  node_ip: 172.17.0.2
  pid: 1571
  should_checkpoint: true
  time_since_restore: 79.54599070549011
  time_this_iter_s: 37.30129790306091
  time_total_s: 79.54599070549011
  timestamp: 1613587686
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 7be21_00006

Result for DEFAULT_7be21_00008:
  accuracy: 0.5262
  date: 2021-02-17_18-48-06
  done: false
  experiment_id: 8bc8b883eb8e4a2b8460566f62205761
  experiment_tag: 8_batch_size=8,l1=64,l2=64,lr=0.0024148
  hostname: 09ee4e08461a
  iterations_since_restore: 2
  loss: 1.3166384412288665
  node_ip: 172.17.0.2
  pid: 1582
  should_checkpoint: true
  time_since_restore: 79.63443660736084
  time_this_iter_s: 37.37921690940857
  time_total_s: 79.63443660736084
  timestamp: 1613587686
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 7be21_00008

Result for DEFAULT_7be21_00002:
  accuracy: 0.4874
  date: 2021-02-17_18-48-07
  done: false
  experiment_id: 8451a29d824f4ad7ac5700e5d04714eb
  experiment_tag: 2_batch_size=8,l1=128,l2=16,lr=0.0053809
  hostname: 09ee4e08461a
  iterations_since_restore: 2
  loss: 1.4372519857645034
  node_ip: 172.17.0.2
  pid: 1555
  should_checkpoint: true
  time_since_restore: 80.68881511688232
  time_this_iter_s: 37.94311165809631
  time_total_s: 80.68881511688232
  timestamp: 1613587687
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 7be21_00002

[2m[36m(pid=1533)[0m [2,  2000] loss: 1.503
[2m[36m(pid=1581)[0m [4,  2000] loss: 1.951
[2m[36m(pid=1580)[0m [1, 14000] loss: 0.315
[2m[36m(pid=1571)[0m [3,  2000] loss: 1.355
[2m[36m(pid=1582)[0m [3,  2000] loss: 1.287
[2m[36m(pid=1535)[0m [3,  2000] loss: 1.449
[2m[36m(pid=1533)[0m [2,  4000] loss: 0.731
[2m[36m(pid=1555)[0m [3,  2000] loss: 1.364
Result for DEFAULT_7be21_00001:
  accuracy: 0.1253
  date: 2021-02-17_18-48-20
  done: false
  experiment_id: 923357017bcd46d68a9ec9fe75ef1710
  experiment_tag: 1_batch_size=16,l1=8,l2=4,lr=0.01981
  hostname: 09ee4e08461a
  iterations_since_restore: 4
  loss: 2.4025123886108397
  node_ip: 172.17.0.2
  pid: 1581
  should_checkpoint: true
  time_since_restore: 94.27190279960632
  time_this_iter_s: 21.857487201690674
  time_total_s: 94.27190279960632
  timestamp: 1613587700
  timesteps_since_restore: 0
  training_iteration: 4
  trial_id: 7be21_00001

== Status ==
Memory usage on this node: 7.6/240.1 GiB
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: -2.4025123886108397 | Iter 2.000: -1.4674723999619483 | Iter 1.000: -1.7425096386909484
Resources requested: 14/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.53287 |     0.4482 |                    1 |
| DEFAULT_7be21_00001 | RUNNING    | 172.17.0.2:1581 |           16 |    8 |    4 | 0.0198101   | 2.40251 |     0.1253 |                    4 |
| DEFAULT_7be21_00002 | RUNNING    | 172.17.0.2:1555 |            8 |  128 |   16 | 0.00538093  | 1.43725 |     0.4874 |                    2 |
| DEFAULT_7be21_00003 | RUNNING    | 172.17.0.2:1535 |            8 |   16 |    8 | 0.00088584  | 1.49769 |     0.4511 |                    2 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.34538 |     0.5153 |                    2 |
| DEFAULT_7be21_00007 | RUNNING    |                 |            2 |  128 |   16 | 0.0099341   |         |            |                      |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.31664 |     0.5262 |                    2 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1580)[0m [1, 16000] loss: 0.272
[2m[36m(pid=1533)[0m [2,  6000] loss: 0.475
[2m[36m(pid=1571)[0m [3,  4000] loss: 0.665
[2m[36m(pid=1582)[0m [3,  4000] loss: 0.628
[2m[36m(pid=1535)[0m [3,  4000] loss: 0.712
[2m[36m(pid=1555)[0m [3,  4000] loss: 0.675
[2m[36m(pid=1581)[0m [5,  2000] loss: 2.286
[2m[36m(pid=1580)[0m [1, 18000] loss: 0.240
[2m[36m(pid=1533)[0m [2,  8000] loss: 0.352
Result for DEFAULT_7be21_00006:
  accuracy: 0.5539
  date: 2021-02-17_18-48-40
  done: false
  experiment_id: 6ce29aed25254bf0885e2d5d603c0bbd
  experiment_tag: 6_batch_size=8,l1=32,l2=16,lr=0.0019646
  hostname: 09ee4e08461a
  iterations_since_restore: 3
  loss: 1.251324620294571
  node_ip: 172.17.0.2
  pid: 1571
  should_checkpoint: true
  time_since_restore: 113.98425698280334
  time_this_iter_s: 34.43826627731323
  time_total_s: 113.98425698280334
  timestamp: 1613587720
  timesteps_since_restore: 0
  training_iteration: 3
  trial_id: 7be21_00006

== Status ==
Memory usage on this node: 7.6/240.1 GiB
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: -2.4025123886108397 | Iter 2.000: -1.4674723999619483 | Iter 1.000: -1.7425096386909484
Resources requested: 14/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.53287 |     0.4482 |                    1 |
| DEFAULT_7be21_00001 | RUNNING    | 172.17.0.2:1581 |           16 |    8 |    4 | 0.0198101   | 2.40251 |     0.1253 |                    4 |
| DEFAULT_7be21_00002 | RUNNING    | 172.17.0.2:1555 |            8 |  128 |   16 | 0.00538093  | 1.43725 |     0.4874 |                    2 |
| DEFAULT_7be21_00003 | RUNNING    | 172.17.0.2:1535 |            8 |   16 |    8 | 0.00088584  | 1.49769 |     0.4511 |                    2 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.25132 |     0.5539 |                    3 |
| DEFAULT_7be21_00007 | RUNNING    |                 |            2 |  128 |   16 | 0.0099341   |         |            |                      |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.31664 |     0.5262 |                    2 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_7be21_00008:
  accuracy: 0.5621
  date: 2021-02-17_18-48-41
  done: false
  experiment_id: 8bc8b883eb8e4a2b8460566f62205761
  experiment_tag: 8_batch_size=8,l1=64,l2=64,lr=0.0024148
  hostname: 09ee4e08461a
  iterations_since_restore: 3
  loss: 1.2378066100597382
  node_ip: 172.17.0.2
  pid: 1582
  should_checkpoint: true
  time_since_restore: 114.5751576423645
  time_this_iter_s: 34.94072103500366
  time_total_s: 114.5751576423645
  timestamp: 1613587721
  timesteps_since_restore: 0
  training_iteration: 3
  trial_id: 7be21_00008

Result for DEFAULT_7be21_00003:
  accuracy: 0.4887
  date: 2021-02-17_18-48-41
  done: false
  experiment_id: 4a196a9f207c408a8464941364bb63d4
  experiment_tag: 3_batch_size=8,l1=16,l2=8,lr=0.00088584
  hostname: 09ee4e08461a
  iterations_since_restore: 3
  loss: 1.4149478818893433
  node_ip: 172.17.0.2
  pid: 1535
  should_checkpoint: true
  time_since_restore: 114.98247051239014
  time_this_iter_s: 35.384515047073364
  time_total_s: 114.98247051239014
  timestamp: 1613587721
  timesteps_since_restore: 0
  training_iteration: 3
  trial_id: 7be21_00003

Result for DEFAULT_7be21_00002:
  accuracy: 0.5073
  date: 2021-02-17_18-48-42
  done: false
  experiment_id: 8451a29d824f4ad7ac5700e5d04714eb
  experiment_tag: 2_batch_size=8,l1=128,l2=16,lr=0.0053809
  hostname: 09ee4e08461a
  iterations_since_restore: 3
  loss: 1.4110955606460571
  node_ip: 172.17.0.2
  pid: 1555
  should_checkpoint: true
  time_since_restore: 115.90358996391296
  time_this_iter_s: 35.21477484703064
  time_total_s: 115.90358996391296
  timestamp: 1613587722
  timesteps_since_restore: 0
  training_iteration: 3
  trial_id: 7be21_00002

Result for DEFAULT_7be21_00001:
  accuracy: 0.1088
  date: 2021-02-17_18-48-42
  done: false
  experiment_id: 923357017bcd46d68a9ec9fe75ef1710
  experiment_tag: 1_batch_size=16,l1=8,l2=4,lr=0.01981
  hostname: 09ee4e08461a
  iterations_since_restore: 5
  loss: 2.2878596294403075
  node_ip: 172.17.0.2
  pid: 1581
  should_checkpoint: true
  time_since_restore: 115.95158052444458
  time_this_iter_s: 21.679677724838257
  time_total_s: 115.95158052444458
  timestamp: 1613587722
  timesteps_since_restore: 0
  training_iteration: 5
  trial_id: 7be21_00001

[2m[36m(pid=1533)[0m [2, 10000] loss: 0.277
[2m[36m(pid=1580)[0m [1, 20000] loss: 0.221
[2m[36m(pid=1571)[0m [4,  2000] loss: 1.254
[2m[36m(pid=1582)[0m [4,  2000] loss: 1.180
[2m[36m(pid=1535)[0m [4,  2000] loss: 1.348
[2m[36m(pid=1555)[0m [4,  2000] loss: 1.282
[2m[36m(pid=1581)[0m [6,  2000] loss: 2.293
Result for DEFAULT_7be21_00000:
  accuracy: 0.5078
  date: 2021-02-17_18-48-58
  done: false
  experiment_id: 80a26b352e064e7f957a91a561e55491
  experiment_tag: 0_batch_size=4,l1=32,l2=16,lr=0.0013426
  hostname: 09ee4e08461a
  iterations_since_restore: 2
  loss: 1.3827803031802177
  node_ip: 172.17.0.2
  pid: 1533
  should_checkpoint: true
  time_since_restore: 131.7500319480896
  time_this_iter_s: 60.82811164855957
  time_total_s: 131.7500319480896
  timestamp: 1613587738
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 7be21_00000

== Status ==
Memory usage on this node: 7.6/240.1 GiB
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: -2.4025123886108397 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.7425096386909484
Resources requested: 14/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.38278 |     0.5078 |                    2 |
| DEFAULT_7be21_00001 | RUNNING    | 172.17.0.2:1581 |           16 |    8 |    4 | 0.0198101   | 2.28786 |     0.1088 |                    5 |
| DEFAULT_7be21_00002 | RUNNING    | 172.17.0.2:1555 |            8 |  128 |   16 | 0.00538093  | 1.4111  |     0.5073 |                    3 |
| DEFAULT_7be21_00003 | RUNNING    | 172.17.0.2:1535 |            8 |   16 |    8 | 0.00088584  | 1.41495 |     0.4887 |                    3 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.25132 |     0.5539 |                    3 |
| DEFAULT_7be21_00007 | RUNNING    |                 |            2 |  128 |   16 | 0.0099341   |         |            |                      |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.23781 |     0.5621 |                    3 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_7be21_00001:
  accuracy: 0.099
  date: 2021-02-17_18-49-04
  done: false
  experiment_id: 923357017bcd46d68a9ec9fe75ef1710
  experiment_tag: 1_batch_size=16,l1=8,l2=4,lr=0.01981
  hostname: 09ee4e08461a
  iterations_since_restore: 6
  loss: 2.3086469886779786
  node_ip: 172.17.0.2
  pid: 1581
  should_checkpoint: true
  time_since_restore: 137.8556694984436
  time_this_iter_s: 21.904088973999023
  time_total_s: 137.8556694984436
  timestamp: 1613587744
  timesteps_since_restore: 0
  training_iteration: 6
  trial_id: 7be21_00001

== Status ==
Memory usage on this node: 7.6/240.1 GiB
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: -2.4025123886108397 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.7425096386909484
Resources requested: 14/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.38278 |     0.5078 |                    2 |
| DEFAULT_7be21_00001 | RUNNING    | 172.17.0.2:1581 |           16 |    8 |    4 | 0.0198101   | 2.30865 |     0.099  |                    6 |
| DEFAULT_7be21_00002 | RUNNING    | 172.17.0.2:1555 |            8 |  128 |   16 | 0.00538093  | 1.4111  |     0.5073 |                    3 |
| DEFAULT_7be21_00003 | RUNNING    | 172.17.0.2:1535 |            8 |   16 |    8 | 0.00088584  | 1.41495 |     0.4887 |                    3 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.25132 |     0.5539 |                    3 |
| DEFAULT_7be21_00007 | RUNNING    |                 |            2 |  128 |   16 | 0.0099341   |         |            |                      |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.23781 |     0.5621 |                    3 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_7be21_00007:
  accuracy: 0.1397
  date: 2021-02-17_18-49-05
  done: true
  experiment_id: 161f76b68baf497b9ab6daa8b2a4e00f
  experiment_tag: 7_batch_size=2,l1=128,l2=16,lr=0.0099341
  hostname: 09ee4e08461a
  iterations_since_restore: 1
  loss: 2.1891848682403565
  node_ip: 172.17.0.2
  pid: 1580
  should_checkpoint: true
  time_since_restore: 138.39315962791443
  time_this_iter_s: 138.39315962791443
  time_total_s: 138.39315962791443
  timestamp: 1613587745
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 7be21_00007

[2m[36m(pid=1571)[0m [4,  4000] loss: 0.623
[2m[36m(pid=1582)[0m [4,  4000] loss: 0.598
[2m[36m(pid=1535)[0m [4,  4000] loss: 0.660
[2m[36m(pid=1555)[0m [4,  4000] loss: 0.655
[2m[36m(pid=1533)[0m [3,  2000] loss: 1.327
Result for DEFAULT_7be21_00006:
  accuracy: 0.5374
  date: 2021-02-17_18-49-15
  done: false
  experiment_id: 6ce29aed25254bf0885e2d5d603c0bbd
  experiment_tag: 6_batch_size=8,l1=32,l2=16,lr=0.0019646
  hostname: 09ee4e08461a
  iterations_since_restore: 4
  loss: 1.3116867203712463
  node_ip: 172.17.0.2
  pid: 1571
  should_checkpoint: true
  time_since_restore: 148.64124870300293
  time_this_iter_s: 34.656991720199585
  time_total_s: 148.64124870300293
  timestamp: 1613587755
  timesteps_since_restore: 0
  training_iteration: 4
  trial_id: 7be21_00006

== Status ==
Memory usage on this node: 7.0/240.1 GiB
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 8.000: None | Iter 4.000: -1.8570995544910431 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.8019469243526458
Resources requested: 12/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.38278 |     0.5078 |                    2 |
| DEFAULT_7be21_00001 | RUNNING    | 172.17.0.2:1581 |           16 |    8 |    4 | 0.0198101   | 2.30865 |     0.099  |                    6 |
| DEFAULT_7be21_00002 | RUNNING    | 172.17.0.2:1555 |            8 |  128 |   16 | 0.00538093  | 1.4111  |     0.5073 |                    3 |
| DEFAULT_7be21_00003 | RUNNING    | 172.17.0.2:1535 |            8 |   16 |    8 | 0.00088584  | 1.41495 |     0.4887 |                    3 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.31169 |     0.5374 |                    4 |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.23781 |     0.5621 |                    3 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00007 | TERMINATED |                 |            2 |  128 |   16 | 0.0099341   | 2.18918 |     0.1397 |                    1 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_7be21_00008:
  accuracy: 0.5798
  date: 2021-02-17_18-49-16
  done: false
  experiment_id: 8bc8b883eb8e4a2b8460566f62205761
  experiment_tag: 8_batch_size=8,l1=64,l2=64,lr=0.0024148
  hostname: 09ee4e08461a
  iterations_since_restore: 4
  loss: 1.1852376123905182
  node_ip: 172.17.0.2
  pid: 1582
  should_checkpoint: true
  time_since_restore: 149.3761236667633
  time_this_iter_s: 34.800966024398804
  time_total_s: 149.3761236667633
  timestamp: 1613587756
  timesteps_since_restore: 0
  training_iteration: 4
  trial_id: 7be21_00008

Result for DEFAULT_7be21_00003:
  accuracy: 0.5117
  date: 2021-02-17_18-49-16
  done: true
  experiment_id: 4a196a9f207c408a8464941364bb63d4
  experiment_tag: 3_batch_size=8,l1=16,l2=8,lr=0.00088584
  hostname: 09ee4e08461a
  iterations_since_restore: 4
  loss: 1.3550899493694306
  node_ip: 172.17.0.2
  pid: 1535
  should_checkpoint: true
  time_since_restore: 149.69974207878113
  time_this_iter_s: 34.71727156639099
  time_total_s: 149.69974207878113
  timestamp: 1613587756
  timesteps_since_restore: 0
  training_iteration: 4
  trial_id: 7be21_00003

Result for DEFAULT_7be21_00002:
  accuracy: 0.5232
  date: 2021-02-17_18-49-17
  done: true
  experiment_id: 8451a29d824f4ad7ac5700e5d04714eb
  experiment_tag: 2_batch_size=8,l1=128,l2=16,lr=0.0053809
  hostname: 09ee4e08461a
  iterations_since_restore: 4
  loss: 1.367085778260231
  node_ip: 172.17.0.2
  pid: 1555
  should_checkpoint: true
  time_since_restore: 151.25951480865479
  time_this_iter_s: 35.35592484474182
  time_total_s: 151.25951480865479
  timestamp: 1613587757
  timesteps_since_restore: 0
  training_iteration: 4
  trial_id: 7be21_00002

[2m[36m(pid=1533)[0m [3,  4000] loss: 0.658
[2m[36m(pid=1581)[0m [7,  2000] loss: 2.305
Result for DEFAULT_7be21_00001:
  accuracy: 0.1043
  date: 2021-02-17_18-49-36
  done: false
  experiment_id: 923357017bcd46d68a9ec9fe75ef1710
  experiment_tag: 1_batch_size=16,l1=8,l2=4,lr=0.01981
  hostname: 09ee4e08461a
  iterations_since_restore: 7
  loss: 2.3066161052703857
  node_ip: 172.17.0.2
  pid: 1581
  should_checkpoint: true
  time_since_restore: 169.62418675422668
  time_this_iter_s: 31.76851725578308
  time_total_s: 169.62418675422668
  timestamp: 1613587776
  timesteps_since_restore: 0
  training_iteration: 7
  trial_id: 7be21_00001

== Status ==
Memory usage on this node: 5.9/240.1 GiB
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 8.000: None | Iter 4.000: -1.3550899493694306 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.8019469243526458
Resources requested: 8/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.38278 |     0.5078 |                    2 |
| DEFAULT_7be21_00001 | RUNNING    | 172.17.0.2:1581 |           16 |    8 |    4 | 0.0198101   | 2.30662 |     0.1043 |                    7 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.31169 |     0.5374 |                    4 |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.18524 |     0.5798 |                    4 |
| DEFAULT_7be21_00002 | TERMINATED |                 |            8 |  128 |   16 | 0.00538093  | 1.36709 |     0.5232 |                    4 |
| DEFAULT_7be21_00003 | TERMINATED |                 |            8 |   16 |    8 | 0.00088584  | 1.35509 |     0.5117 |                    4 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00007 | TERMINATED |                 |            2 |  128 |   16 | 0.0099341   | 2.18918 |     0.1397 |                    1 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1571)[0m [5,  2000] loss: 1.185
[2m[36m(pid=1582)[0m [5,  2000] loss: 1.101
[2m[36m(pid=1533)[0m [3,  6000] loss: 0.447
[2m[36m(pid=1571)[0m [5,  4000] loss: 0.606
[2m[36m(pid=1582)[0m [5,  4000] loss: 0.566
[2m[36m(pid=1533)[0m [3,  8000] loss: 0.335
[2m[36m(pid=1581)[0m [8,  2000] loss: 2.305
Result for DEFAULT_7be21_00001:
  accuracy: 0.103
  date: 2021-02-17_18-49-56
  done: false
  experiment_id: 923357017bcd46d68a9ec9fe75ef1710
  experiment_tag: 1_batch_size=16,l1=8,l2=4,lr=0.01981
  hostname: 09ee4e08461a
  iterations_since_restore: 8
  loss: 2.3058314392089843
  node_ip: 172.17.0.2
  pid: 1581
  should_checkpoint: true
  time_since_restore: 190.05587911605835
  time_this_iter_s: 20.431692361831665
  time_total_s: 190.05587911605835
  timestamp: 1613587796
  timesteps_since_restore: 0
  training_iteration: 8
  trial_id: 7be21_00001

== Status ==
Memory usage on this node: 5.9/240.1 GiB
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 8.000: -2.3058314392089843 | Iter 4.000: -1.3550899493694306 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.8019469243526458
Resources requested: 8/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.38278 |     0.5078 |                    2 |
| DEFAULT_7be21_00001 | RUNNING    | 172.17.0.2:1581 |           16 |    8 |    4 | 0.0198101   | 2.30583 |     0.103  |                    8 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.31169 |     0.5374 |                    4 |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.18524 |     0.5798 |                    4 |
| DEFAULT_7be21_00002 | TERMINATED |                 |            8 |  128 |   16 | 0.00538093  | 1.36709 |     0.5232 |                    4 |
| DEFAULT_7be21_00003 | TERMINATED |                 |            8 |   16 |    8 | 0.00088584  | 1.35509 |     0.5117 |                    4 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00007 | TERMINATED |                 |            2 |  128 |   16 | 0.0099341   | 2.18918 |     0.1397 |                    1 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_7be21_00006:
  accuracy: 0.556
  date: 2021-02-17_18-49-58
  done: false
  experiment_id: 6ce29aed25254bf0885e2d5d603c0bbd
  experiment_tag: 6_batch_size=8,l1=32,l2=16,lr=0.0019646
  hostname: 09ee4e08461a
  iterations_since_restore: 5
  loss: 1.2428726294517518
  node_ip: 172.17.0.2
  pid: 1571
  should_checkpoint: true
  time_since_restore: 192.12891674041748
  time_this_iter_s: 43.48766803741455
  time_total_s: 192.12891674041748
  timestamp: 1613587798
  timesteps_since_restore: 0
  training_iteration: 5
  trial_id: 7be21_00006

Result for DEFAULT_7be21_00008:
  accuracy: 0.5989
  date: 2021-02-17_18-49-59
  done: false
  experiment_id: 8bc8b883eb8e4a2b8460566f62205761
  experiment_tag: 8_batch_size=8,l1=64,l2=64,lr=0.0024148
  hostname: 09ee4e08461a
  iterations_since_restore: 5
  loss: 1.1510348963499069
  node_ip: 172.17.0.2
  pid: 1582
  should_checkpoint: true
  time_since_restore: 192.65134525299072
  time_this_iter_s: 43.27522158622742
  time_total_s: 192.65134525299072
  timestamp: 1613587799
  timesteps_since_restore: 0
  training_iteration: 5
  trial_id: 7be21_00008

[2m[36m(pid=1533)[0m [3, 10000] loss: 0.258
Result for DEFAULT_7be21_00000:
  accuracy: 0.4964
  date: 2021-02-17_18-50-06
  done: false
  experiment_id: 80a26b352e064e7f957a91a561e55491
  experiment_tag: 0_batch_size=4,l1=32,l2=16,lr=0.0013426
  hostname: 09ee4e08461a
  iterations_since_restore: 3
  loss: 1.4541935437485576
  node_ip: 172.17.0.2
  pid: 1533
  should_checkpoint: true
  time_since_restore: 199.6615240573883
  time_this_iter_s: 67.9114921092987
  time_total_s: 199.6615240573883
  timestamp: 1613587806
  timesteps_since_restore: 0
  training_iteration: 3
  trial_id: 7be21_00000

== Status ==
Memory usage on this node: 5.9/240.1 GiB
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 8.000: -2.3058314392089843 | Iter 4.000: -1.3550899493694306 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.8019469243526458
Resources requested: 8/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.45419 |     0.4964 |                    3 |
| DEFAULT_7be21_00001 | RUNNING    | 172.17.0.2:1581 |           16 |    8 |    4 | 0.0198101   | 2.30583 |     0.103  |                    8 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.24287 |     0.556  |                    5 |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.15103 |     0.5989 |                    5 |
| DEFAULT_7be21_00002 | TERMINATED |                 |            8 |  128 |   16 | 0.00538093  | 1.36709 |     0.5232 |                    4 |
| DEFAULT_7be21_00003 | TERMINATED |                 |            8 |   16 |    8 | 0.00088584  | 1.35509 |     0.5117 |                    4 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00007 | TERMINATED |                 |            2 |  128 |   16 | 0.0099341   | 2.18918 |     0.1397 |                    1 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1571)[0m [6,  2000] loss: 1.138
[2m[36m(pid=1581)[0m [9,  2000] loss: 2.305
[2m[36m(pid=1582)[0m [6,  2000] loss: 1.055
[2m[36m(pid=1533)[0m [4,  2000] loss: 1.249
Result for DEFAULT_7be21_00001:
  accuracy: 0.0998
  date: 2021-02-17_18-50-16
  done: false
  experiment_id: 923357017bcd46d68a9ec9fe75ef1710
  experiment_tag: 1_batch_size=16,l1=8,l2=4,lr=0.01981
  hostname: 09ee4e08461a
  iterations_since_restore: 9
  loss: 2.3044867069244384
  node_ip: 172.17.0.2
  pid: 1581
  should_checkpoint: true
  time_since_restore: 210.30883955955505
  time_this_iter_s: 20.252960443496704
  time_total_s: 210.30883955955505
  timestamp: 1613587816
  timesteps_since_restore: 0
  training_iteration: 9
  trial_id: 7be21_00001

== Status ==
Memory usage on this node: 5.9/240.1 GiB
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 8.000: -2.3058314392089843 | Iter 4.000: -1.3550899493694306 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.8019469243526458
Resources requested: 8/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.45419 |     0.4964 |                    3 |
| DEFAULT_7be21_00001 | RUNNING    | 172.17.0.2:1581 |           16 |    8 |    4 | 0.0198101   | 2.30449 |     0.0998 |                    9 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.24287 |     0.556  |                    5 |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.15103 |     0.5989 |                    5 |
| DEFAULT_7be21_00002 | TERMINATED |                 |            8 |  128 |   16 | 0.00538093  | 1.36709 |     0.5232 |                    4 |
| DEFAULT_7be21_00003 | TERMINATED |                 |            8 |   16 |    8 | 0.00088584  | 1.35509 |     0.5117 |                    4 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00007 | TERMINATED |                 |            2 |  128 |   16 | 0.0099341   | 2.18918 |     0.1397 |                    1 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1571)[0m [6,  4000] loss: 0.580
[2m[36m(pid=1582)[0m [6,  4000] loss: 0.542
[2m[36m(pid=1533)[0m [4,  4000] loss: 0.633
Result for DEFAULT_7be21_00006:
  accuracy: 0.5589
  date: 2021-02-17_18-50-31
  done: false
  experiment_id: 6ce29aed25254bf0885e2d5d603c0bbd
  experiment_tag: 6_batch_size=8,l1=32,l2=16,lr=0.0019646
  hostname: 09ee4e08461a
  iterations_since_restore: 6
  loss: 1.251379635155201
  node_ip: 172.17.0.2
  pid: 1571
  should_checkpoint: true
  time_since_restore: 224.3960976600647
  time_this_iter_s: 32.26718091964722
  time_total_s: 224.3960976600647
  timestamp: 1613587831
  timesteps_since_restore: 0
  training_iteration: 6
  trial_id: 7be21_00006

== Status ==
Memory usage on this node: 5.9/240.1 GiB
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 8.000: -2.3058314392089843 | Iter 4.000: -1.3550899493694306 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.8019469243526458
Resources requested: 8/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.45419 |     0.4964 |                    3 |
| DEFAULT_7be21_00001 | RUNNING    | 172.17.0.2:1581 |           16 |    8 |    4 | 0.0198101   | 2.30449 |     0.0998 |                    9 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.25138 |     0.5589 |                    6 |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.15103 |     0.5989 |                    5 |
| DEFAULT_7be21_00002 | TERMINATED |                 |            8 |  128 |   16 | 0.00538093  | 1.36709 |     0.5232 |                    4 |
| DEFAULT_7be21_00003 | TERMINATED |                 |            8 |   16 |    8 | 0.00088584  | 1.35509 |     0.5117 |                    4 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00007 | TERMINATED |                 |            2 |  128 |   16 | 0.0099341   | 2.18918 |     0.1397 |                    1 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1581)[0m [10,  2000] loss: 2.305
Result for DEFAULT_7be21_00008:
  accuracy: 0.5958
  date: 2021-02-17_18-50-32
  done: false
  experiment_id: 8bc8b883eb8e4a2b8460566f62205761
  experiment_tag: 8_batch_size=8,l1=64,l2=64,lr=0.0024148
  hostname: 09ee4e08461a
  iterations_since_restore: 6
  loss: 1.1730864935278893
  node_ip: 172.17.0.2
  pid: 1582
  should_checkpoint: true
  time_since_restore: 225.3908715248108
  time_this_iter_s: 32.73952627182007
  time_total_s: 225.3908715248108
  timestamp: 1613587832
  timesteps_since_restore: 0
  training_iteration: 6
  trial_id: 7be21_00008

[2m[36m(pid=1533)[0m [4,  6000] loss: 0.421
Result for DEFAULT_7be21_00001:
  accuracy: 0.099
  date: 2021-02-17_18-50-37
  done: true
  experiment_id: 923357017bcd46d68a9ec9fe75ef1710
  experiment_tag: 1_batch_size=16,l1=8,l2=4,lr=0.01981
  hostname: 09ee4e08461a
  iterations_since_restore: 10
  loss: 2.3048166904449463
  node_ip: 172.17.0.2
  pid: 1581
  should_checkpoint: true
  time_since_restore: 230.58842492103577
  time_this_iter_s: 20.279585361480713
  time_total_s: 230.58842492103577
  timestamp: 1613587837
  timesteps_since_restore: 0
  training_iteration: 10
  trial_id: 7be21_00001

== Status ==
Memory usage on this node: 5.9/240.1 GiB
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 8.000: -2.3058314392089843 | Iter 4.000: -1.3550899493694306 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.8019469243526458
Resources requested: 8/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.45419 |     0.4964 |                    3 |
| DEFAULT_7be21_00001 | RUNNING    | 172.17.0.2:1581 |           16 |    8 |    4 | 0.0198101   | 2.30482 |     0.099  |                   10 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.25138 |     0.5589 |                    6 |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.17309 |     0.5958 |                    6 |
| DEFAULT_7be21_00002 | TERMINATED |                 |            8 |  128 |   16 | 0.00538093  | 1.36709 |     0.5232 |                    4 |
| DEFAULT_7be21_00003 | TERMINATED |                 |            8 |   16 |    8 | 0.00088584  | 1.35509 |     0.5117 |                    4 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00007 | TERMINATED |                 |            2 |  128 |   16 | 0.0099341   | 2.18918 |     0.1397 |                    1 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1571)[0m [7,  2000] loss: 1.111
[2m[36m(pid=1582)[0m [7,  2000] loss: 1.006
[2m[36m(pid=1533)[0m [4,  8000] loss: 0.313
[2m[36m(pid=1571)[0m [7,  4000] loss: 0.569
[2m[36m(pid=1582)[0m [7,  4000] loss: 0.526
[2m[36m(pid=1533)[0m [4, 10000] loss: 0.253
Result for DEFAULT_7be21_00000:
  accuracy: 0.5443
  date: 2021-02-17_18-51-01
  done: false
  experiment_id: 80a26b352e064e7f957a91a561e55491
  experiment_tag: 0_batch_size=4,l1=32,l2=16,lr=0.0013426
  hostname: 09ee4e08461a
  iterations_since_restore: 4
  loss: 1.2831376832604409
  node_ip: 172.17.0.2
  pid: 1533
  should_checkpoint: true
  time_since_restore: 254.45360469818115
  time_this_iter_s: 54.79208064079285
  time_total_s: 254.45360469818115
  timestamp: 1613587861
  timesteps_since_restore: 0
  training_iteration: 4
  trial_id: 7be21_00000

== Status ==
Memory usage on this node: 5.3/240.1 GiB
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 8.000: -2.3058314392089843 | Iter 4.000: -1.3333883348703384 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.8019469243526458
Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.28314 |     0.5443 |                    4 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.25138 |     0.5589 |                    6 |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.17309 |     0.5958 |                    6 |
| DEFAULT_7be21_00001 | TERMINATED |                 |           16 |    8 |    4 | 0.0198101   | 2.30482 |     0.099  |                   10 |
| DEFAULT_7be21_00002 | TERMINATED |                 |            8 |  128 |   16 | 0.00538093  | 1.36709 |     0.5232 |                    4 |
| DEFAULT_7be21_00003 | TERMINATED |                 |            8 |   16 |    8 | 0.00088584  | 1.35509 |     0.5117 |                    4 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00007 | TERMINATED |                 |            2 |  128 |   16 | 0.0099341   | 2.18918 |     0.1397 |                    1 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_7be21_00006:
  accuracy: 0.5844
  date: 2021-02-17_18-51-02
  done: false
  experiment_id: 6ce29aed25254bf0885e2d5d603c0bbd
  experiment_tag: 6_batch_size=8,l1=32,l2=16,lr=0.0019646
  hostname: 09ee4e08461a
  iterations_since_restore: 7
  loss: 1.1835517253756522
  node_ip: 172.17.0.2
  pid: 1571
  should_checkpoint: true
  time_since_restore: 256.05893182754517
  time_this_iter_s: 31.66283416748047
  time_total_s: 256.05893182754517
  timestamp: 1613587862
  timesteps_since_restore: 0
  training_iteration: 7
  trial_id: 7be21_00006

Result for DEFAULT_7be21_00008:
  accuracy: 0.5818
  date: 2021-02-17_18-51-03
  done: false
  experiment_id: 8bc8b883eb8e4a2b8460566f62205761
  experiment_tag: 8_batch_size=8,l1=64,l2=64,lr=0.0024148
  hostname: 09ee4e08461a
  iterations_since_restore: 7
  loss: 1.215340897512436
  node_ip: 172.17.0.2
  pid: 1582
  should_checkpoint: true
  time_since_restore: 256.8210892677307
  time_this_iter_s: 31.430217742919922
  time_total_s: 256.8210892677307
  timestamp: 1613587863
  timesteps_since_restore: 0
  training_iteration: 7
  trial_id: 7be21_00008

[2m[36m(pid=1533)[0m [5,  2000] loss: 1.206
[2m[36m(pid=1571)[0m [8,  2000] loss: 1.082
[2m[36m(pid=1582)[0m [8,  2000] loss: 0.987
[2m[36m(pid=1533)[0m [5,  4000] loss: 0.603
[2m[36m(pid=1571)[0m [8,  4000] loss: 0.543
[2m[36m(pid=1582)[0m [8,  4000] loss: 0.507
[2m[36m(pid=1533)[0m [5,  6000] loss: 0.402
Result for DEFAULT_7be21_00006:
  accuracy: 0.5876
  date: 2021-02-17_18-51-33
  done: false
  experiment_id: 6ce29aed25254bf0885e2d5d603c0bbd
  experiment_tag: 6_batch_size=8,l1=32,l2=16,lr=0.0019646
  hostname: 09ee4e08461a
  iterations_since_restore: 8
  loss: 1.1699074127078057
  node_ip: 172.17.0.2
  pid: 1571
  should_checkpoint: true
  time_since_restore: 287.22612833976746
  time_this_iter_s: 31.16719651222229
  time_total_s: 287.22612833976746
  timestamp: 1613587893
  timesteps_since_restore: 0
  training_iteration: 8
  trial_id: 7be21_00006

== Status ==
Memory usage on this node: 5.3/240.1 GiB
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 8.000: -1.737869425958395 | Iter 4.000: -1.3333883348703384 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.8019469243526458
Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.28314 |     0.5443 |                    4 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.16991 |     0.5876 |                    8 |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.21534 |     0.5818 |                    7 |
| DEFAULT_7be21_00001 | TERMINATED |                 |           16 |    8 |    4 | 0.0198101   | 2.30482 |     0.099  |                   10 |
| DEFAULT_7be21_00002 | TERMINATED |                 |            8 |  128 |   16 | 0.00538093  | 1.36709 |     0.5232 |                    4 |
| DEFAULT_7be21_00003 | TERMINATED |                 |            8 |   16 |    8 | 0.00088584  | 1.35509 |     0.5117 |                    4 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00007 | TERMINATED |                 |            2 |  128 |   16 | 0.0099341   | 2.18918 |     0.1397 |                    1 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_7be21_00008:
  accuracy: 0.6042
  date: 2021-02-17_18-51-35
  done: false
  experiment_id: 8bc8b883eb8e4a2b8460566f62205761
  experiment_tag: 8_batch_size=8,l1=64,l2=64,lr=0.0024148
  hostname: 09ee4e08461a
  iterations_since_restore: 8
  loss: 1.1309769105672836
  node_ip: 172.17.0.2
  pid: 1582
  should_checkpoint: true
  time_since_restore: 288.41531348228455
  time_this_iter_s: 31.594224214553833
  time_total_s: 288.41531348228455
  timestamp: 1613587895
  timesteps_since_restore: 0
  training_iteration: 8
  trial_id: 7be21_00008

[2m[36m(pid=1533)[0m [5,  8000] loss: 0.308
[2m[36m(pid=1571)[0m [9,  2000] loss: 1.053
[2m[36m(pid=1582)[0m [9,  2000] loss: 0.940
[2m[36m(pid=1533)[0m [5, 10000] loss: 0.246
Result for DEFAULT_7be21_00000:
  accuracy: 0.5498
  date: 2021-02-17_18-51-55
  done: false
  experiment_id: 80a26b352e064e7f957a91a561e55491
  experiment_tag: 0_batch_size=4,l1=32,l2=16,lr=0.0013426
  hostname: 09ee4e08461a
  iterations_since_restore: 5
  loss: 1.2787905728697777
  node_ip: 172.17.0.2
  pid: 1533
  should_checkpoint: true
  time_since_restore: 308.7496280670166
  time_this_iter_s: 54.29602336883545
  time_total_s: 308.7496280670166
  timestamp: 1613587915
  timesteps_since_restore: 0
  training_iteration: 5
  trial_id: 7be21_00000

== Status ==
Memory usage on this node: 5.3/240.1 GiB
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 8.000: -1.1699074127078057 | Iter 4.000: -1.3333883348703384 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.8019469243526458
Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.27879 |     0.5498 |                    5 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.16991 |     0.5876 |                    8 |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.13098 |     0.6042 |                    8 |
| DEFAULT_7be21_00001 | TERMINATED |                 |           16 |    8 |    4 | 0.0198101   | 2.30482 |     0.099  |                   10 |
| DEFAULT_7be21_00002 | TERMINATED |                 |            8 |  128 |   16 | 0.00538093  | 1.36709 |     0.5232 |                    4 |
| DEFAULT_7be21_00003 | TERMINATED |                 |            8 |   16 |    8 | 0.00088584  | 1.35509 |     0.5117 |                    4 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00007 | TERMINATED |                 |            2 |  128 |   16 | 0.0099341   | 2.18918 |     0.1397 |                    1 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1571)[0m [9,  4000] loss: 0.537
[2m[36m(pid=1582)[0m [9,  4000] loss: 0.495
[2m[36m(pid=1533)[0m [6,  2000] loss: 1.175
Result for DEFAULT_7be21_00006:
  accuracy: 0.6018
  date: 2021-02-17_18-52-05
  done: false
  experiment_id: 6ce29aed25254bf0885e2d5d603c0bbd
  experiment_tag: 6_batch_size=8,l1=32,l2=16,lr=0.0019646
  hostname: 09ee4e08461a
  iterations_since_restore: 9
  loss: 1.1338432680010795
  node_ip: 172.17.0.2
  pid: 1571
  should_checkpoint: true
  time_since_restore: 318.8576364517212
  time_this_iter_s: 31.631508111953735
  time_total_s: 318.8576364517212
  timestamp: 1613587925
  timesteps_since_restore: 0
  training_iteration: 9
  trial_id: 7be21_00006

== Status ==
Memory usage on this node: 5.3/240.1 GiB
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 8.000: -1.1699074127078057 | Iter 4.000: -1.3333883348703384 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.8019469243526458
Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.27879 |     0.5498 |                    5 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.13384 |     0.6018 |                    9 |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.13098 |     0.6042 |                    8 |
| DEFAULT_7be21_00001 | TERMINATED |                 |           16 |    8 |    4 | 0.0198101   | 2.30482 |     0.099  |                   10 |
| DEFAULT_7be21_00002 | TERMINATED |                 |            8 |  128 |   16 | 0.00538093  | 1.36709 |     0.5232 |                    4 |
| DEFAULT_7be21_00003 | TERMINATED |                 |            8 |   16 |    8 | 0.00088584  | 1.35509 |     0.5117 |                    4 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00007 | TERMINATED |                 |            2 |  128 |   16 | 0.0099341   | 2.18918 |     0.1397 |                    1 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_7be21_00008:
  accuracy: 0.601
  date: 2021-02-17_18-52-06
  done: false
  experiment_id: 8bc8b883eb8e4a2b8460566f62205761
  experiment_tag: 8_batch_size=8,l1=64,l2=64,lr=0.0024148
  hostname: 09ee4e08461a
  iterations_since_restore: 9
  loss: 1.1546772684335709
  node_ip: 172.17.0.2
  pid: 1582
  should_checkpoint: true
  time_since_restore: 320.06180453300476
  time_this_iter_s: 31.646491050720215
  time_total_s: 320.06180453300476
  timestamp: 1613587926
  timesteps_since_restore: 0
  training_iteration: 9
  trial_id: 7be21_00008

[2m[36m(pid=1533)[0m [6,  4000] loss: 0.583
[2m[36m(pid=1571)[0m [10,  2000] loss: 1.034
[2m[36m(pid=1582)[0m [10,  2000] loss: 0.933
[2m[36m(pid=1533)[0m [6,  6000] loss: 0.395
[2m[36m(pid=1571)[0m [10,  4000] loss: 0.527
[2m[36m(pid=1582)[0m [10,  4000] loss: 0.476
[2m[36m(pid=1533)[0m [6,  8000] loss: 0.300
Result for DEFAULT_7be21_00006:
  accuracy: 0.5711
  date: 2021-02-17_18-52-36
  done: true
  experiment_id: 6ce29aed25254bf0885e2d5d603c0bbd
  experiment_tag: 6_batch_size=8,l1=32,l2=16,lr=0.0019646
  hostname: 09ee4e08461a
  iterations_since_restore: 10
  loss: 1.228988034081459
  node_ip: 172.17.0.2
  pid: 1571
  should_checkpoint: true
  time_since_restore: 350.2420482635498
  time_this_iter_s: 31.384411811828613
  time_total_s: 350.2420482635498
  timestamp: 1613587956
  timesteps_since_restore: 0
  training_iteration: 10
  trial_id: 7be21_00006

== Status ==
Memory usage on this node: 5.3/240.1 GiB
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 8.000: -1.1699074127078057 | Iter 4.000: -1.3333883348703384 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.8019469243526458
Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.27879 |     0.5498 |                    5 |
| DEFAULT_7be21_00006 | RUNNING    | 172.17.0.2:1571 |            8 |   32 |   16 | 0.00196461  | 1.22899 |     0.5711 |                   10 |
| DEFAULT_7be21_00008 | RUNNING    | 172.17.0.2:1582 |            8 |   64 |   64 | 0.00241479  | 1.15468 |     0.601  |                    9 |
| DEFAULT_7be21_00001 | TERMINATED |                 |           16 |    8 |    4 | 0.0198101   | 2.30482 |     0.099  |                   10 |
| DEFAULT_7be21_00002 | TERMINATED |                 |            8 |  128 |   16 | 0.00538093  | 1.36709 |     0.5232 |                    4 |
| DEFAULT_7be21_00003 | TERMINATED |                 |            8 |   16 |    8 | 0.00088584  | 1.35509 |     0.5117 |                    4 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00007 | TERMINATED |                 |            2 |  128 |   16 | 0.0099341   | 2.18918 |     0.1397 |                    1 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_7be21_00008:
  accuracy: 0.6069
  date: 2021-02-17_18-52-38
  done: true
  experiment_id: 8bc8b883eb8e4a2b8460566f62205761
  experiment_tag: 8_batch_size=8,l1=64,l2=64,lr=0.0024148
  hostname: 09ee4e08461a
  iterations_since_restore: 10
  loss: 1.1548725825995207
  node_ip: 172.17.0.2
  pid: 1582
  should_checkpoint: true
  time_since_restore: 351.4130525588989
  time_this_iter_s: 31.351248025894165
  time_total_s: 351.4130525588989
  timestamp: 1613587958
  timesteps_since_restore: 0
  training_iteration: 10
  trial_id: 7be21_00008

[2m[36m(pid=1533)[0m [6, 10000] loss: 0.232
Result for DEFAULT_7be21_00000:
  accuracy: 0.5767
  date: 2021-02-17_18-52-49
  done: false
  experiment_id: 80a26b352e064e7f957a91a561e55491
  experiment_tag: 0_batch_size=4,l1=32,l2=16,lr=0.0013426
  hostname: 09ee4e08461a
  iterations_since_restore: 6
  loss: 1.2108140528798104
  node_ip: 172.17.0.2
  pid: 1533
  should_checkpoint: true
  time_since_restore: 362.80767726898193
  time_this_iter_s: 54.05804920196533
  time_total_s: 362.80767726898193
  timestamp: 1613587969
  timesteps_since_restore: 0
  training_iteration: 6
  trial_id: 7be21_00000

== Status ==
Memory usage on this node: 4.2/240.1 GiB
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.1699074127078057 | Iter 4.000: -1.3333883348703384 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.8019469243526458
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.21081 |     0.5767 |                    6 |
| DEFAULT_7be21_00001 | TERMINATED |                 |           16 |    8 |    4 | 0.0198101   | 2.30482 |     0.099  |                   10 |
| DEFAULT_7be21_00002 | TERMINATED |                 |            8 |  128 |   16 | 0.00538093  | 1.36709 |     0.5232 |                    4 |
| DEFAULT_7be21_00003 | TERMINATED |                 |            8 |   16 |    8 | 0.00088584  | 1.35509 |     0.5117 |                    4 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00006 | TERMINATED |                 |            8 |   32 |   16 | 0.00196461  | 1.22899 |     0.5711 |                   10 |
| DEFAULT_7be21_00007 | TERMINATED |                 |            2 |  128 |   16 | 0.0099341   | 2.18918 |     0.1397 |                    1 |
| DEFAULT_7be21_00008 | TERMINATED |                 |            8 |   64 |   64 | 0.00241479  | 1.15487 |     0.6069 |                   10 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1533)[0m [7,  2000] loss: 1.139
[2m[36m(pid=1533)[0m [7,  4000] loss: 0.572
[2m[36m(pid=1533)[0m [7,  6000] loss: 0.384
[2m[36m(pid=1533)[0m [7,  8000] loss: 0.289
[2m[36m(pid=1533)[0m [7, 10000] loss: 0.233
Result for DEFAULT_7be21_00000:
  accuracy: 0.5625
  date: 2021-02-17_18-53-41
  done: false
  experiment_id: 80a26b352e064e7f957a91a561e55491
  experiment_tag: 0_batch_size=4,l1=32,l2=16,lr=0.0013426
  hostname: 09ee4e08461a
  iterations_since_restore: 7
  loss: 1.2550442327551543
  node_ip: 172.17.0.2
  pid: 1533
  should_checkpoint: true
  time_since_restore: 414.76299834251404
  time_this_iter_s: 51.955321073532104
  time_total_s: 414.76299834251404
  timestamp: 1613588021
  timesteps_since_restore: 0
  training_iteration: 7
  trial_id: 7be21_00000

== Status ==
Memory usage on this node: 4.1/240.1 GiB
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.1699074127078057 | Iter 4.000: -1.3333883348703384 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.8019469243526458
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.25504 |     0.5625 |                    7 |
| DEFAULT_7be21_00001 | TERMINATED |                 |           16 |    8 |    4 | 0.0198101   | 2.30482 |     0.099  |                   10 |
| DEFAULT_7be21_00002 | TERMINATED |                 |            8 |  128 |   16 | 0.00538093  | 1.36709 |     0.5232 |                    4 |
| DEFAULT_7be21_00003 | TERMINATED |                 |            8 |   16 |    8 | 0.00088584  | 1.35509 |     0.5117 |                    4 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00006 | TERMINATED |                 |            8 |   32 |   16 | 0.00196461  | 1.22899 |     0.5711 |                   10 |
| DEFAULT_7be21_00007 | TERMINATED |                 |            2 |  128 |   16 | 0.0099341   | 2.18918 |     0.1397 |                    1 |
| DEFAULT_7be21_00008 | TERMINATED |                 |            8 |   64 |   64 | 0.00241479  | 1.15487 |     0.6069 |                   10 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1533)[0m [8,  2000] loss: 1.120
[2m[36m(pid=1533)[0m [8,  4000] loss: 0.548
[2m[36m(pid=1533)[0m [8,  6000] loss: 0.376
[2m[36m(pid=1533)[0m [8,  8000] loss: 0.287
[2m[36m(pid=1533)[0m [8, 10000] loss: 0.230
Result for DEFAULT_7be21_00000:
  accuracy: 0.5851
  date: 2021-02-17_18-54-33
  done: true
  experiment_id: 80a26b352e064e7f957a91a561e55491
  experiment_tag: 0_batch_size=4,l1=32,l2=16,lr=0.0013426
  hostname: 09ee4e08461a
  iterations_since_restore: 8
  loss: 1.2036002240523695
  node_ip: 172.17.0.2
  pid: 1533
  should_checkpoint: true
  time_since_restore: 466.8815176486969
  time_this_iter_s: 52.11851930618286
  time_total_s: 466.8815176486969
  timestamp: 1613588073
  timesteps_since_restore: 0
  training_iteration: 8
  trial_id: 7be21_00000

== Status ==
Memory usage on this node: 4.1/240.1 GiB
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 8.000: -1.1867538183800876 | Iter 4.000: -1.3333883348703384 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.8019469243526458
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | RUNNING    | 172.17.0.2:1533 |            4 |   32 |   16 | 0.00134258  | 1.2036  |     0.5851 |                    8 |
| DEFAULT_7be21_00001 | TERMINATED |                 |           16 |    8 |    4 | 0.0198101   | 2.30482 |     0.099  |                   10 |
| DEFAULT_7be21_00002 | TERMINATED |                 |            8 |  128 |   16 | 0.00538093  | 1.36709 |     0.5232 |                    4 |
| DEFAULT_7be21_00003 | TERMINATED |                 |            8 |   16 |    8 | 0.00088584  | 1.35509 |     0.5117 |                    4 |
| DEFAULT_7be21_00004 | TERMINATED |                 |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |                 |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00006 | TERMINATED |                 |            8 |   32 |   16 | 0.00196461  | 1.22899 |     0.5711 |                   10 |
| DEFAULT_7be21_00007 | TERMINATED |                 |            2 |  128 |   16 | 0.0099341   | 2.18918 |     0.1397 |                    1 |
| DEFAULT_7be21_00008 | TERMINATED |                 |            8 |   64 |   64 | 0.00241479  | 1.15487 |     0.6069 |                   10 |
| DEFAULT_7be21_00009 | TERMINATED |                 |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


== Status ==
Memory usage on this node: 3.9/240.1 GiB
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 8.000: -1.1867538183800876 | Iter 4.000: -1.3333883348703384 | Iter 2.000: -1.4372519857645034 | Iter 1.000: -1.8019469243526458
Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-17_18-46-45
Number of trials: 10/10 (10 TERMINATED)
+---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc   |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_7be21_00000 | TERMINATED |       |            4 |   32 |   16 | 0.00134258  | 1.2036  |     0.5851 |                    8 |
| DEFAULT_7be21_00001 | TERMINATED |       |           16 |    8 |    4 | 0.0198101   | 2.30482 |     0.099  |                   10 |
| DEFAULT_7be21_00002 | TERMINATED |       |            8 |  128 |   16 | 0.00538093  | 1.36709 |     0.5232 |                    4 |
| DEFAULT_7be21_00003 | TERMINATED |       |            8 |   16 |    8 | 0.00088584  | 1.35509 |     0.5117 |                    4 |
| DEFAULT_7be21_00004 | TERMINATED |       |           16 |  256 |   32 | 0.000269525 | 2.30008 |     0.0995 |                    1 |
| DEFAULT_7be21_00005 | TERMINATED |       |            4 |   16 |    4 | 0.000221824 | 2.01442 |     0.2069 |                    1 |
| DEFAULT_7be21_00006 | TERMINATED |       |            8 |   32 |   16 | 0.00196461  | 1.22899 |     0.5711 |                   10 |
| DEFAULT_7be21_00007 | TERMINATED |       |            2 |  128 |   16 | 0.0099341   | 2.18918 |     0.1397 |                    1 |
| DEFAULT_7be21_00008 | TERMINATED |       |            8 |   64 |   64 | 0.00241479  | 1.15487 |     0.6069 |                   10 |
| DEFAULT_7be21_00009 | TERMINATED |       |            8 |    8 |    8 | 0.0125789   | 2.22777 |     0.1514 |                    2 |
+---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+


Best trial config: {'l1': 64, 'l2': 64, 'lr': 0.0024147888609189283, 'batch_size': 8}
Best trial final validation loss: 1.1548725825995207
Best trial final validation accuracy: 0.6069
Files already downloaded and verified
Files already downloaded and verified
Best trial test set accuracy: 0.6022
</pre></div>
</div>
<p>If you run the code, an example output could look like this:</p>
<p>Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 58%, which could
be confirmed on the test set.</p>
<p>So that’s it! You can now tune the parameters of your PyTorch models.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 8 minutes  7.159 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-beginner-hyperparameter-tuning-tutorial-py">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/95074cd7ce8c3e57a92e7a9c49182e6a/hyperparameter_tuning_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">hyperparameter_tuning_tutorial.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/c24b93738bc036c1b66d0387555bf69a/hyperparameter_tuning_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">hyperparameter_tuning_tutorial.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</article>
</div>
<footer>
<div aria-label="footer navigation" class="rst-footer-buttons" role="navigation">
<a accesskey="n" class="btn btn-neutral float-right" href="../intermediate/pruning_tutorial.html" rel="next" title="Pruning Tutorial">Next <img class="next-page" src="../_static/images/chevron-right-orange.svg"/></a>
<a accesskey="p" class="btn btn-neutral" href="profiler.html" rel="prev" title="Profiling your PyTorch Module"><img class="previous-page" src="../_static/images/chevron-right-orange.svg"/> Previous</a>
</div>
<hr class="rating-hr hr-top"/>
<div class="rating-container">
<div class="rating-prompt">Rate this Tutorial</div>
<div class="stars-outer">
<i class="far fa-star" data-behavior="tutorial-rating" data-count="1" title="1 Star"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="2" title="2 Stars"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="3" title="3 Stars"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="4" title="4 Stars"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="5" title="5 Stars"></i>
</div>
</div>
<hr class="rating-hr hr-bottom"/>
<div role="contentinfo">
<p>
        © Copyright 2017, PyTorch.

    </p>
</div>
<div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
</footer>
</div>
</div>
<div class="pytorch-content-right" id="pytorch-content-right">
<div class="pytorch-right-menu" id="pytorch-right-menu">
<div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
<ul>
<li><a class="reference internal" href="#">Hyperparameter tuning with Ray Tune</a><ul>
<li><a class="reference internal" href="#setup-imports">Setup / Imports</a></li>
<li><a class="reference internal" href="#data-loaders">Data loaders</a></li>
<li><a class="reference internal" href="#configurable-neural-network">Configurable neural network</a></li>
<li><a class="reference internal" href="#the-train-function">The train function</a><ul>
<li><a class="reference internal" href="#adding-multi-gpu-support-with-dataparallel">Adding (multi) GPU support with DataParallel</a></li>
<li><a class="reference internal" href="#communicating-with-ray-tune">Communicating with Ray Tune</a></li>
<li><a class="reference internal" href="#full-training-function">Full training function</a></li>
</ul>
</li>
<li><a class="reference internal" href="#test-set-accuracy">Test set accuracy</a></li>
<li><a class="reference internal" href="#configuring-the-search-space">Configuring the search space</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</section>
</div>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js" type="text/javascript"></script>
<script src="../_static/jquery.js" type="text/javascript"></script>
<script src="../_static/underscore.js" type="text/javascript"></script>
<script src="../_static/doctools.js" type="text/javascript"></script>
<script src="../_static/clipboard.min.js" type="text/javascript"></script>
<script src="../_static/copybutton.js" type="text/javascript"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script src="../_static/js/vendor/popper.min.js" type="text/javascript"></script>
<script src="../_static/js/vendor/bootstrap.min.js" type="text/javascript"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
<script>

  window.dataLayer = window.dataLayer || [];

  function gtag(){dataLayer.push(arguments);}

  gtag('js', new Date());
  gtag('config', 'UA-117752657-2');

</script>
<script>
  !function(f,b,e,v,n,t,s)
  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
  n.queue=[];t=b.createElement(e);t.async=!0;
  t.src=v;s=b.getElementsByTagName(e)[0];
  s.parentNode.insertBefore(t,s)}(window,document,'script',
  'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');

  $("[data-behavior='call-to-action-event']").on('click', function(){
    fbq('trackCustom', "Download", {
      tutorialTitle: $('h1:first').text(),
      downloadLink: this.href,
      tutorialLink: window.location.href,
      downloadTitle: $(this).attr("data-response")
    });
    ga('send', {
      hitType: 'event',
      eventCategory: $(this).attr("data-response"),
      eventAction: 'click',
      eventLabel: window.location.href
    });

    gtag('event', 'click', {
      'event_category': $(this).attr("data-response"),
      'event_label': $("h1").first().text(),
      'tutorial_link': window.location.href
    });
   });

   $("[data-behavior='tutorial-rating']").on('click', function(){
    fbq('trackCustom', "Tutorial Rating", {
      tutorialLink: window.location.href,
      tutorialTitle: $('h1:first').text(),
      rating: $(this).attr("data-count")
    });

    gtag('event', 'click', {
      'event_category': 'Tutorial Rating',
      'event_label': $("h1").first().text(),
      'value': $(this).attr("data-count")
    });
   });

   if (location.pathname == "/") {
     $(".rating-container").hide();
     $(".hr-bottom").hide();
   }
</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView
  &amp;noscript=1" width="1"/>
</noscript>
<img alt="" height="1" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0" style="border-style:none;" width="1"/>
<!-- Begin Footer -->
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4 text-center">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4 text-center">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4 text-center">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="footer-logo-wrapper">
<a class="footer-logo" href="https://pytorch.org/"></a>
</div>
<div class="footer-links-wrapper">
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
<li><a href="https://pytorch.org/get-started">Get Started</a></li>
<li><a href="https://pytorch.org/features">Features</a></li>
<li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
<li><a href="https://pytorch.org/blog/">Blog</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
<li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
<li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
<li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
<li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
<li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
</ul>
</div>
<div class="footer-links-col follow-us-col">
<ul>
<li class="list-title">Stay Connected</li>
<li>
<div id="mc_embed_signup">
<form action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&amp;id=91d0dccd39" class="email-subscribe-form validate" id="mc-embedded-subscribe-form" method="post" name="mc-embedded-subscribe-form" novalidate="" target="_blank">
<div class="email-subscribe-form-fields-wrapper" id="mc_embed_signup_scroll">
<div class="mc-field-group">
<label for="mce-EMAIL" style="display:none;">Email Address</label>
<input class="required email" id="mce-EMAIL" name="EMAIL" placeholder="Email Address" type="email" value=""/>
</div>
<div class="clear" id="mce-responses">
<div class="response" id="mce-error-response" style="display:none"></div>
<div class="response" id="mce-success-response" style="display:none"></div>
</div> <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
<div aria-hidden="true" style="position: absolute; left: -5000px;"><input name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" type="text" value=""/></div>
<div class="clear">
<input class="button email-subscribe-button" id="mc-embedded-subscribe" name="subscribe" type="submit" value=""/>
</div>
</div>
</form>
</div>
</li>
</ul>
<div class="footer-social-icons">
<a class="facebook" href="https://www.facebook.com/pytorch" target="_blank"></a>
<a class="twitter" href="https://twitter.com/pytorch" target="_blank"></a>
<a class="youtube" href="https://www.youtube.com/pytorch" target="_blank"></a>
</div>
</div>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../_static/images/pytorch-x.svg">
</img></div>
</div>
<!-- End Footer -->
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="container">
<div class="mobile-main-menu-header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#"></a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/ecosystem">Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/mobile">Mobile</a>
</li>
<li>
<a href="https://pytorch.org/hub">PyTorch Hub</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li class="resources-mobile-menu-title">
            Docs
          </li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
</li>
<li>
<a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
</li>
<li>
<a href="https://pytorch.org/text/stable/index.html">torchtext</a>
</li>
<li>
<a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
</li>
<li>
<a href="https://pytorch.org/elastic/">TorchElastic</a>
</li>
<li>
<a href="https://pytorch.org/serve/">TorchServe</a>
</li>
<li>
<a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
            Resources
          </li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/resources">Developer Resources</a>
</li>
<li>
<a href="https://pytorch.org/features">About</a>
</li>
<li>
<a href="https://pytorch.org/hub">Models (Beta)</a>
</li>
<li>
<a href="https://pytorch.org/#community-module">Community</a>
</li>
<li>
<a href="https://discuss.pytorch.org/">Forums</a>
</li>
</ul>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<script src="../_static/js/vendor/anchor.min.js" type="text/javascript"></script>
<script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>