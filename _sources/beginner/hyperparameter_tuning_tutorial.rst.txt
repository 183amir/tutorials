.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_hyperparameter_tuning_tutorial.py:


Hyperparameter tuning with Ray Tune
===================================

Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.

Fortunately, there are tools that help with finding the best combination of parameters.
`Ray Tune <https://docs.ray.io/en/latest/tune.html>`_ is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through `Ray's distributed machine learning engine
<https://ray.io/>`_.

In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend `this tutorial from the PyTorch documentation
<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ for training
a CIFAR10 image classifier.

As you will see, we only need to add some slight modifications. In particular, we
need to

1. wrap data loading and training in functions,
2. make some network parameters configurable,
3. add checkpointing (optional),
4. and define the search space for the model tuning

|

To run this tutorial, please make sure the following packages are
installed:

-  ``ray[tune]``: Distributed hyperparameter tuning library
-  ``torchvision``: For the data transformers

Setup / Imports
---------------
Let's start with the imports:


.. code-block:: default

    from functools import partial
    import numpy as np
    import os
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import random_split
    import torchvision
    import torchvision.transforms as transforms
    from ray import tune
    from ray.tune import CLIReporter
    from ray.tune.schedulers import ASHAScheduler







Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.

Data loaders
------------
We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.


.. code-block:: default



    def load_data(data_dir="./data"):
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])

        trainset = torchvision.datasets.CIFAR10(
            root=data_dir, train=True, download=True, transform=transform)

        testset = torchvision.datasets.CIFAR10(
            root=data_dir, train=False, download=True, transform=transform)

        return trainset, testset







Configurable neural network
---------------------------
We can only tune those parameters that are configurable. In this example, we can specify
the layer sizes of the fully connected layers:


.. code-block:: default



    class Net(nn.Module):
        def __init__(self, l1=120, l2=84):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5)
            self.pool = nn.MaxPool2d(2, 2)
            self.conv2 = nn.Conv2d(6, 16, 5)
            self.fc1 = nn.Linear(16 * 5 * 5, l1)
            self.fc2 = nn.Linear(l1, l2)
            self.fc3 = nn.Linear(l2, 10)

        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = x.view(-1, 16 * 5 * 5)
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x







The train function
------------------
Now it gets interesting, because we introduce some changes to the example `from the PyTorch
documentation <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_.

We wrap the training script in a function ``train_cifar(config, checkpoint_dir=None, data_dir=None)``.
As you can guess, the ``config`` parameter will receive the hyperparameters we would like to
train with. The ``checkpoint_dir`` parameter is used to restore checkpoints. The ``data_dir`` specifies
the directory where we load and store the data, so multiple runs can share the same data source.

.. code-block:: python

    net = Net(config["l1"], config["l2"])

    if checkpoint_dir:
        model_state, optimizer_state = torch.load(
            os.path.join(checkpoint_dir, "checkpoint"))
        net.load_state_dict(model_state)
        optimizer.load_state_dict(optimizer_state)

The learning rate of the optimizer is made configurable, too:

.. code-block:: python

    optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.

Adding (multi) GPU support with DataParallel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch's abstractions in Ray Tune. Thus, we can wrap our model in ``nn.DataParallel``
to support data parallel training on multiple GPUs:

.. code-block:: python

    device = "cpu"
    if torch.cuda.is_available():
        device = "cuda:0"
        if torch.cuda.device_count() > 1:
            net = nn.DataParallel(net)
    net.to(device)

By using a ``device`` variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:

.. code-block:: python

    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports `fractional GPUs <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We'll come back
to that later.

Communicating with Ray Tune
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The most interesting part is the communication with Ray Tune:

.. code-block:: python

    with tune.checkpoint_dir(epoch) as checkpoint_dir:
        path = os.path.join(checkpoint_dir, "checkpoint")
        torch.save((net.state_dict(), optimizer.state_dict()), path)

    tune.report(loss=(val_loss / val_steps), accuracy=correct / total)

Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.

The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
`Population Based Training <https://docs.ray.io/en/master/tune/tutorials/tune-advanced-tutorial.html>`_.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set.

Full training function
~~~~~~~~~~~~~~~~~~~~~~

The full code example looks like this:


.. code-block:: default



    def train_cifar(config, checkpoint_dir=None, data_dir=None):
        net = Net(config["l1"], config["l2"])

        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if torch.cuda.device_count() > 1:
                net = nn.DataParallel(net)
        net.to(device)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

        if checkpoint_dir:
            model_state, optimizer_state = torch.load(
                os.path.join(checkpoint_dir, "checkpoint"))
            net.load_state_dict(model_state)
            optimizer.load_state_dict(optimizer_state)

        trainset, testset = load_data(data_dir)

        test_abs = int(len(trainset) * 0.8)
        train_subset, val_subset = random_split(
            trainset, [test_abs, len(trainset) - test_abs])

        trainloader = torch.utils.data.DataLoader(
            train_subset,
            batch_size=int(config["batch_size"]),
            shuffle=True,
            num_workers=8)
        valloader = torch.utils.data.DataLoader(
            val_subset,
            batch_size=int(config["batch_size"]),
            shuffle=True,
            num_workers=8)

        for epoch in range(10):  # loop over the dataset multiple times
            running_loss = 0.0
            epoch_steps = 0
            for i, data in enumerate(trainloader, 0):
                # get the inputs; data is a list of [inputs, labels]
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward + backward + optimize
                outputs = net(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                # print statistics
                running_loss += loss.item()
                epoch_steps += 1
                if i % 2000 == 1999:  # print every 2000 mini-batches
                    print("[%d, %5d] loss: %.3f" % (epoch + 1, i + 1,
                                                    running_loss / epoch_steps))
                    running_loss = 0.0

            # Validation loss
            val_loss = 0.0
            val_steps = 0
            total = 0
            correct = 0
            for i, data in enumerate(valloader, 0):
                with torch.no_grad():
                    inputs, labels = data
                    inputs, labels = inputs.to(device), labels.to(device)

                    outputs = net(inputs)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                    loss = criterion(outputs, labels)
                    val_loss += loss.cpu().numpy()
                    val_steps += 1

            with tune.checkpoint_dir(epoch) as checkpoint_dir:
                path = os.path.join(checkpoint_dir, "checkpoint")
                torch.save((net.state_dict(), optimizer.state_dict()), path)

            tune.report(loss=(val_loss / val_steps), accuracy=correct / total)
        print("Finished Training")







As you can see, most of the code is adapted directly from the original example.

Test set accuracy
-----------------
Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:


.. code-block:: default



    def test_accuracy(net, device="cpu"):
        trainset, testset = load_data()

        testloader = torch.utils.data.DataLoader(
            testset, batch_size=4, shuffle=False, num_workers=2)

        correct = 0
        total = 0
        with torch.no_grad():
            for data in testloader:
                images, labels = data
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return correct / total







The function also expects a ``device`` parameter, so we can do the
test set validation on a GPU.

Configuring the search space
----------------------------
Lastly, we need to define Ray Tune's search space. Here is an example:

.. code-block:: python

    config = {
        "l1": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),
        "l2": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16])
    }

The ``tune.sample_from()`` function makes it possible to define your own sample
methods to obtain hyperparameters. In this example, the ``l1`` and ``l2`` parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.

At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the ``ASHAScheduler`` which will terminate bad
performing trials early.

We wrap the ``train_cifar`` function with ``functools.partial`` to set the constant
``data_dir`` parameter. We can also tell Ray Tune what resources should be
available for each trial:

.. code-block:: python

    gpus_per_trial = 2
    # ...
    result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 8, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
        progress_reporter=reporter,
        checkpoint_at_end=True)

You can specify the number of CPUs, which are then available e.g.
to increase the ``num_workers`` of the PyTorch ``DataLoader`` instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven't been requested for them - so you don't have to care about two trials
using the same set of resources.

Here we can also specify fractional GPUs, so something like ``gpus_per_trial=0.5`` is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.

After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.

The full main function looks like this:


.. code-block:: default



    def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):
        data_dir = os.path.abspath("./data")
        load_data(data_dir)
        config = {
            "l1": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
            "l2": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
            "lr": tune.loguniform(1e-4, 1e-1),
            "batch_size": tune.choice([2, 4, 8, 16])
        }
        scheduler = ASHAScheduler(
            metric="loss",
            mode="min",
            max_t=max_num_epochs,
            grace_period=1,
            reduction_factor=2)
        reporter = CLIReporter(
            # parameter_columns=["l1", "l2", "lr", "batch_size"],
            metric_columns=["loss", "accuracy", "training_iteration"])
        result = tune.run(
            partial(train_cifar, data_dir=data_dir),
            resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
            config=config,
            num_samples=num_samples,
            scheduler=scheduler,
            progress_reporter=reporter)

        best_trial = result.get_best_trial("loss", "min", "last")
        print("Best trial config: {}".format(best_trial.config))
        print("Best trial final validation loss: {}".format(
            best_trial.last_result["loss"]))
        print("Best trial final validation accuracy: {}".format(
            best_trial.last_result["accuracy"]))

        best_trained_model = Net(best_trial.config["l1"], best_trial.config["l2"])
        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if gpus_per_trial > 1:
                best_trained_model = nn.DataParallel(best_trained_model)
        best_trained_model.to(device)

        best_checkpoint_dir = best_trial.checkpoint.value
        model_state, optimizer_state = torch.load(os.path.join(
            best_checkpoint_dir, "checkpoint"))
        best_trained_model.load_state_dict(model_state)

        test_acc = test_accuracy(best_trained_model, device)
        print("Best trial test set accuracy: {}".format(test_acc))


    if __name__ == "__main__":
        # You can change the number of GPUs per trial here:
        main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz
    Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
    Files already downloaded and verified
    == Status ==
    Memory usage on this node: 4.0/240.1 GiB
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 1/10 (1 RUNNING)
    +---------------------+----------+-------+--------------+------+------+----------+
    | Trial name          | status   | loc   |   batch_size |   l1 |   l2 |       lr |
    |---------------------+----------+-------+--------------+------+------+----------|
    | DEFAULT_daa35_00000 | RUNNING  |       |            2 |  256 |   64 | 0.053996 |
    +---------------------+----------+-------+--------------+------+------+----------+


    [2m[36m(pid=1484)[0m Files already downloaded and verified
    [2m[36m(pid=1556)[0m Files already downloaded and verified
    [2m[36m(pid=1511)[0m Files already downloaded and verified
    [2m[36m(pid=1555)[0m Files already downloaded and verified
    [2m[36m(pid=1546)[0m Files already downloaded and verified
    [2m[36m(pid=1543)[0m Files already downloaded and verified
    [2m[36m(pid=1564)[0m Files already downloaded and verified
    [2m[36m(pid=1538)[0m Files already downloaded and verified
    [2m[36m(pid=1495)[0m Files already downloaded and verified
    [2m[36m(pid=1490)[0m Files already downloaded and verified
    [2m[36m(pid=1484)[0m Files already downloaded and verified
    [2m[36m(pid=1556)[0m Files already downloaded and verified
    [2m[36m(pid=1511)[0m Files already downloaded and verified
    [2m[36m(pid=1555)[0m Files already downloaded and verified
    [2m[36m(pid=1546)[0m Files already downloaded and verified
    [2m[36m(pid=1543)[0m Files already downloaded and verified
    [2m[36m(pid=1538)[0m Files already downloaded and verified
    [2m[36m(pid=1495)[0m Files already downloaded and verified
    [2m[36m(pid=1564)[0m Files already downloaded and verified
    [2m[36m(pid=1490)[0m Files already downloaded and verified
    [2m[36m(pid=1556)[0m [1,  2000] loss: 2.268
    [2m[36m(pid=1555)[0m [1,  2000] loss: 2.307
    [2m[36m(pid=1546)[0m [1,  2000] loss: 2.219
    [2m[36m(pid=1495)[0m [1,  2000] loss: 2.297
    [2m[36m(pid=1484)[0m [1,  2000] loss: 2.367
    [2m[36m(pid=1538)[0m [1,  2000] loss: 2.328
    [2m[36m(pid=1564)[0m [1,  2000] loss: 2.070
    [2m[36m(pid=1511)[0m [1,  2000] loss: 1.991
    [2m[36m(pid=1490)[0m [1,  2000] loss: 2.315
    [2m[36m(pid=1543)[0m [1,  2000] loss: 2.328
    [2m[36m(pid=1556)[0m [1,  4000] loss: 1.040
    [2m[36m(pid=1555)[0m [1,  4000] loss: 1.151
    Result for DEFAULT_daa35_00008:
      accuracy: 0.4069
      date: 2021-02-08_14-35-41
      done: false
      experiment_id: 842021ed6bba45edae73eda2ded9fb4b
      experiment_tag: 8_batch_size=16,l1=16,l2=8,lr=0.0027677
      hostname: 9acb6dd638d6
      iterations_since_restore: 1
      loss: 1.5890211484909058
      node_ip: 172.17.0.2
      pid: 1511
      should_checkpoint: true
      time_since_restore: 27.139898777008057
      time_this_iter_s: 27.139898777008057
      time_total_s: 27.139898777008057
      timestamp: 1612794941
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: daa35_00008
  
    == Status ==
    Memory usage on this node: 9.3/240.1 GiB
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.5890211484909058
    Resources requested: 20/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (10 RUNNING)
    +---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status   | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00000 | RUNNING  |                 |            2 |  256 |   64 | 0.053996    |         |            |                      |
    | DEFAULT_daa35_00001 | RUNNING  |                 |           16 |  256 |    4 | 0.000119345 |         |            |                      |
    | DEFAULT_daa35_00002 | RUNNING  |                 |            2 |   16 |   16 | 0.000114956 |         |            |                      |
    | DEFAULT_daa35_00003 | RUNNING  |                 |            2 |  256 |  128 | 0.00931199  |         |            |                      |
    | DEFAULT_daa35_00004 | RUNNING  |                 |            8 |  256 |   32 | 0.0207814   |         |            |                      |
    | DEFAULT_daa35_00005 | RUNNING  |                 |            4 |  256 |  256 | 0.000306556 |         |            |                      |
    | DEFAULT_daa35_00006 | RUNNING  |                 |            4 |  256 |    8 | 0.0492039   |         |            |                      |
    | DEFAULT_daa35_00007 | RUNNING  |                 |            2 |   32 |    4 | 0.00393992  |         |            |                      |
    | DEFAULT_daa35_00008 | RUNNING  | 172.17.0.2:1511 |           16 |   16 |    8 | 0.00276771  | 1.58902 |     0.4069 |                    1 |
    | DEFAULT_daa35_00009 | RUNNING  |                 |           16 |    8 |    8 | 0.00010222  |         |            |                      |
    +---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_daa35_00009:
      accuracy: 0.1044
      date: 2021-02-08_14-35-42
      done: true
      experiment_id: e274d6993c70417eb7d64c373c1b2f53
      experiment_tag: 9_batch_size=16,l1=8,l2=8,lr=0.00010222
      hostname: 9acb6dd638d6
      iterations_since_restore: 1
      loss: 2.3104214611053466
      node_ip: 172.17.0.2
      pid: 1490
      should_checkpoint: true
      time_since_restore: 27.85047698020935
      time_this_iter_s: 27.85047698020935
      time_total_s: 27.85047698020935
      timestamp: 1612794942
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: daa35_00009
  
    Result for DEFAULT_daa35_00001:
      accuracy: 0.0976
      date: 2021-02-08_14-35-43
      done: true
      experiment_id: 27763341b9f744129761d4ecd290206c
      experiment_tag: 1_batch_size=16,l1=256,l2=4,lr=0.00011934
      hostname: 9acb6dd638d6
      iterations_since_restore: 1
      loss: 2.3189205924987792
      node_ip: 172.17.0.2
      pid: 1543
      should_checkpoint: true
      time_since_restore: 28.996987104415894
      time_this_iter_s: 28.996987104415894
      time_total_s: 28.996987104415894
      timestamp: 1612794943
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: daa35_00001
  
    [2m[36m(pid=1495)[0m [1,  4000] loss: 1.092
    [2m[36m(pid=1546)[0m [1,  4000] loss: 1.081
    [2m[36m(pid=1484)[0m [1,  4000] loss: 1.179
    [2m[36m(pid=1564)[0m [1,  4000] loss: 1.001
    [2m[36m(pid=1538)[0m [1,  4000] loss: 1.165
    [2m[36m(pid=1556)[0m [1,  6000] loss: 0.678
    [2m[36m(pid=1555)[0m [1,  6000] loss: 0.763
    [2m[36m(pid=1511)[0m [2,  2000] loss: 1.533
    [2m[36m(pid=1495)[0m [1,  6000] loss: 0.640
    Result for DEFAULT_daa35_00004:
      accuracy: 0.2425
      date: 2021-02-08_14-35-59
      done: false
      experiment_id: 9c284fc7246c429cb72e3902c4279d9f
      experiment_tag: 4_batch_size=8,l1=256,l2=32,lr=0.020781
      hostname: 9acb6dd638d6
      iterations_since_restore: 1
      loss: 2.0063673469543457
      node_ip: 172.17.0.2
      pid: 1564
      should_checkpoint: true
      time_since_restore: 44.371326208114624
      time_this_iter_s: 44.371326208114624
      time_total_s: 44.371326208114624
      timestamp: 1612794959
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: daa35_00004
  
    == Status ==
    Memory usage on this node: 8.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1583944040298464
    Resources requested: 16/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00000 | RUNNING    |                 |            2 |  256 |   64 | 0.053996    |         |            |                      |
    | DEFAULT_daa35_00002 | RUNNING    |                 |            2 |   16 |   16 | 0.000114956 |         |            |                      |
    | DEFAULT_daa35_00003 | RUNNING    |                 |            2 |  256 |  128 | 0.00931199  |         |            |                      |
    | DEFAULT_daa35_00004 | RUNNING    | 172.17.0.2:1564 |            8 |  256 |   32 | 0.0207814   | 2.00637 |     0.2425 |                    1 |
    | DEFAULT_daa35_00005 | RUNNING    |                 |            4 |  256 |  256 | 0.000306556 |         |            |                      |
    | DEFAULT_daa35_00006 | RUNNING    |                 |            4 |  256 |    8 | 0.0492039   |         |            |                      |
    | DEFAULT_daa35_00007 | RUNNING    |                 |            2 |   32 |    4 | 0.00393992  |         |            |                      |
    | DEFAULT_daa35_00008 | RUNNING    | 172.17.0.2:1511 |           16 |   16 |    8 | 0.00276771  | 1.58902 |     0.4069 |                    1 |
    | DEFAULT_daa35_00001 | TERMINATED |                 |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00009 | TERMINATED |                 |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1546)[0m [1,  6000] loss: 0.712
    [2m[36m(pid=1484)[0m [1,  6000] loss: 0.788
    [2m[36m(pid=1555)[0m [1,  8000] loss: 0.562
    [2m[36m(pid=1556)[0m [1,  8000] loss: 0.505
    [2m[36m(pid=1538)[0m [1,  6000] loss: 0.776
    Result for DEFAULT_daa35_00008:
      accuracy: 0.486
      date: 2021-02-08_14-36-04
      done: false
      experiment_id: 842021ed6bba45edae73eda2ded9fb4b
      experiment_tag: 8_batch_size=16,l1=16,l2=8,lr=0.0027677
      hostname: 9acb6dd638d6
      iterations_since_restore: 2
      loss: 1.4035974509239197
      node_ip: 172.17.0.2
      pid: 1511
      should_checkpoint: true
      time_since_restore: 49.36026382446289
      time_this_iter_s: 22.220365047454834
      time_total_s: 49.36026382446289
      timestamp: 1612794964
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: daa35_00008
  
    [2m[36m(pid=1495)[0m [1,  8000] loss: 0.450
    [2m[36m(pid=1555)[0m [1, 10000] loss: 0.440
    [2m[36m(pid=1556)[0m [1, 10000] loss: 0.402
    [2m[36m(pid=1546)[0m [1,  8000] loss: 0.534
    [2m[36m(pid=1564)[0m [2,  2000] loss: 2.013
    [2m[36m(pid=1484)[0m [1,  8000] loss: 0.592
    [2m[36m(pid=1538)[0m [1,  8000] loss: 0.582
    [2m[36m(pid=1511)[0m [3,  2000] loss: 1.391
    [2m[36m(pid=1555)[0m [1, 12000] loss: 0.356
    [2m[36m(pid=1556)[0m [1, 12000] loss: 0.329
    [2m[36m(pid=1495)[0m [1, 10000] loss: 0.340
    Result for DEFAULT_daa35_00008:
      accuracy: 0.4956
      date: 2021-02-08_14-36-25
      done: false
      experiment_id: 842021ed6bba45edae73eda2ded9fb4b
      experiment_tag: 8_batch_size=16,l1=16,l2=8,lr=0.0027677
      hostname: 9acb6dd638d6
      iterations_since_restore: 3
      loss: 1.36775298538208
      node_ip: 172.17.0.2
      pid: 1511
      should_checkpoint: true
      time_since_restore: 71.17022728919983
      time_this_iter_s: 21.80996346473694
      time_total_s: 71.17022728919983
      timestamp: 1612794985
      timesteps_since_restore: 0
      training_iteration: 3
      trial_id: daa35_00008
  
    == Status ==
    Memory usage on this node: 8.2/240.1 GiB
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.4035974509239197 | Iter 1.000: -2.1583944040298464
    Resources requested: 16/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00000 | RUNNING    |                 |            2 |  256 |   64 | 0.053996    |         |            |                      |
    | DEFAULT_daa35_00002 | RUNNING    |                 |            2 |   16 |   16 | 0.000114956 |         |            |                      |
    | DEFAULT_daa35_00003 | RUNNING    |                 |            2 |  256 |  128 | 0.00931199  |         |            |                      |
    | DEFAULT_daa35_00004 | RUNNING    | 172.17.0.2:1564 |            8 |  256 |   32 | 0.0207814   | 2.00637 |     0.2425 |                    1 |
    | DEFAULT_daa35_00005 | RUNNING    |                 |            4 |  256 |  256 | 0.000306556 |         |            |                      |
    | DEFAULT_daa35_00006 | RUNNING    |                 |            4 |  256 |    8 | 0.0492039   |         |            |                      |
    | DEFAULT_daa35_00007 | RUNNING    |                 |            2 |   32 |    4 | 0.00393992  |         |            |                      |
    | DEFAULT_daa35_00008 | RUNNING    | 172.17.0.2:1511 |           16 |   16 |    8 | 0.00276771  | 1.36775 |     0.4956 |                    3 |
    | DEFAULT_daa35_00001 | TERMINATED |                 |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00009 | TERMINATED |                 |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1546)[0m [1, 10000] loss: 0.432
    [2m[36m(pid=1564)[0m [2,  4000] loss: 1.019
    [2m[36m(pid=1484)[0m [1, 10000] loss: 0.473
    Result for DEFAULT_daa35_00005:
      accuracy: 0.3891
      date: 2021-02-08_14-36-29
      done: false
      experiment_id: 36e73eaba6aa4df88b517cf3a856daf6
      experiment_tag: 5_batch_size=4,l1=256,l2=256,lr=0.00030656
      hostname: 9acb6dd638d6
      iterations_since_restore: 1
      loss: 1.6527884335279466
      node_ip: 172.17.0.2
      pid: 1495
      should_checkpoint: true
      time_since_restore: 74.71373987197876
      time_this_iter_s: 74.71373987197876
      time_total_s: 74.71373987197876
      timestamp: 1612794989
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: daa35_00005
  
    [2m[36m(pid=1538)[0m [1, 10000] loss: 0.466
    [2m[36m(pid=1555)[0m [1, 14000] loss: 0.292
    [2m[36m(pid=1556)[0m [1, 14000] loss: 0.282
    Result for DEFAULT_daa35_00006:
      accuracy: 0.0959
      date: 2021-02-08_14-36-37
      done: true
      experiment_id: 12ff94fc20754be5bb3acf2f7d540df0
      experiment_tag: 6_batch_size=4,l1=256,l2=8,lr=0.049204
      hostname: 9acb6dd638d6
      iterations_since_restore: 1
      loss: 2.3253649652957917
      node_ip: 172.17.0.2
      pid: 1538
      should_checkpoint: true
      time_since_restore: 82.8699598312378
      time_this_iter_s: 82.8699598312378
      time_total_s: 82.8699598312378
      timestamp: 1612794997
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: daa35_00006
  
    == Status ==
    Memory usage on this node: 8.2/240.1 GiB
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.4035974509239197 | Iter 1.000: -2.1583944040298464
    Resources requested: 16/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00000 | RUNNING    |                 |            2 |  256 |   64 | 0.053996    |         |            |                      |
    | DEFAULT_daa35_00002 | RUNNING    |                 |            2 |   16 |   16 | 0.000114956 |         |            |                      |
    | DEFAULT_daa35_00003 | RUNNING    |                 |            2 |  256 |  128 | 0.00931199  |         |            |                      |
    | DEFAULT_daa35_00004 | RUNNING    | 172.17.0.2:1564 |            8 |  256 |   32 | 0.0207814   | 2.00637 |     0.2425 |                    1 |
    | DEFAULT_daa35_00005 | RUNNING    | 172.17.0.2:1495 |            4 |  256 |  256 | 0.000306556 | 1.65279 |     0.3891 |                    1 |
    | DEFAULT_daa35_00006 | RUNNING    | 172.17.0.2:1538 |            4 |  256 |    8 | 0.0492039   | 2.32536 |     0.0959 |                    1 |
    | DEFAULT_daa35_00007 | RUNNING    |                 |            2 |   32 |    4 | 0.00393992  |         |            |                      |
    | DEFAULT_daa35_00008 | RUNNING    | 172.17.0.2:1511 |           16 |   16 |    8 | 0.00276771  | 1.36775 |     0.4956 |                    3 |
    | DEFAULT_daa35_00001 | TERMINATED |                 |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00009 | TERMINATED |                 |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_daa35_00004:
      accuracy: 0.1627
      date: 2021-02-08_14-36-39
      done: true
      experiment_id: 9c284fc7246c429cb72e3902c4279d9f
      experiment_tag: 4_batch_size=8,l1=256,l2=32,lr=0.020781
      hostname: 9acb6dd638d6
      iterations_since_restore: 2
      loss: 2.0920752392768858
      node_ip: 172.17.0.2
      pid: 1564
      should_checkpoint: true
      time_since_restore: 84.76765251159668
      time_this_iter_s: 40.396326303482056
      time_total_s: 84.76765251159668
      timestamp: 1612794999
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: daa35_00004
  
    [2m[36m(pid=1555)[0m [1, 16000] loss: 0.245
    [2m[36m(pid=1546)[0m [1, 12000] loss: 0.371
    [2m[36m(pid=1511)[0m [4,  2000] loss: 1.308
    [2m[36m(pid=1556)[0m [1, 16000] loss: 0.249
    [2m[36m(pid=1495)[0m [2,  2000] loss: 1.650
    [2m[36m(pid=1484)[0m [1, 12000] loss: 0.394
    Result for DEFAULT_daa35_00008:
      accuracy: 0.505
      date: 2021-02-08_14-36-47
      done: false
      experiment_id: 842021ed6bba45edae73eda2ded9fb4b
      experiment_tag: 8_batch_size=16,l1=16,l2=8,lr=0.0027677
      hostname: 9acb6dd638d6
      iterations_since_restore: 4
      loss: 1.3489532001495361
      node_ip: 172.17.0.2
      pid: 1511
      should_checkpoint: true
      time_since_restore: 92.96185731887817
      time_this_iter_s: 21.791630029678345
      time_total_s: 92.96185731887817
      timestamp: 1612795007
      timesteps_since_restore: 0
      training_iteration: 4
      trial_id: daa35_00008
  
    == Status ==
    Memory usage on this node: 7.0/240.1 GiB
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: -1.3489532001495361 | Iter 2.000: -1.7478363451004029 | Iter 1.000: -2.1583944040298464
    Resources requested: 12/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00000 | RUNNING    |                 |            2 |  256 |   64 | 0.053996    |         |            |                      |
    | DEFAULT_daa35_00002 | RUNNING    |                 |            2 |   16 |   16 | 0.000114956 |         |            |                      |
    | DEFAULT_daa35_00003 | RUNNING    |                 |            2 |  256 |  128 | 0.00931199  |         |            |                      |
    | DEFAULT_daa35_00005 | RUNNING    | 172.17.0.2:1495 |            4 |  256 |  256 | 0.000306556 | 1.65279 |     0.3891 |                    1 |
    | DEFAULT_daa35_00007 | RUNNING    |                 |            2 |   32 |    4 | 0.00393992  |         |            |                      |
    | DEFAULT_daa35_00008 | RUNNING    | 172.17.0.2:1511 |           16 |   16 |    8 | 0.00276771  | 1.34895 |     0.505  |                    4 |
    | DEFAULT_daa35_00001 | TERMINATED |                 |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00004 | TERMINATED |                 |            8 |  256 |   32 | 0.0207814   | 2.09208 |     0.1627 |                    2 |
    | DEFAULT_daa35_00006 | TERMINATED |                 |            4 |  256 |    8 | 0.0492039   | 2.32536 |     0.0959 |                    1 |
    | DEFAULT_daa35_00009 | TERMINATED |                 |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1555)[0m [1, 18000] loss: 0.211
    [2m[36m(pid=1556)[0m [1, 18000] loss: 0.222
    [2m[36m(pid=1495)[0m [2,  4000] loss: 0.796
    [2m[36m(pid=1546)[0m [1, 14000] loss: 0.331
    [2m[36m(pid=1484)[0m [1, 14000] loss: 0.338
    [2m[36m(pid=1555)[0m [1, 20000] loss: 0.185
    [2m[36m(pid=1556)[0m [1, 20000] loss: 0.201
    [2m[36m(pid=1511)[0m [5,  2000] loss: 1.257
    [2m[36m(pid=1495)[0m [2,  6000] loss: 0.519
    Result for DEFAULT_daa35_00008:
      accuracy: 0.5583
      date: 2021-02-08_14-37-08
      done: false
      experiment_id: 842021ed6bba45edae73eda2ded9fb4b
      experiment_tag: 8_batch_size=16,l1=16,l2=8,lr=0.0027677
      hostname: 9acb6dd638d6
      iterations_since_restore: 5
      loss: 1.255533707714081
      node_ip: 172.17.0.2
      pid: 1511
      should_checkpoint: true
      time_since_restore: 113.85328817367554
      time_this_iter_s: 20.891430854797363
      time_total_s: 113.85328817367554
      timestamp: 1612795028
      timesteps_since_restore: 0
      training_iteration: 5
      trial_id: daa35_00008
  
    == Status ==
    Memory usage on this node: 7.0/240.1 GiB
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: -1.3489532001495361 | Iter 2.000: -1.7478363451004029 | Iter 1.000: -2.1583944040298464
    Resources requested: 12/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00000 | RUNNING    |                 |            2 |  256 |   64 | 0.053996    |         |            |                      |
    | DEFAULT_daa35_00002 | RUNNING    |                 |            2 |   16 |   16 | 0.000114956 |         |            |                      |
    | DEFAULT_daa35_00003 | RUNNING    |                 |            2 |  256 |  128 | 0.00931199  |         |            |                      |
    | DEFAULT_daa35_00005 | RUNNING    | 172.17.0.2:1495 |            4 |  256 |  256 | 0.000306556 | 1.65279 |     0.3891 |                    1 |
    | DEFAULT_daa35_00007 | RUNNING    |                 |            2 |   32 |    4 | 0.00393992  |         |            |                      |
    | DEFAULT_daa35_00008 | RUNNING    | 172.17.0.2:1511 |           16 |   16 |    8 | 0.00276771  | 1.25553 |     0.5583 |                    5 |
    | DEFAULT_daa35_00001 | TERMINATED |                 |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00004 | TERMINATED |                 |            8 |  256 |   32 | 0.0207814   | 2.09208 |     0.1627 |                    2 |
    | DEFAULT_daa35_00006 | TERMINATED |                 |            4 |  256 |    8 | 0.0492039   | 2.32536 |     0.0959 |                    1 |
    | DEFAULT_daa35_00009 | TERMINATED |                 |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1484)[0m [1, 16000] loss: 0.295
    [2m[36m(pid=1546)[0m [1, 16000] loss: 0.289
    Result for DEFAULT_daa35_00002:
      accuracy: 0.3376
      date: 2021-02-08_14-37-11
      done: false
      experiment_id: b6381b8643ce4fdab9b627f02aaee85c
      experiment_tag: 2_batch_size=2,l1=16,l2=16,lr=0.00011496
      hostname: 9acb6dd638d6
      iterations_since_restore: 1
      loss: 1.8106758074045182
      node_ip: 172.17.0.2
      pid: 1555
      should_checkpoint: true
      time_since_restore: 116.81745624542236
      time_this_iter_s: 116.81745624542236
      time_total_s: 116.81745624542236
      timestamp: 1612795031
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: daa35_00002
  
    Result for DEFAULT_daa35_00007:
      accuracy: 0.2061
      date: 2021-02-08_14-37-13
      done: true
      experiment_id: f612c777c78b44c1b140fc8fb4859912
      experiment_tag: 7_batch_size=2,l1=32,l2=4,lr=0.0039399
      hostname: 9acb6dd638d6
      iterations_since_restore: 1
      loss: 2.3125601183861493
      node_ip: 172.17.0.2
      pid: 1556
      should_checkpoint: true
      time_since_restore: 118.81180834770203
      time_this_iter_s: 118.81180834770203
      time_total_s: 118.81180834770203
      timestamp: 1612795033
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: daa35_00007
  
    [2m[36m(pid=1495)[0m [2,  8000] loss: 0.375
    [2m[36m(pid=1555)[0m [2,  2000] loss: 1.818
    [2m[36m(pid=1484)[0m [1, 18000] loss: 0.262
    [2m[36m(pid=1546)[0m [1, 18000] loss: 0.257
    [2m[36m(pid=1511)[0m [6,  2000] loss: 1.217
    [2m[36m(pid=1495)[0m [2, 10000] loss: 0.293
    Result for DEFAULT_daa35_00008:
      accuracy: 0.5593
      date: 2021-02-08_14-37-29
      done: false
      experiment_id: 842021ed6bba45edae73eda2ded9fb4b
      experiment_tag: 8_batch_size=16,l1=16,l2=8,lr=0.0027677
      hostname: 9acb6dd638d6
      iterations_since_restore: 6
      loss: 1.2212017738342285
      node_ip: 172.17.0.2
      pid: 1511
      should_checkpoint: true
      time_since_restore: 134.64682841300964
      time_this_iter_s: 20.793540239334106
      time_total_s: 134.64682841300964
      timestamp: 1612795049
      timesteps_since_restore: 0
      training_iteration: 6
      trial_id: daa35_00008
  
    == Status ==
    Memory usage on this node: 6.5/240.1 GiB
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: -1.3489532001495361 | Iter 2.000: -1.7478363451004029 | Iter 1.000: -2.1583944040298464
    Resources requested: 10/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00000 | RUNNING    |                 |            2 |  256 |   64 | 0.053996    |         |            |                      |
    | DEFAULT_daa35_00002 | RUNNING    | 172.17.0.2:1555 |            2 |   16 |   16 | 0.000114956 | 1.81068 |     0.3376 |                    1 |
    | DEFAULT_daa35_00003 | RUNNING    |                 |            2 |  256 |  128 | 0.00931199  |         |            |                      |
    | DEFAULT_daa35_00005 | RUNNING    | 172.17.0.2:1495 |            4 |  256 |  256 | 0.000306556 | 1.65279 |     0.3891 |                    1 |
    | DEFAULT_daa35_00008 | RUNNING    | 172.17.0.2:1511 |           16 |   16 |    8 | 0.00276771  | 1.2212  |     0.5593 |                    6 |
    | DEFAULT_daa35_00001 | TERMINATED |                 |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00004 | TERMINATED |                 |            8 |  256 |   32 | 0.0207814   | 2.09208 |     0.1627 |                    2 |
    | DEFAULT_daa35_00006 | TERMINATED |                 |            4 |  256 |    8 | 0.0492039   | 2.32536 |     0.0959 |                    1 |
    | DEFAULT_daa35_00007 | TERMINATED |                 |            2 |   32 |    4 | 0.00393992  | 2.31256 |     0.2061 |                    1 |
    | DEFAULT_daa35_00009 | TERMINATED |                 |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1555)[0m [2,  4000] loss: 0.884
    Result for DEFAULT_daa35_00005:
      accuracy: 0.4686
      date: 2021-02-08_14-37-33
      done: false
      experiment_id: 36e73eaba6aa4df88b517cf3a856daf6
      experiment_tag: 5_batch_size=4,l1=256,l2=256,lr=0.00030656
      hostname: 9acb6dd638d6
      iterations_since_restore: 2
      loss: 1.475889776134491
      node_ip: 172.17.0.2
      pid: 1495
      should_checkpoint: true
      time_since_restore: 138.37652039527893
      time_this_iter_s: 63.66278052330017
      time_total_s: 138.37652039527893
      timestamp: 1612795053
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: daa35_00005
  
    [2m[36m(pid=1484)[0m [1, 20000] loss: 0.237
    [2m[36m(pid=1546)[0m [1, 20000] loss: 0.232
    [2m[36m(pid=1555)[0m [2,  6000] loss: 0.564
    [2m[36m(pid=1511)[0m [7,  2000] loss: 1.181
    [2m[36m(pid=1495)[0m [3,  2000] loss: 1.423
    [2m[36m(pid=1555)[0m [2,  8000] loss: 0.421
    Result for DEFAULT_daa35_00000:
      accuracy: 0.0983
      date: 2021-02-08_14-37-47
      done: true
      experiment_id: 50b9cd16553a4ee9a11e84e439e47f7c
      experiment_tag: 0_batch_size=2,l1=256,l2=64,lr=0.053996
      hostname: 9acb6dd638d6
      iterations_since_restore: 1
      loss: 2.3717188648223875
      node_ip: 172.17.0.2
      pid: 1484
      should_checkpoint: true
      time_since_restore: 153.1735599040985
      time_this_iter_s: 153.1735599040985
      time_total_s: 153.1735599040985
      timestamp: 1612795067
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: daa35_00000
  
    == Status ==
    Memory usage on this node: 6.5/240.1 GiB
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.3489532001495361 | Iter 2.000: -1.475889776134491 | Iter 1.000: -2.3104214611053466
    Resources requested: 10/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00000 | RUNNING    | 172.17.0.2:1484 |            2 |  256 |   64 | 0.053996    | 2.37172 |     0.0983 |                    1 |
    | DEFAULT_daa35_00002 | RUNNING    | 172.17.0.2:1555 |            2 |   16 |   16 | 0.000114956 | 1.81068 |     0.3376 |                    1 |
    | DEFAULT_daa35_00003 | RUNNING    |                 |            2 |  256 |  128 | 0.00931199  |         |            |                      |
    | DEFAULT_daa35_00005 | RUNNING    | 172.17.0.2:1495 |            4 |  256 |  256 | 0.000306556 | 1.47589 |     0.4686 |                    2 |
    | DEFAULT_daa35_00008 | RUNNING    | 172.17.0.2:1511 |           16 |   16 |    8 | 0.00276771  | 1.2212  |     0.5593 |                    6 |
    | DEFAULT_daa35_00001 | TERMINATED |                 |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00004 | TERMINATED |                 |            8 |  256 |   32 | 0.0207814   | 2.09208 |     0.1627 |                    2 |
    | DEFAULT_daa35_00006 | TERMINATED |                 |            4 |  256 |    8 | 0.0492039   | 2.32536 |     0.0959 |                    1 |
    | DEFAULT_daa35_00007 | TERMINATED |                 |            2 |   32 |    4 | 0.00393992  | 2.31256 |     0.2061 |                    1 |
    | DEFAULT_daa35_00009 | TERMINATED |                 |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_daa35_00008:
      accuracy: 0.5766
      date: 2021-02-08_14-37-49
      done: false
      experiment_id: 842021ed6bba45edae73eda2ded9fb4b
      experiment_tag: 8_batch_size=16,l1=16,l2=8,lr=0.0027677
      hostname: 9acb6dd638d6
      iterations_since_restore: 7
      loss: 1.1837658787727356
      node_ip: 172.17.0.2
      pid: 1511
      should_checkpoint: true
      time_since_restore: 155.15279960632324
      time_this_iter_s: 20.5059711933136
      time_total_s: 155.15279960632324
      timestamp: 1612795069
      timesteps_since_restore: 0
      training_iteration: 7
      trial_id: daa35_00008
  
    Result for DEFAULT_daa35_00003:
      accuracy: 0.0977
      date: 2021-02-08_14-37-49
      done: true
      experiment_id: 5732c858f0de40e5b336bd9398cac77f
      experiment_tag: 3_batch_size=2,l1=256,l2=128,lr=0.009312
      hostname: 9acb6dd638d6
      iterations_since_restore: 1
      loss: 2.3150286093235017
      node_ip: 172.17.0.2
      pid: 1546
      should_checkpoint: true
      time_since_restore: 155.18156599998474
      time_this_iter_s: 155.18156599998474
      time_total_s: 155.18156599998474
      timestamp: 1612795069
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: daa35_00003
  
    [2m[36m(pid=1495)[0m [3,  4000] loss: 0.700
    [2m[36m(pid=1555)[0m [2, 10000] loss: 0.333
    [2m[36m(pid=1511)[0m [8,  2000] loss: 1.149
    [2m[36m(pid=1555)[0m [2, 12000] loss: 0.271
    [2m[36m(pid=1495)[0m [3,  6000] loss: 0.465
    Result for DEFAULT_daa35_00008:
      accuracy: 0.5773
      date: 2021-02-08_14-38-09
      done: false
      experiment_id: 842021ed6bba45edae73eda2ded9fb4b
      experiment_tag: 8_batch_size=16,l1=16,l2=8,lr=0.0027677
      hostname: 9acb6dd638d6
      iterations_since_restore: 8
      loss: 1.1818948541164398
      node_ip: 172.17.0.2
      pid: 1511
      should_checkpoint: true
      time_since_restore: 175.10108304023743
      time_this_iter_s: 19.948283433914185
      time_total_s: 175.10108304023743
      timestamp: 1612795089
      timesteps_since_restore: 0
      training_iteration: 8
      trial_id: daa35_00008
  
    == Status ==
    Memory usage on this node: 5.3/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.1818948541164398 | Iter 4.000: -1.3489532001495361 | Iter 2.000: -1.475889776134491 | Iter 1.000: -2.311490789745748
    Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00002 | RUNNING    | 172.17.0.2:1555 |            2 |   16 |   16 | 0.000114956 | 1.81068 |     0.3376 |                    1 |
    | DEFAULT_daa35_00005 | RUNNING    | 172.17.0.2:1495 |            4 |  256 |  256 | 0.000306556 | 1.47589 |     0.4686 |                    2 |
    | DEFAULT_daa35_00008 | RUNNING    | 172.17.0.2:1511 |           16 |   16 |    8 | 0.00276771  | 1.18189 |     0.5773 |                    8 |
    | DEFAULT_daa35_00000 | TERMINATED |                 |            2 |  256 |   64 | 0.053996    | 2.37172 |     0.0983 |                    1 |
    | DEFAULT_daa35_00001 | TERMINATED |                 |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00003 | TERMINATED |                 |            2 |  256 |  128 | 0.00931199  | 2.31503 |     0.0977 |                    1 |
    | DEFAULT_daa35_00004 | TERMINATED |                 |            8 |  256 |   32 | 0.0207814   | 2.09208 |     0.1627 |                    2 |
    | DEFAULT_daa35_00006 | TERMINATED |                 |            4 |  256 |    8 | 0.0492039   | 2.32536 |     0.0959 |                    1 |
    | DEFAULT_daa35_00007 | TERMINATED |                 |            2 |   32 |    4 | 0.00393992  | 2.31256 |     0.2061 |                    1 |
    | DEFAULT_daa35_00009 | TERMINATED |                 |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1555)[0m [2, 14000] loss: 0.228
    [2m[36m(pid=1495)[0m [3,  8000] loss: 0.339
    [2m[36m(pid=1555)[0m [2, 16000] loss: 0.194
    [2m[36m(pid=1511)[0m [9,  2000] loss: 1.142
    [2m[36m(pid=1495)[0m [3, 10000] loss: 0.270
    Result for DEFAULT_daa35_00008:
      accuracy: 0.5827
      date: 2021-02-08_14-38-29
      done: false
      experiment_id: 842021ed6bba45edae73eda2ded9fb4b
      experiment_tag: 8_batch_size=16,l1=16,l2=8,lr=0.0027677
      hostname: 9acb6dd638d6
      iterations_since_restore: 9
      loss: 1.2011442136764527
      node_ip: 172.17.0.2
      pid: 1511
      should_checkpoint: true
      time_since_restore: 195.12106943130493
      time_this_iter_s: 20.019986391067505
      time_total_s: 195.12106943130493
      timestamp: 1612795109
      timesteps_since_restore: 0
      training_iteration: 9
      trial_id: daa35_00008
  
    == Status ==
    Memory usage on this node: 5.3/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.1818948541164398 | Iter 4.000: -1.3489532001495361 | Iter 2.000: -1.475889776134491 | Iter 1.000: -2.311490789745748
    Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00002 | RUNNING    | 172.17.0.2:1555 |            2 |   16 |   16 | 0.000114956 | 1.81068 |     0.3376 |                    1 |
    | DEFAULT_daa35_00005 | RUNNING    | 172.17.0.2:1495 |            4 |  256 |  256 | 0.000306556 | 1.47589 |     0.4686 |                    2 |
    | DEFAULT_daa35_00008 | RUNNING    | 172.17.0.2:1511 |           16 |   16 |    8 | 0.00276771  | 1.20114 |     0.5827 |                    9 |
    | DEFAULT_daa35_00000 | TERMINATED |                 |            2 |  256 |   64 | 0.053996    | 2.37172 |     0.0983 |                    1 |
    | DEFAULT_daa35_00001 | TERMINATED |                 |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00003 | TERMINATED |                 |            2 |  256 |  128 | 0.00931199  | 2.31503 |     0.0977 |                    1 |
    | DEFAULT_daa35_00004 | TERMINATED |                 |            8 |  256 |   32 | 0.0207814   | 2.09208 |     0.1627 |                    2 |
    | DEFAULT_daa35_00006 | TERMINATED |                 |            4 |  256 |    8 | 0.0492039   | 2.32536 |     0.0959 |                    1 |
    | DEFAULT_daa35_00007 | TERMINATED |                 |            2 |   32 |    4 | 0.00393992  | 2.31256 |     0.2061 |                    1 |
    | DEFAULT_daa35_00009 | TERMINATED |                 |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1555)[0m [2, 18000] loss: 0.176
    Result for DEFAULT_daa35_00005:
      accuracy: 0.517
      date: 2021-02-08_14-38-33
      done: false
      experiment_id: 36e73eaba6aa4df88b517cf3a856daf6
      experiment_tag: 5_batch_size=4,l1=256,l2=256,lr=0.00030656
      hostname: 9acb6dd638d6
      iterations_since_restore: 3
      loss: 1.331259906733036
      node_ip: 172.17.0.2
      pid: 1495
      should_checkpoint: true
      time_since_restore: 198.65153980255127
      time_this_iter_s: 60.27501940727234
      time_total_s: 198.65153980255127
      timestamp: 1612795113
      timesteps_since_restore: 0
      training_iteration: 3
      trial_id: daa35_00005
  
    [2m[36m(pid=1555)[0m [2, 20000] loss: 0.155
    [2m[36m(pid=1511)[0m [10,  2000] loss: 1.117
    [2m[36m(pid=1495)[0m [4,  2000] loss: 1.306
    Result for DEFAULT_daa35_00008:
      accuracy: 0.569
      date: 2021-02-08_14-38-51
      done: true
      experiment_id: 842021ed6bba45edae73eda2ded9fb4b
      experiment_tag: 8_batch_size=16,l1=16,l2=8,lr=0.0027677
      hostname: 9acb6dd638d6
      iterations_since_restore: 10
      loss: 1.2066850241661071
      node_ip: 172.17.0.2
      pid: 1511
      should_checkpoint: true
      time_since_restore: 217.11749029159546
      time_this_iter_s: 21.996420860290527
      time_total_s: 217.11749029159546
      timestamp: 1612795131
      timesteps_since_restore: 0
      training_iteration: 10
      trial_id: daa35_00008
  
    == Status ==
    Memory usage on this node: 5.3/240.1 GiB
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.1818948541164398 | Iter 4.000: -1.3489532001495361 | Iter 2.000: -1.475889776134491 | Iter 1.000: -2.311490789745748
    Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00002 | RUNNING    | 172.17.0.2:1555 |            2 |   16 |   16 | 0.000114956 | 1.81068 |     0.3376 |                    1 |
    | DEFAULT_daa35_00005 | RUNNING    | 172.17.0.2:1495 |            4 |  256 |  256 | 0.000306556 | 1.33126 |     0.517  |                    3 |
    | DEFAULT_daa35_00008 | RUNNING    | 172.17.0.2:1511 |           16 |   16 |    8 | 0.00276771  | 1.20669 |     0.569  |                   10 |
    | DEFAULT_daa35_00000 | TERMINATED |                 |            2 |  256 |   64 | 0.053996    | 2.37172 |     0.0983 |                    1 |
    | DEFAULT_daa35_00001 | TERMINATED |                 |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00003 | TERMINATED |                 |            2 |  256 |  128 | 0.00931199  | 2.31503 |     0.0977 |                    1 |
    | DEFAULT_daa35_00004 | TERMINATED |                 |            8 |  256 |   32 | 0.0207814   | 2.09208 |     0.1627 |                    2 |
    | DEFAULT_daa35_00006 | TERMINATED |                 |            4 |  256 |    8 | 0.0492039   | 2.32536 |     0.0959 |                    1 |
    | DEFAULT_daa35_00007 | TERMINATED |                 |            2 |   32 |    4 | 0.00393992  | 2.31256 |     0.2061 |                    1 |
    | DEFAULT_daa35_00009 | TERMINATED |                 |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_daa35_00002:
      accuracy: 0.4305
      date: 2021-02-08_14-38-53
      done: true
      experiment_id: b6381b8643ce4fdab9b627f02aaee85c
      experiment_tag: 2_batch_size=2,l1=16,l2=16,lr=0.00011496
      hostname: 9acb6dd638d6
      iterations_since_restore: 2
      loss: 1.5556287031769753
      node_ip: 172.17.0.2
      pid: 1555
      should_checkpoint: true
      time_since_restore: 219.2596583366394
      time_this_iter_s: 102.44220209121704
      time_total_s: 219.2596583366394
      timestamp: 1612795133
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: daa35_00002
  
    [2m[36m(pid=1495)[0m [4,  4000] loss: 0.637
    [2m[36m(pid=1495)[0m [4,  6000] loss: 0.422
    [2m[36m(pid=1495)[0m [4,  8000] loss: 0.312
    [2m[36m(pid=1495)[0m [4, 10000] loss: 0.249
    Result for DEFAULT_daa35_00005:
      accuracy: 0.5512
      date: 2021-02-08_14-39-32
      done: false
      experiment_id: 36e73eaba6aa4df88b517cf3a856daf6
      experiment_tag: 5_batch_size=4,l1=256,l2=256,lr=0.00030656
      hostname: 9acb6dd638d6
      iterations_since_restore: 4
      loss: 1.2664287532269956
      node_ip: 172.17.0.2
      pid: 1495
      should_checkpoint: true
      time_since_restore: 258.15844988822937
      time_this_iter_s: 59.5069100856781
      time_total_s: 258.15844988822937
      timestamp: 1612795172
      timesteps_since_restore: 0
      training_iteration: 4
      trial_id: daa35_00005
  
    == Status ==
    Memory usage on this node: 4.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.1818948541164398 | Iter 4.000: -1.3076909766882658 | Iter 2.000: -1.5157592396557331 | Iter 1.000: -2.311490789745748
    Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00005 | RUNNING    | 172.17.0.2:1495 |            4 |  256 |  256 | 0.000306556 | 1.26643 |     0.5512 |                    4 |
    | DEFAULT_daa35_00000 | TERMINATED |                 |            2 |  256 |   64 | 0.053996    | 2.37172 |     0.0983 |                    1 |
    | DEFAULT_daa35_00001 | TERMINATED |                 |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00002 | TERMINATED |                 |            2 |   16 |   16 | 0.000114956 | 1.55563 |     0.4305 |                    2 |
    | DEFAULT_daa35_00003 | TERMINATED |                 |            2 |  256 |  128 | 0.00931199  | 2.31503 |     0.0977 |                    1 |
    | DEFAULT_daa35_00004 | TERMINATED |                 |            8 |  256 |   32 | 0.0207814   | 2.09208 |     0.1627 |                    2 |
    | DEFAULT_daa35_00006 | TERMINATED |                 |            4 |  256 |    8 | 0.0492039   | 2.32536 |     0.0959 |                    1 |
    | DEFAULT_daa35_00007 | TERMINATED |                 |            2 |   32 |    4 | 0.00393992  | 2.31256 |     0.2061 |                    1 |
    | DEFAULT_daa35_00008 | TERMINATED |                 |           16 |   16 |    8 | 0.00276771  | 1.20669 |     0.569  |                   10 |
    | DEFAULT_daa35_00009 | TERMINATED |                 |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1495)[0m [5,  2000] loss: 1.182
    [2m[36m(pid=1495)[0m [5,  4000] loss: 0.580
    [2m[36m(pid=1495)[0m [5,  6000] loss: 0.390
    [2m[36m(pid=1495)[0m [5,  8000] loss: 0.296
    [2m[36m(pid=1495)[0m [5, 10000] loss: 0.233
    Result for DEFAULT_daa35_00005:
      accuracy: 0.5697
      date: 2021-02-08_14-40-29
      done: false
      experiment_id: 36e73eaba6aa4df88b517cf3a856daf6
      experiment_tag: 5_batch_size=4,l1=256,l2=256,lr=0.00030656
      hostname: 9acb6dd638d6
      iterations_since_restore: 5
      loss: 1.194693154504895
      node_ip: 172.17.0.2
      pid: 1495
      should_checkpoint: true
      time_since_restore: 314.82328033447266
      time_this_iter_s: 56.664830446243286
      time_total_s: 314.82328033447266
      timestamp: 1612795229
      timesteps_since_restore: 0
      training_iteration: 5
      trial_id: daa35_00005
  
    == Status ==
    Memory usage on this node: 4.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.1818948541164398 | Iter 4.000: -1.3076909766882658 | Iter 2.000: -1.5157592396557331 | Iter 1.000: -2.311490789745748
    Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00005 | RUNNING    | 172.17.0.2:1495 |            4 |  256 |  256 | 0.000306556 | 1.19469 |     0.5697 |                    5 |
    | DEFAULT_daa35_00000 | TERMINATED |                 |            2 |  256 |   64 | 0.053996    | 2.37172 |     0.0983 |                    1 |
    | DEFAULT_daa35_00001 | TERMINATED |                 |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00002 | TERMINATED |                 |            2 |   16 |   16 | 0.000114956 | 1.55563 |     0.4305 |                    2 |
    | DEFAULT_daa35_00003 | TERMINATED |                 |            2 |  256 |  128 | 0.00931199  | 2.31503 |     0.0977 |                    1 |
    | DEFAULT_daa35_00004 | TERMINATED |                 |            8 |  256 |   32 | 0.0207814   | 2.09208 |     0.1627 |                    2 |
    | DEFAULT_daa35_00006 | TERMINATED |                 |            4 |  256 |    8 | 0.0492039   | 2.32536 |     0.0959 |                    1 |
    | DEFAULT_daa35_00007 | TERMINATED |                 |            2 |   32 |    4 | 0.00393992  | 2.31256 |     0.2061 |                    1 |
    | DEFAULT_daa35_00008 | TERMINATED |                 |           16 |   16 |    8 | 0.00276771  | 1.20669 |     0.569  |                   10 |
    | DEFAULT_daa35_00009 | TERMINATED |                 |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1495)[0m [6,  2000] loss: 1.114
    [2m[36m(pid=1495)[0m [6,  4000] loss: 0.541
    [2m[36m(pid=1495)[0m [6,  6000] loss: 0.363
    [2m[36m(pid=1495)[0m [6,  8000] loss: 0.275
    [2m[36m(pid=1495)[0m [6, 10000] loss: 0.218
    Result for DEFAULT_daa35_00005:
      accuracy: 0.582
      date: 2021-02-08_14-41-25
      done: false
      experiment_id: 36e73eaba6aa4df88b517cf3a856daf6
      experiment_tag: 5_batch_size=4,l1=256,l2=256,lr=0.00030656
      hostname: 9acb6dd638d6
      iterations_since_restore: 6
      loss: 1.2151359305366873
      node_ip: 172.17.0.2
      pid: 1495
      should_checkpoint: true
      time_since_restore: 371.1322731971741
      time_this_iter_s: 56.308992862701416
      time_total_s: 371.1322731971741
      timestamp: 1612795285
      timesteps_since_restore: 0
      training_iteration: 6
      trial_id: daa35_00005
  
    == Status ==
    Memory usage on this node: 4.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.1818948541164398 | Iter 4.000: -1.3076909766882658 | Iter 2.000: -1.5157592396557331 | Iter 1.000: -2.311490789745748
    Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00005 | RUNNING    | 172.17.0.2:1495 |            4 |  256 |  256 | 0.000306556 | 1.21514 |     0.582  |                    6 |
    | DEFAULT_daa35_00000 | TERMINATED |                 |            2 |  256 |   64 | 0.053996    | 2.37172 |     0.0983 |                    1 |
    | DEFAULT_daa35_00001 | TERMINATED |                 |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00002 | TERMINATED |                 |            2 |   16 |   16 | 0.000114956 | 1.55563 |     0.4305 |                    2 |
    | DEFAULT_daa35_00003 | TERMINATED |                 |            2 |  256 |  128 | 0.00931199  | 2.31503 |     0.0977 |                    1 |
    | DEFAULT_daa35_00004 | TERMINATED |                 |            8 |  256 |   32 | 0.0207814   | 2.09208 |     0.1627 |                    2 |
    | DEFAULT_daa35_00006 | TERMINATED |                 |            4 |  256 |    8 | 0.0492039   | 2.32536 |     0.0959 |                    1 |
    | DEFAULT_daa35_00007 | TERMINATED |                 |            2 |   32 |    4 | 0.00393992  | 2.31256 |     0.2061 |                    1 |
    | DEFAULT_daa35_00008 | TERMINATED |                 |           16 |   16 |    8 | 0.00276771  | 1.20669 |     0.569  |                   10 |
    | DEFAULT_daa35_00009 | TERMINATED |                 |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1495)[0m [7,  2000] loss: 1.031
    [2m[36m(pid=1495)[0m [7,  4000] loss: 0.511
    [2m[36m(pid=1495)[0m [7,  6000] loss: 0.347
    [2m[36m(pid=1495)[0m [7,  8000] loss: 0.255
    [2m[36m(pid=1495)[0m [7, 10000] loss: 0.205
    Result for DEFAULT_daa35_00005:
      accuracy: 0.6046
      date: 2021-02-08_14-42-22
      done: false
      experiment_id: 36e73eaba6aa4df88b517cf3a856daf6
      experiment_tag: 5_batch_size=4,l1=256,l2=256,lr=0.00030656
      hostname: 9acb6dd638d6
      iterations_since_restore: 7
      loss: 1.1148830617651344
      node_ip: 172.17.0.2
      pid: 1495
      should_checkpoint: true
      time_since_restore: 427.27196502685547
      time_this_iter_s: 56.1396918296814
      time_total_s: 427.27196502685547
      timestamp: 1612795342
      timesteps_since_restore: 0
      training_iteration: 7
      trial_id: daa35_00005
  
    == Status ==
    Memory usage on this node: 4.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.1818948541164398 | Iter 4.000: -1.3076909766882658 | Iter 2.000: -1.5157592396557331 | Iter 1.000: -2.311490789745748
    Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00005 | RUNNING    | 172.17.0.2:1495 |            4 |  256 |  256 | 0.000306556 | 1.11488 |     0.6046 |                    7 |
    | DEFAULT_daa35_00000 | TERMINATED |                 |            2 |  256 |   64 | 0.053996    | 2.37172 |     0.0983 |                    1 |
    | DEFAULT_daa35_00001 | TERMINATED |                 |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00002 | TERMINATED |                 |            2 |   16 |   16 | 0.000114956 | 1.55563 |     0.4305 |                    2 |
    | DEFAULT_daa35_00003 | TERMINATED |                 |            2 |  256 |  128 | 0.00931199  | 2.31503 |     0.0977 |                    1 |
    | DEFAULT_daa35_00004 | TERMINATED |                 |            8 |  256 |   32 | 0.0207814   | 2.09208 |     0.1627 |                    2 |
    | DEFAULT_daa35_00006 | TERMINATED |                 |            4 |  256 |    8 | 0.0492039   | 2.32536 |     0.0959 |                    1 |
    | DEFAULT_daa35_00007 | TERMINATED |                 |            2 |   32 |    4 | 0.00393992  | 2.31256 |     0.2061 |                    1 |
    | DEFAULT_daa35_00008 | TERMINATED |                 |           16 |   16 |    8 | 0.00276771  | 1.20669 |     0.569  |                   10 |
    | DEFAULT_daa35_00009 | TERMINATED |                 |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1495)[0m [8,  2000] loss: 0.949
    [2m[36m(pid=1495)[0m [8,  4000] loss: 0.479
    [2m[36m(pid=1495)[0m [8,  6000] loss: 0.317
    [2m[36m(pid=1495)[0m [8,  8000] loss: 0.247
    [2m[36m(pid=1495)[0m [8, 10000] loss: 0.192
    Result for DEFAULT_daa35_00005:
      accuracy: 0.6188
      date: 2021-02-08_14-43-18
      done: false
      experiment_id: 36e73eaba6aa4df88b517cf3a856daf6
      experiment_tag: 5_batch_size=4,l1=256,l2=256,lr=0.00030656
      hostname: 9acb6dd638d6
      iterations_since_restore: 8
      loss: 1.0973329602435231
      node_ip: 172.17.0.2
      pid: 1495
      should_checkpoint: true
      time_since_restore: 483.5882134437561
      time_this_iter_s: 56.316248416900635
      time_total_s: 483.5882134437561
      timestamp: 1612795398
      timesteps_since_restore: 0
      training_iteration: 8
      trial_id: daa35_00005
  
    == Status ==
    Memory usage on this node: 4.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.1396139071799816 | Iter 4.000: -1.3076909766882658 | Iter 2.000: -1.5157592396557331 | Iter 1.000: -2.311490789745748
    Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00005 | RUNNING    | 172.17.0.2:1495 |            4 |  256 |  256 | 0.000306556 | 1.09733 |     0.6188 |                    8 |
    | DEFAULT_daa35_00000 | TERMINATED |                 |            2 |  256 |   64 | 0.053996    | 2.37172 |     0.0983 |                    1 |
    | DEFAULT_daa35_00001 | TERMINATED |                 |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00002 | TERMINATED |                 |            2 |   16 |   16 | 0.000114956 | 1.55563 |     0.4305 |                    2 |
    | DEFAULT_daa35_00003 | TERMINATED |                 |            2 |  256 |  128 | 0.00931199  | 2.31503 |     0.0977 |                    1 |
    | DEFAULT_daa35_00004 | TERMINATED |                 |            8 |  256 |   32 | 0.0207814   | 2.09208 |     0.1627 |                    2 |
    | DEFAULT_daa35_00006 | TERMINATED |                 |            4 |  256 |    8 | 0.0492039   | 2.32536 |     0.0959 |                    1 |
    | DEFAULT_daa35_00007 | TERMINATED |                 |            2 |   32 |    4 | 0.00393992  | 2.31256 |     0.2061 |                    1 |
    | DEFAULT_daa35_00008 | TERMINATED |                 |           16 |   16 |    8 | 0.00276771  | 1.20669 |     0.569  |                   10 |
    | DEFAULT_daa35_00009 | TERMINATED |                 |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1495)[0m [9,  2000] loss: 0.902
    [2m[36m(pid=1495)[0m [9,  4000] loss: 0.443
    [2m[36m(pid=1495)[0m [9,  6000] loss: 0.295
    [2m[36m(pid=1495)[0m [9,  8000] loss: 0.225
    [2m[36m(pid=1495)[0m [9, 10000] loss: 0.181
    Result for DEFAULT_daa35_00005:
      accuracy: 0.6182
      date: 2021-02-08_14-44-14
      done: false
      experiment_id: 36e73eaba6aa4df88b517cf3a856daf6
      experiment_tag: 5_batch_size=4,l1=256,l2=256,lr=0.00030656
      hostname: 9acb6dd638d6
      iterations_since_restore: 9
      loss: 1.0856344561450184
      node_ip: 172.17.0.2
      pid: 1495
      should_checkpoint: true
      time_since_restore: 540.1924932003021
      time_this_iter_s: 56.60427975654602
      time_total_s: 540.1924932003021
      timestamp: 1612795454
      timesteps_since_restore: 0
      training_iteration: 9
      trial_id: daa35_00005
  
    == Status ==
    Memory usage on this node: 4.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.1396139071799816 | Iter 4.000: -1.3076909766882658 | Iter 2.000: -1.5157592396557331 | Iter 1.000: -2.311490789745748
    Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00005 | RUNNING    | 172.17.0.2:1495 |            4 |  256 |  256 | 0.000306556 | 1.08563 |     0.6182 |                    9 |
    | DEFAULT_daa35_00000 | TERMINATED |                 |            2 |  256 |   64 | 0.053996    | 2.37172 |     0.0983 |                    1 |
    | DEFAULT_daa35_00001 | TERMINATED |                 |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00002 | TERMINATED |                 |            2 |   16 |   16 | 0.000114956 | 1.55563 |     0.4305 |                    2 |
    | DEFAULT_daa35_00003 | TERMINATED |                 |            2 |  256 |  128 | 0.00931199  | 2.31503 |     0.0977 |                    1 |
    | DEFAULT_daa35_00004 | TERMINATED |                 |            8 |  256 |   32 | 0.0207814   | 2.09208 |     0.1627 |                    2 |
    | DEFAULT_daa35_00006 | TERMINATED |                 |            4 |  256 |    8 | 0.0492039   | 2.32536 |     0.0959 |                    1 |
    | DEFAULT_daa35_00007 | TERMINATED |                 |            2 |   32 |    4 | 0.00393992  | 2.31256 |     0.2061 |                    1 |
    | DEFAULT_daa35_00008 | TERMINATED |                 |           16 |   16 |    8 | 0.00276771  | 1.20669 |     0.569  |                   10 |
    | DEFAULT_daa35_00009 | TERMINATED |                 |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1495)[0m [10,  2000] loss: 0.824
    [2m[36m(pid=1495)[0m [10,  4000] loss: 0.415
    [2m[36m(pid=1495)[0m [10,  6000] loss: 0.280
    [2m[36m(pid=1495)[0m [10,  8000] loss: 0.213
    [2m[36m(pid=1495)[0m [10, 10000] loss: 0.172
    Result for DEFAULT_daa35_00005:
      accuracy: 0.6287
      date: 2021-02-08_14-45-11
      done: true
      experiment_id: 36e73eaba6aa4df88b517cf3a856daf6
      experiment_tag: 5_batch_size=4,l1=256,l2=256,lr=0.00030656
      hostname: 9acb6dd638d6
      iterations_since_restore: 10
      loss: 1.089533281974122
      node_ip: 172.17.0.2
      pid: 1495
      should_checkpoint: true
      time_since_restore: 596.3387813568115
      time_this_iter_s: 56.1462881565094
      time_total_s: 596.3387813568115
      timestamp: 1612795511
      timesteps_since_restore: 0
      training_iteration: 10
      trial_id: daa35_00005
  
    == Status ==
    Memory usage on this node: 4.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.1396139071799816 | Iter 4.000: -1.3076909766882658 | Iter 2.000: -1.5157592396557331 | Iter 1.000: -2.311490789745748
    Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00005 | RUNNING    | 172.17.0.2:1495 |            4 |  256 |  256 | 0.000306556 | 1.08953 |     0.6287 |                   10 |
    | DEFAULT_daa35_00000 | TERMINATED |                 |            2 |  256 |   64 | 0.053996    | 2.37172 |     0.0983 |                    1 |
    | DEFAULT_daa35_00001 | TERMINATED |                 |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00002 | TERMINATED |                 |            2 |   16 |   16 | 0.000114956 | 1.55563 |     0.4305 |                    2 |
    | DEFAULT_daa35_00003 | TERMINATED |                 |            2 |  256 |  128 | 0.00931199  | 2.31503 |     0.0977 |                    1 |
    | DEFAULT_daa35_00004 | TERMINATED |                 |            8 |  256 |   32 | 0.0207814   | 2.09208 |     0.1627 |                    2 |
    | DEFAULT_daa35_00006 | TERMINATED |                 |            4 |  256 |    8 | 0.0492039   | 2.32536 |     0.0959 |                    1 |
    | DEFAULT_daa35_00007 | TERMINATED |                 |            2 |   32 |    4 | 0.00393992  | 2.31256 |     0.2061 |                    1 |
    | DEFAULT_daa35_00008 | TERMINATED |                 |           16 |   16 |    8 | 0.00276771  | 1.20669 |     0.569  |                   10 |
    | DEFAULT_daa35_00009 | TERMINATED |                 |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    == Status ==
    Memory usage on this node: 3.9/240.1 GiB
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.1396139071799816 | Iter 4.000: -1.3076909766882658 | Iter 2.000: -1.5157592396557331 | Iter 1.000: -2.311490789745748
    Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/157.71 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-02-08_14-35-13
    Number of trials: 10/10 (10 TERMINATED)
    +---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc   |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_daa35_00000 | TERMINATED |       |            2 |  256 |   64 | 0.053996    | 2.37172 |     0.0983 |                    1 |
    | DEFAULT_daa35_00001 | TERMINATED |       |           16 |  256 |    4 | 0.000119345 | 2.31892 |     0.0976 |                    1 |
    | DEFAULT_daa35_00002 | TERMINATED |       |            2 |   16 |   16 | 0.000114956 | 1.55563 |     0.4305 |                    2 |
    | DEFAULT_daa35_00003 | TERMINATED |       |            2 |  256 |  128 | 0.00931199  | 2.31503 |     0.0977 |                    1 |
    | DEFAULT_daa35_00004 | TERMINATED |       |            8 |  256 |   32 | 0.0207814   | 2.09208 |     0.1627 |                    2 |
    | DEFAULT_daa35_00005 | TERMINATED |       |            4 |  256 |  256 | 0.000306556 | 1.08953 |     0.6287 |                   10 |
    | DEFAULT_daa35_00006 | TERMINATED |       |            4 |  256 |    8 | 0.0492039   | 2.32536 |     0.0959 |                    1 |
    | DEFAULT_daa35_00007 | TERMINATED |       |            2 |   32 |    4 | 0.00393992  | 2.31256 |     0.2061 |                    1 |
    | DEFAULT_daa35_00008 | TERMINATED |       |           16 |   16 |    8 | 0.00276771  | 1.20669 |     0.569  |                   10 |
    | DEFAULT_daa35_00009 | TERMINATED |       |           16 |    8 |    8 | 0.00010222  | 2.31042 |     0.1044 |                    1 |
    +---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+


    Best trial config: {'l1': 256, 'l2': 256, 'lr': 0.0003065563590736632, 'batch_size': 4}
    Best trial final validation loss: 1.089533281974122
    Best trial final validation accuracy: 0.6287
    Files already downloaded and verified
    Files already downloaded and verified
    Best trial test set accuracy: 0.6282


If you run the code, an example output could look like this:

.. code-block::

    Number of trials: 10 (10 TERMINATED)
    +-----+------+------+-------------+--------------+---------+------------+--------------------+
    | ... |   l1 |   l2 |          lr |   batch_size |    loss |   accuracy | training_iteration |
    |-----+------+------+-------------+--------------+---------+------------+--------------------|
    | ... |   64 |    4 | 0.00011629  |            2 | 1.87273 |     0.244  |                  2 |
    | ... |   32 |   64 | 0.000339763 |            8 | 1.23603 |     0.567  |                  8 |
    | ... |    8 |   16 | 0.00276249  |           16 | 1.1815  |     0.5836 |                 10 |
    | ... |    4 |   64 | 0.000648721 |            4 | 1.31131 |     0.5224 |                  8 |
    | ... |   32 |   16 | 0.000340753 |            8 | 1.26454 |     0.5444 |                  8 |
    | ... |    8 |    4 | 0.000699775 |            8 | 1.99594 |     0.1983 |                  2 |
    | ... |  256 |    8 | 0.0839654   |           16 | 2.3119  |     0.0993 |                  1 |
    | ... |   16 |  128 | 0.0758154   |           16 | 2.33575 |     0.1327 |                  1 |
    | ... |   16 |    8 | 0.0763312   |           16 | 2.31129 |     0.1042 |                  4 |
    | ... |  128 |   16 | 0.000124903 |            4 | 2.26917 |     0.1945 |                  1 |
    +-----+------+------+-------------+--------------+---------+------------+--------------------+


    Best trial config: {'l1': 8, 'l2': 16, 'lr': 0.00276249, 'batch_size': 16, 'data_dir': '...'}
    Best trial final validation loss: 1.181501
    Best trial final validation accuracy: 0.5836
    Best trial test set accuracy: 0.5806

Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 58%, which could
be confirmed on the test set.

So that's it! You can now tune the parameters of your PyTorch models.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 10 minutes  17.523 seconds)


.. _sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: hyperparameter_tuning_tutorial.py <hyperparameter_tuning_tutorial.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: hyperparameter_tuning_tutorial.ipynb <hyperparameter_tuning_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
