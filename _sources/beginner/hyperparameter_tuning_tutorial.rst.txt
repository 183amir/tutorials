.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_hyperparameter_tuning_tutorial.py:


Hyperparameter tuning with Ray Tune
===================================

Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.

Fortunately, there are tools that help with finding the best combination of parameters.
`Ray Tune <https://docs.ray.io/en/latest/tune.html>`_ is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through `Ray's distributed machine learning engine
<https://ray.io/>`_.

In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend `this tutorial from the PyTorch documentation
<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ for training
a CIFAR10 image classifier.

As you will see, we only need to add some slight modifications. In particular, we
need to

1. wrap data loading and training in functions,
2. make some network parameters configurable,
3. add checkpointing (optional),
4. and define the search space for the model tuning

|

To run this tutorial, please make sure the following packages are
installed:

-  ``ray[tune]``: Distributed hyperparameter tuning library
-  ``torchvision``: For the data transformers

Setup / Imports
---------------
Let's start with the imports:


.. code-block:: default

    from functools import partial
    import numpy as np
    import os
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import random_split
    import torchvision
    import torchvision.transforms as transforms
    from ray import tune
    from ray.tune import CLIReporter
    from ray.tune.schedulers import ASHAScheduler







Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.

Data loaders
------------
We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.


.. code-block:: default



    def load_data(data_dir="./data"):
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])

        trainset = torchvision.datasets.CIFAR10(
            root=data_dir, train=True, download=True, transform=transform)

        testset = torchvision.datasets.CIFAR10(
            root=data_dir, train=False, download=True, transform=transform)

        return trainset, testset







Configurable neural network
---------------------------
We can only tune those parameters that are configurable. In this example, we can specify
the layer sizes of the fully connected layers:


.. code-block:: default



    class Net(nn.Module):
        def __init__(self, l1=120, l2=84):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5)
            self.pool = nn.MaxPool2d(2, 2)
            self.conv2 = nn.Conv2d(6, 16, 5)
            self.fc1 = nn.Linear(16 * 5 * 5, l1)
            self.fc2 = nn.Linear(l1, l2)
            self.fc3 = nn.Linear(l2, 10)

        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = x.view(-1, 16 * 5 * 5)
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x







The train function
------------------
Now it gets interesting, because we introduce some changes to the example `from the PyTorch
documentation <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_.

We wrap the training script in a function ``train_cifar(config, checkpoint_dir=None, data_dir=None)``.
As you can guess, the ``config`` parameter will receive the hyperparameters we would like to
train with. The ``checkpoint_dir`` parameter is used to restore checkpoints. The ``data_dir`` specifies
the directory where we load and store the data, so multiple runs can share the same data source.

.. code-block:: python

    net = Net(config["l1"], config["l2"])

    if checkpoint_dir:
        model_state, optimizer_state = torch.load(
            os.path.join(checkpoint_dir, "checkpoint"))
        net.load_state_dict(model_state)
        optimizer.load_state_dict(optimizer_state)

The learning rate of the optimizer is made configurable, too:

.. code-block:: python

    optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.

Adding (multi) GPU support with DataParallel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch's abstractions in Ray Tune. Thus, we can wrap our model in ``nn.DataParallel``
to support data parallel training on multiple GPUs:

.. code-block:: python

    device = "cpu"
    if torch.cuda.is_available():
        device = "cuda:0"
        if torch.cuda.device_count() > 1:
            net = nn.DataParallel(net)
    net.to(device)

By using a ``device`` variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:

.. code-block:: python

    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports `fractional GPUs <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We'll come back
to that later.

Communicating with Ray Tune
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The most interesting part is the communication with Ray Tune:

.. code-block:: python

    with tune.checkpoint_dir(epoch) as checkpoint_dir:
        path = os.path.join(checkpoint_dir, "checkpoint")
        torch.save((net.state_dict(), optimizer.state_dict()), path)

    tune.report(loss=(val_loss / val_steps), accuracy=correct / total)

Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.

The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
`Population Based Training <https://docs.ray.io/en/master/tune/tutorials/tune-advanced-tutorial.html>`_.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set.

Full training function
~~~~~~~~~~~~~~~~~~~~~~

The full code example looks like this:


.. code-block:: default



    def train_cifar(config, checkpoint_dir=None, data_dir=None):
        net = Net(config["l1"], config["l2"])

        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if torch.cuda.device_count() > 1:
                net = nn.DataParallel(net)
        net.to(device)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

        if checkpoint_dir:
            model_state, optimizer_state = torch.load(
                os.path.join(checkpoint_dir, "checkpoint"))
            net.load_state_dict(model_state)
            optimizer.load_state_dict(optimizer_state)

        trainset, testset = load_data(data_dir)

        test_abs = int(len(trainset) * 0.8)
        train_subset, val_subset = random_split(
            trainset, [test_abs, len(trainset) - test_abs])

        trainloader = torch.utils.data.DataLoader(
            train_subset,
            batch_size=int(config["batch_size"]),
            shuffle=True,
            num_workers=8)
        valloader = torch.utils.data.DataLoader(
            val_subset,
            batch_size=int(config["batch_size"]),
            shuffle=True,
            num_workers=8)

        for epoch in range(10):  # loop over the dataset multiple times
            running_loss = 0.0
            epoch_steps = 0
            for i, data in enumerate(trainloader, 0):
                # get the inputs; data is a list of [inputs, labels]
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward + backward + optimize
                outputs = net(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                # print statistics
                running_loss += loss.item()
                epoch_steps += 1
                if i % 2000 == 1999:  # print every 2000 mini-batches
                    print("[%d, %5d] loss: %.3f" % (epoch + 1, i + 1,
                                                    running_loss / epoch_steps))
                    running_loss = 0.0

            # Validation loss
            val_loss = 0.0
            val_steps = 0
            total = 0
            correct = 0
            for i, data in enumerate(valloader, 0):
                with torch.no_grad():
                    inputs, labels = data
                    inputs, labels = inputs.to(device), labels.to(device)

                    outputs = net(inputs)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                    loss = criterion(outputs, labels)
                    val_loss += loss.cpu().numpy()
                    val_steps += 1

            with tune.checkpoint_dir(epoch) as checkpoint_dir:
                path = os.path.join(checkpoint_dir, "checkpoint")
                torch.save((net.state_dict(), optimizer.state_dict()), path)

            tune.report(loss=(val_loss / val_steps), accuracy=correct / total)
        print("Finished Training")







As you can see, most of the code is adapted directly from the original example.

Test set accuracy
-----------------
Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:


.. code-block:: default



    def test_accuracy(net, device="cpu"):
        trainset, testset = load_data()

        testloader = torch.utils.data.DataLoader(
            testset, batch_size=4, shuffle=False, num_workers=2)

        correct = 0
        total = 0
        with torch.no_grad():
            for data in testloader:
                images, labels = data
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return correct / total







The function also expects a ``device`` parameter, so we can do the
test set validation on a GPU.

Configuring the search space
----------------------------
Lastly, we need to define Ray Tune's search space. Here is an example:

.. code-block:: python

    config = {
        "l1": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),
        "l2": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16])
    }

The ``tune.sample_from()`` function makes it possible to define your own sample
methods to obtain hyperparameters. In this example, the ``l1`` and ``l2`` parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.

At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the ``ASHAScheduler`` which will terminate bad
performing trials early.

We wrap the ``train_cifar`` function with ``functools.partial`` to set the constant
``data_dir`` parameter. We can also tell Ray Tune what resources should be
available for each trial:

.. code-block:: python

    gpus_per_trial = 2
    # ...
    result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 8, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
        progress_reporter=reporter,
        checkpoint_at_end=True)

You can specify the number of CPUs, which are then available e.g.
to increase the ``num_workers`` of the PyTorch ``DataLoader`` instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven't been requested for them - so you don't have to care about two trials
using the same set of resources.

Here we can also specify fractional GPUs, so something like ``gpus_per_trial=0.5`` is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.

After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.

The full main function looks like this:


.. code-block:: default



    def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):
        data_dir = os.path.abspath("./data")
        load_data(data_dir)
        config = {
            "l1": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
            "l2": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
            "lr": tune.loguniform(1e-4, 1e-1),
            "batch_size": tune.choice([2, 4, 8, 16])
        }
        scheduler = ASHAScheduler(
            metric="loss",
            mode="min",
            max_t=max_num_epochs,
            grace_period=1,
            reduction_factor=2)
        reporter = CLIReporter(
            # parameter_columns=["l1", "l2", "lr", "batch_size"],
            metric_columns=["loss", "accuracy", "training_iteration"])
        result = tune.run(
            partial(train_cifar, data_dir=data_dir),
            resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
            config=config,
            num_samples=num_samples,
            scheduler=scheduler,
            progress_reporter=reporter)

        best_trial = result.get_best_trial("loss", "min", "last")
        print("Best trial config: {}".format(best_trial.config))
        print("Best trial final validation loss: {}".format(
            best_trial.last_result["loss"]))
        print("Best trial final validation accuracy: {}".format(
            best_trial.last_result["accuracy"]))

        best_trained_model = Net(best_trial.config["l1"], best_trial.config["l2"])
        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if gpus_per_trial > 1:
                best_trained_model = nn.DataParallel(best_trained_model)
        best_trained_model.to(device)

        best_checkpoint_dir = best_trial.checkpoint.value
        model_state, optimizer_state = torch.load(os.path.join(
            best_checkpoint_dir, "checkpoint"))
        best_trained_model.load_state_dict(model_state)

        test_acc = test_accuracy(best_trained_model, device)
        print("Best trial test set accuracy: {}".format(test_acc))


    if __name__ == "__main__":
        # You can change the number of GPUs per trial here:
        main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz
    Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
    Files already downloaded and verified
    == Status ==
    Memory usage on this node: 4.4/240.1 GiB
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Resources requested: 2.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (9 PENDING, 1 RUNNING)
    +---------------------+----------+-------+--------------+------+------+-------------+
    | Trial name          | status   | loc   |   batch_size |   l1 |   l2 |          lr |
    |---------------------+----------+-------+--------------+------+------+-------------|
    | DEFAULT_0e65d_00000 | RUNNING  |       |           16 |    4 |   32 | 0.00882003  |
    | DEFAULT_0e65d_00001 | PENDING  |       |            8 |  256 |  128 | 0.00398049  |
    | DEFAULT_0e65d_00002 | PENDING  |       |            2 |  256 |   64 | 0.00922119  |
    | DEFAULT_0e65d_00003 | PENDING  |       |           16 |   16 |   64 | 0.000883321 |
    | DEFAULT_0e65d_00004 | PENDING  |       |            4 |   64 |  256 | 0.000102859 |
    | DEFAULT_0e65d_00005 | PENDING  |       |            8 |  128 |   64 | 0.000219673 |
    | DEFAULT_0e65d_00006 | PENDING  |       |           16 |   16 |  128 | 0.0107294   |
    | DEFAULT_0e65d_00007 | PENDING  |       |            2 |  128 |   64 | 0.0433275   |
    | DEFAULT_0e65d_00008 | PENDING  |       |            8 |   16 |   16 | 0.0667362   |
    | DEFAULT_0e65d_00009 | PENDING  |       |            2 |   16 |   64 | 0.0608499   |
    +---------------------+----------+-------+--------------+------+------+-------------+


    [2m[36m(pid=1491)[0m Files already downloaded and verified
    [2m[36m(pid=1487)[0m Files already downloaded and verified
    [2m[36m(pid=1481)[0m Files already downloaded and verified
    [2m[36m(pid=1449)[0m Files already downloaded and verified
    [2m[36m(pid=1486)[0m Files already downloaded and verified
    [2m[36m(pid=1462)[0m Files already downloaded and verified
    [2m[36m(pid=1502)[0m Files already downloaded and verified
    [2m[36m(pid=1501)[0m Files already downloaded and verified
    [2m[36m(pid=1466)[0m Files already downloaded and verified
    [2m[36m(pid=1450)[0m Files already downloaded and verified
    [2m[36m(pid=1491)[0m Files already downloaded and verified
    [2m[36m(pid=1487)[0m Files already downloaded and verified
    [2m[36m(pid=1481)[0m Files already downloaded and verified
    [2m[36m(pid=1449)[0m Files already downloaded and verified
    [2m[36m(pid=1486)[0m Files already downloaded and verified
    [2m[36m(pid=1502)[0m Files already downloaded and verified
    [2m[36m(pid=1501)[0m Files already downloaded and verified
    [2m[36m(pid=1462)[0m Files already downloaded and verified
    [2m[36m(pid=1466)[0m Files already downloaded and verified
    [2m[36m(pid=1450)[0m Files already downloaded and verified
    [2m[36m(pid=1449)[0m [1,  2000] loss: 2.369
    [2m[36m(pid=1501)[0m [1,  2000] loss: 2.213
    [2m[36m(pid=1502)[0m [1,  2000] loss: 2.301
    [2m[36m(pid=1486)[0m [1,  2000] loss: 2.352
    [2m[36m(pid=1450)[0m [1,  2000] loss: 2.321
    [2m[36m(pid=1466)[0m [1,  2000] loss: 2.304
    [2m[36m(pid=1481)[0m [1,  2000] loss: 1.886
    [2m[36m(pid=1487)[0m [1,  2000] loss: 2.211
    [2m[36m(pid=1462)[0m [1,  2000] loss: 1.800
    [2m[36m(pid=1491)[0m [1,  2000] loss: 1.896
    [2m[36m(pid=1449)[0m [1,  4000] loss: 1.183
    [2m[36m(pid=1502)[0m [1,  4000] loss: 1.146
    Result for DEFAULT_0e65d_00003:
      accuracy: 0.2902
      date: 2021-05-04_19-30-02
      done: false
      experiment_id: 0766ccfb272d4fdfa7b1b4e6a2bc2e69
      hostname: d26a977e64c3
      iterations_since_restore: 1
      loss: 1.913128999710083
      node_ip: 172.17.0.2
      pid: 1487
      should_checkpoint: true
      time_since_restore: 26.59880256652832
      time_this_iter_s: 26.59880256652832
      time_total_s: 26.59880256652832
      timestamp: 1620156602
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 0e65d_00003
  
    == Status ==
    Memory usage on this node: 9.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.913128999710083
    Resources requested: 20.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (10 RUNNING)
    +---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status   | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00000 | RUNNING  |                 |           16 |    4 |   32 | 0.00882003  |         |            |                      |
    | DEFAULT_0e65d_00001 | RUNNING  |                 |            8 |  256 |  128 | 0.00398049  |         |            |                      |
    | DEFAULT_0e65d_00002 | RUNNING  |                 |            2 |  256 |   64 | 0.00922119  |         |            |                      |
    | DEFAULT_0e65d_00003 | RUNNING  | 172.17.0.2:1487 |           16 |   16 |   64 | 0.000883321 | 1.91313 |     0.2902 |                    1 |
    | DEFAULT_0e65d_00004 | RUNNING  |                 |            4 |   64 |  256 | 0.000102859 |         |            |                      |
    | DEFAULT_0e65d_00005 | RUNNING  |                 |            8 |  128 |   64 | 0.000219673 |         |            |                      |
    | DEFAULT_0e65d_00006 | RUNNING  |                 |           16 |   16 |  128 | 0.0107294   |         |            |                      |
    | DEFAULT_0e65d_00007 | RUNNING  |                 |            2 |  128 |   64 | 0.0433275   |         |            |                      |
    | DEFAULT_0e65d_00008 | RUNNING  |                 |            8 |   16 |   16 | 0.0667362   |         |            |                      |
    | DEFAULT_0e65d_00009 | RUNNING  |                 |            2 |   16 |   64 | 0.0608499   |         |            |                      |
    +---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_0e65d_00006:
      accuracy: 0.4196
      date: 2021-05-04_19-30-02
      done: false
      experiment_id: d4ef0cc3c4f34cf9af14477f8fdb8e88
      hostname: d26a977e64c3
      iterations_since_restore: 1
      loss: 1.6051800449371338
      node_ip: 172.17.0.2
      pid: 1462
      should_checkpoint: true
      time_since_restore: 26.64230442047119
      time_this_iter_s: 26.64230442047119
      time_total_s: 26.64230442047119
      timestamp: 1620156602
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 0e65d_00006
  
    Result for DEFAULT_0e65d_00000:
      accuracy: 0.3681
      date: 2021-05-04_19-30-02
      done: false
      experiment_id: 1eaf24623d0b4075a5dd1fa933868158
      hostname: d26a977e64c3
      iterations_since_restore: 1
      loss: 1.6695699558258057
      node_ip: 172.17.0.2
      pid: 1491
      should_checkpoint: true
      time_since_restore: 27.02587080001831
      time_this_iter_s: 27.02587080001831
      time_total_s: 27.02587080001831
      timestamp: 1620156602
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 0e65d_00000
  
    [2m[36m(pid=1486)[0m [1,  4000] loss: 1.177
    [2m[36m(pid=1501)[0m [1,  4000] loss: 1.083
    [2m[36m(pid=1450)[0m [1,  4000] loss: 1.161
    [2m[36m(pid=1466)[0m [1,  4000] loss: 1.149
    [2m[36m(pid=1481)[0m [1,  4000] loss: 0.772
    [2m[36m(pid=1449)[0m [1,  6000] loss: 0.788
    [2m[36m(pid=1502)[0m [1,  6000] loss: 0.755
    [2m[36m(pid=1486)[0m [1,  6000] loss: 0.785
    Result for DEFAULT_0e65d_00008:
      accuracy: 0.1009
      date: 2021-05-04_19-30-16
      done: true
      experiment_id: dda0773a77c64a24a1f6230c254df7c9
      hostname: d26a977e64c3
      iterations_since_restore: 1
      loss: 2.315392397117615
      node_ip: 172.17.0.2
      pid: 1450
      should_checkpoint: true
      time_since_restore: 40.51223421096802
      time_this_iter_s: 40.51223421096802
      time_total_s: 40.51223421096802
      timestamp: 1620156616
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 0e65d_00008
  
    == Status ==
    Memory usage on this node: 9.7/240.1 GiB
    Using AsyncHyperBand: num_stopped=1
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.7913494777679444
    Resources requested: 20.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (10 RUNNING)
    +---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status   | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00000 | RUNNING  | 172.17.0.2:1491 |           16 |    4 |   32 | 0.00882003  | 1.66957 |     0.3681 |                    1 |
    | DEFAULT_0e65d_00001 | RUNNING  |                 |            8 |  256 |  128 | 0.00398049  |         |            |                      |
    | DEFAULT_0e65d_00002 | RUNNING  |                 |            2 |  256 |   64 | 0.00922119  |         |            |                      |
    | DEFAULT_0e65d_00003 | RUNNING  | 172.17.0.2:1487 |           16 |   16 |   64 | 0.000883321 | 1.91313 |     0.2902 |                    1 |
    | DEFAULT_0e65d_00004 | RUNNING  |                 |            4 |   64 |  256 | 0.000102859 |         |            |                      |
    | DEFAULT_0e65d_00005 | RUNNING  |                 |            8 |  128 |   64 | 0.000219673 |         |            |                      |
    | DEFAULT_0e65d_00006 | RUNNING  | 172.17.0.2:1462 |           16 |   16 |  128 | 0.0107294   | 1.60518 |     0.4196 |                    1 |
    | DEFAULT_0e65d_00007 | RUNNING  |                 |            2 |  128 |   64 | 0.0433275   |         |            |                      |
    | DEFAULT_0e65d_00008 | RUNNING  | 172.17.0.2:1450 |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    | DEFAULT_0e65d_00009 | RUNNING  |                 |            2 |   16 |   64 | 0.0608499   |         |            |                      |
    +---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1501)[0m [1,  6000] loss: 0.724
    Result for DEFAULT_0e65d_00005:
      accuracy: 0.1541
      date: 2021-05-04_19-30-16
      done: true
      experiment_id: 4e359bb605764225b4031ba58a1c2bde
      hostname: d26a977e64c3
      iterations_since_restore: 1
      loss: 2.274135831260681
      node_ip: 172.17.0.2
      pid: 1466
      should_checkpoint: true
      time_since_restore: 41.200536489486694
      time_this_iter_s: 41.200536489486694
      time_total_s: 41.200536489486694
      timestamp: 1620156616
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 0e65d_00005
  
    Result for DEFAULT_0e65d_00001:
      accuracy: 0.461
      date: 2021-05-04_19-30-17
      done: false
      experiment_id: 63f35ea355be46cf8f5dbffd61170f3b
      hostname: d26a977e64c3
      iterations_since_restore: 1
      loss: 1.4611683300256728
      node_ip: 172.17.0.2
      pid: 1481
      should_checkpoint: true
      time_since_restore: 42.22592210769653
      time_this_iter_s: 42.22592210769653
      time_total_s: 42.22592210769653
      timestamp: 1620156617
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 0e65d_00001
  
    [2m[36m(pid=1491)[0m [2,  2000] loss: 1.622
    [2m[36m(pid=1487)[0m [2,  2000] loss: 1.751
    [2m[36m(pid=1462)[0m [2,  2000] loss: 1.531
    [2m[36m(pid=1449)[0m [1,  8000] loss: 0.594
    [2m[36m(pid=1502)[0m [1,  8000] loss: 0.545
    Result for DEFAULT_0e65d_00000:
      accuracy: 0.4034
      date: 2021-05-04_19-30-24
      done: false
      experiment_id: 1eaf24623d0b4075a5dd1fa933868158
      hostname: d26a977e64c3
      iterations_since_restore: 2
      loss: 1.6155211853027345
      node_ip: 172.17.0.2
      pid: 1491
      should_checkpoint: true
      time_since_restore: 48.77045464515686
      time_this_iter_s: 21.74458384513855
      time_total_s: 48.77045464515686
      timestamp: 1620156624
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: 0e65d_00000
  
    == Status ==
    Memory usage on this node: 8.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.6155211853027345 | Iter 1.000: -1.7913494777679444
    Resources requested: 16.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00000 | RUNNING    | 172.17.0.2:1491 |           16 |    4 |   32 | 0.00882003  | 1.61552 |     0.4034 |                    2 |
    | DEFAULT_0e65d_00001 | RUNNING    | 172.17.0.2:1481 |            8 |  256 |  128 | 0.00398049  | 1.46117 |     0.461  |                    1 |
    | DEFAULT_0e65d_00002 | RUNNING    |                 |            2 |  256 |   64 | 0.00922119  |         |            |                      |
    | DEFAULT_0e65d_00003 | RUNNING    | 172.17.0.2:1487 |           16 |   16 |   64 | 0.000883321 | 1.91313 |     0.2902 |                    1 |
    | DEFAULT_0e65d_00004 | RUNNING    |                 |            4 |   64 |  256 | 0.000102859 |         |            |                      |
    | DEFAULT_0e65d_00006 | RUNNING    | 172.17.0.2:1462 |           16 |   16 |  128 | 0.0107294   | 1.60518 |     0.4196 |                    1 |
    | DEFAULT_0e65d_00007 | RUNNING    |                 |            2 |  128 |   64 | 0.0433275   |         |            |                      |
    | DEFAULT_0e65d_00009 | RUNNING    |                 |            2 |   16 |   64 | 0.0608499   |         |            |                      |
    | DEFAULT_0e65d_00005 | TERMINATED |                 |            8 |  128 |   64 | 0.000219673 | 2.27414 |     0.1541 |                    1 |
    | DEFAULT_0e65d_00008 | TERMINATED |                 |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_0e65d_00006:
      accuracy: 0.4653
      date: 2021-05-04_19-30-24
      done: false
      experiment_id: d4ef0cc3c4f34cf9af14477f8fdb8e88
      hostname: d26a977e64c3
      iterations_since_restore: 2
      loss: 1.461721660232544
      node_ip: 172.17.0.2
      pid: 1462
      should_checkpoint: true
      time_since_restore: 48.93205976486206
      time_this_iter_s: 22.28975534439087
      time_total_s: 48.93205976486206
      timestamp: 1620156624
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: 0e65d_00006
  
    Result for DEFAULT_0e65d_00003:
      accuracy: 0.4232
      date: 2021-05-04_19-30-24
      done: true
      experiment_id: 0766ccfb272d4fdfa7b1b4e6a2bc2e69
      hostname: d26a977e64c3
      iterations_since_restore: 2
      loss: 1.55569115858078
      node_ip: 172.17.0.2
      pid: 1487
      should_checkpoint: true
      time_since_restore: 49.06973052024841
      time_this_iter_s: 22.470927953720093
      time_total_s: 49.06973052024841
      timestamp: 1620156624
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: 0e65d_00003
  
    [2m[36m(pid=1486)[0m [1,  8000] loss: 0.588
    [2m[36m(pid=1449)[0m [1, 10000] loss: 0.475
    [2m[36m(pid=1501)[0m [1,  8000] loss: 0.540
    [2m[36m(pid=1481)[0m [2,  2000] loss: 1.383
    [2m[36m(pid=1502)[0m [1, 10000] loss: 0.420
    [2m[36m(pid=1486)[0m [1, 10000] loss: 0.470
    [2m[36m(pid=1449)[0m [1, 12000] loss: 0.396
    [2m[36m(pid=1491)[0m [3,  2000] loss: 1.584
    [2m[36m(pid=1462)[0m [3,  2000] loss: 1.481
    Result for DEFAULT_0e65d_00004:
      accuracy: 0.2621
      date: 2021-05-04_19-30-40
      done: true
      experiment_id: bc720862a00a4a68af1ba2102faa8b5c
      hostname: d26a977e64c3
      iterations_since_restore: 1
      loss: 2.066939203310013
      node_ip: 172.17.0.2
      pid: 1502
      should_checkpoint: true
      time_since_restore: 64.99631524085999
      time_this_iter_s: 64.99631524085999
      time_total_s: 64.99631524085999
      timestamp: 1620156640
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 0e65d_00004
  
    == Status ==
    Memory usage on this node: 8.0/240.1 GiB
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.55569115858078 | Iter 1.000: -1.913128999710083
    Resources requested: 14.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00000 | RUNNING    | 172.17.0.2:1491 |           16 |    4 |   32 | 0.00882003  | 1.61552 |     0.4034 |                    2 |
    | DEFAULT_0e65d_00001 | RUNNING    | 172.17.0.2:1481 |            8 |  256 |  128 | 0.00398049  | 1.46117 |     0.461  |                    1 |
    | DEFAULT_0e65d_00002 | RUNNING    |                 |            2 |  256 |   64 | 0.00922119  |         |            |                      |
    | DEFAULT_0e65d_00004 | RUNNING    | 172.17.0.2:1502 |            4 |   64 |  256 | 0.000102859 | 2.06694 |     0.2621 |                    1 |
    | DEFAULT_0e65d_00006 | RUNNING    | 172.17.0.2:1462 |           16 |   16 |  128 | 0.0107294   | 1.46172 |     0.4653 |                    2 |
    | DEFAULT_0e65d_00007 | RUNNING    |                 |            2 |  128 |   64 | 0.0433275   |         |            |                      |
    | DEFAULT_0e65d_00009 | RUNNING    |                 |            2 |   16 |   64 | 0.0608499   |         |            |                      |
    | DEFAULT_0e65d_00003 | TERMINATED |                 |           16 |   16 |   64 | 0.000883321 | 1.55569 |     0.4232 |                    2 |
    | DEFAULT_0e65d_00005 | TERMINATED |                 |            8 |  128 |   64 | 0.000219673 | 2.27414 |     0.1541 |                    1 |
    | DEFAULT_0e65d_00008 | TERMINATED |                 |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1501)[0m [1, 10000] loss: 0.454
    [2m[36m(pid=1481)[0m [2,  4000] loss: 0.677
    Result for DEFAULT_0e65d_00000:
      accuracy: 0.4425
      date: 2021-05-04_19-30-43
      done: false
      experiment_id: 1eaf24623d0b4075a5dd1fa933868158
      hostname: d26a977e64c3
      iterations_since_restore: 3
      loss: 1.521465906906128
      node_ip: 172.17.0.2
      pid: 1491
      should_checkpoint: true
      time_since_restore: 68.42535853385925
      time_this_iter_s: 19.654903888702393
      time_total_s: 68.42535853385925
      timestamp: 1620156643
      timesteps_since_restore: 0
      training_iteration: 3
      trial_id: 0e65d_00000
  
    Result for DEFAULT_0e65d_00006:
      accuracy: 0.4627
      date: 2021-05-04_19-30-44
      done: false
      experiment_id: d4ef0cc3c4f34cf9af14477f8fdb8e88
      hostname: d26a977e64c3
      iterations_since_restore: 3
      loss: 1.498916006565094
      node_ip: 172.17.0.2
      pid: 1462
      should_checkpoint: true
      time_since_restore: 69.12565517425537
      time_this_iter_s: 20.19359540939331
      time_total_s: 69.12565517425537
      timestamp: 1620156644
      timesteps_since_restore: 0
      training_iteration: 3
      trial_id: 0e65d_00006
  
    [2m[36m(pid=1449)[0m [1, 14000] loss: 0.339
    [2m[36m(pid=1486)[0m [1, 12000] loss: 0.392
    Result for DEFAULT_0e65d_00001:
      accuracy: 0.5343
      date: 2021-05-04_19-30-51
      done: false
      experiment_id: 63f35ea355be46cf8f5dbffd61170f3b
      hostname: d26a977e64c3
      iterations_since_restore: 2
      loss: 1.3040977229833604
      node_ip: 172.17.0.2
      pid: 1481
      should_checkpoint: true
      time_since_restore: 76.07604479789734
      time_this_iter_s: 33.850122690200806
      time_total_s: 76.07604479789734
      timestamp: 1620156651
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: 0e65d_00001
  
    == Status ==
    Memory usage on this node: 7.4/240.1 GiB
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.508706409406662 | Iter 1.000: -1.913128999710083
    Resources requested: 12.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00000 | RUNNING    | 172.17.0.2:1491 |           16 |    4 |   32 | 0.00882003  | 1.52147 |     0.4425 |                    3 |
    | DEFAULT_0e65d_00001 | RUNNING    | 172.17.0.2:1481 |            8 |  256 |  128 | 0.00398049  | 1.3041  |     0.5343 |                    2 |
    | DEFAULT_0e65d_00002 | RUNNING    |                 |            2 |  256 |   64 | 0.00922119  |         |            |                      |
    | DEFAULT_0e65d_00006 | RUNNING    | 172.17.0.2:1462 |           16 |   16 |  128 | 0.0107294   | 1.49892 |     0.4627 |                    3 |
    | DEFAULT_0e65d_00007 | RUNNING    |                 |            2 |  128 |   64 | 0.0433275   |         |            |                      |
    | DEFAULT_0e65d_00009 | RUNNING    |                 |            2 |   16 |   64 | 0.0608499   |         |            |                      |
    | DEFAULT_0e65d_00003 | TERMINATED |                 |           16 |   16 |   64 | 0.000883321 | 1.55569 |     0.4232 |                    2 |
    | DEFAULT_0e65d_00004 | TERMINATED |                 |            4 |   64 |  256 | 0.000102859 | 2.06694 |     0.2621 |                    1 |
    | DEFAULT_0e65d_00005 | TERMINATED |                 |            8 |  128 |   64 | 0.000219673 | 2.27414 |     0.1541 |                    1 |
    | DEFAULT_0e65d_00008 | TERMINATED |                 |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1501)[0m [1, 12000] loss: 0.385
    [2m[36m(pid=1449)[0m [1, 16000] loss: 0.297
    [2m[36m(pid=1486)[0m [1, 14000] loss: 0.336
    [2m[36m(pid=1491)[0m [4,  2000] loss: 1.526
    [2m[36m(pid=1462)[0m [4,  2000] loss: 1.442
    [2m[36m(pid=1449)[0m [1, 18000] loss: 0.264
    [2m[36m(pid=1481)[0m [3,  2000] loss: 1.222
    Result for DEFAULT_0e65d_00000:
      accuracy: 0.4209
      date: 2021-05-04_19-31-03
      done: false
      experiment_id: 1eaf24623d0b4075a5dd1fa933868158
      hostname: d26a977e64c3
      iterations_since_restore: 4
      loss: 1.5625790387153626
      node_ip: 172.17.0.2
      pid: 1491
      should_checkpoint: true
      time_since_restore: 87.91511464118958
      time_this_iter_s: 19.489756107330322
      time_total_s: 87.91511464118958
      timestamp: 1620156663
      timesteps_since_restore: 0
      training_iteration: 4
      trial_id: 0e65d_00000
  
    == Status ==
    Memory usage on this node: 7.5/240.1 GiB
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: -1.5625790387153626 | Iter 2.000: -1.508706409406662 | Iter 1.000: -1.913128999710083
    Resources requested: 12.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00000 | RUNNING    | 172.17.0.2:1491 |           16 |    4 |   32 | 0.00882003  | 1.56258 |     0.4209 |                    4 |
    | DEFAULT_0e65d_00001 | RUNNING    | 172.17.0.2:1481 |            8 |  256 |  128 | 0.00398049  | 1.3041  |     0.5343 |                    2 |
    | DEFAULT_0e65d_00002 | RUNNING    |                 |            2 |  256 |   64 | 0.00922119  |         |            |                      |
    | DEFAULT_0e65d_00006 | RUNNING    | 172.17.0.2:1462 |           16 |   16 |  128 | 0.0107294   | 1.49892 |     0.4627 |                    3 |
    | DEFAULT_0e65d_00007 | RUNNING    |                 |            2 |  128 |   64 | 0.0433275   |         |            |                      |
    | DEFAULT_0e65d_00009 | RUNNING    |                 |            2 |   16 |   64 | 0.0608499   |         |            |                      |
    | DEFAULT_0e65d_00003 | TERMINATED |                 |           16 |   16 |   64 | 0.000883321 | 1.55569 |     0.4232 |                    2 |
    | DEFAULT_0e65d_00004 | TERMINATED |                 |            4 |   64 |  256 | 0.000102859 | 2.06694 |     0.2621 |                    1 |
    | DEFAULT_0e65d_00005 | TERMINATED |                 |            8 |  128 |   64 | 0.000219673 | 2.27414 |     0.1541 |                    1 |
    | DEFAULT_0e65d_00008 | TERMINATED |                 |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_0e65d_00006:
      accuracy: 0.5016
      date: 2021-05-04_19-31-04
      done: false
      experiment_id: d4ef0cc3c4f34cf9af14477f8fdb8e88
      hostname: d26a977e64c3
      iterations_since_restore: 4
      loss: 1.4139432209014893
      node_ip: 172.17.0.2
      pid: 1462
      should_checkpoint: true
      time_since_restore: 88.8046281337738
      time_this_iter_s: 19.678972959518433
      time_total_s: 88.8046281337738
      timestamp: 1620156664
      timesteps_since_restore: 0
      training_iteration: 4
      trial_id: 0e65d_00006
  
    [2m[36m(pid=1501)[0m [1, 14000] loss: 0.330
    [2m[36m(pid=1486)[0m [1, 16000] loss: 0.294
    [2m[36m(pid=1449)[0m [1, 20000] loss: 0.237
    [2m[36m(pid=1481)[0m [3,  4000] loss: 0.614
    [2m[36m(pid=1491)[0m [5,  2000] loss: 1.493
    [2m[36m(pid=1486)[0m [1, 18000] loss: 0.261
    [2m[36m(pid=1462)[0m [5,  2000] loss: 1.426
    [2m[36m(pid=1501)[0m [1, 16000] loss: 0.289
    Result for DEFAULT_0e65d_00000:
      accuracy: 0.4434
      date: 2021-05-04_19-31-22
      done: false
      experiment_id: 1eaf24623d0b4075a5dd1fa933868158
      hostname: d26a977e64c3
      iterations_since_restore: 5
      loss: 1.5412607893943786
      node_ip: 172.17.0.2
      pid: 1491
      should_checkpoint: true
      time_since_restore: 107.25886249542236
      time_this_iter_s: 19.343747854232788
      time_total_s: 107.25886249542236
      timestamp: 1620156682
      timesteps_since_restore: 0
      training_iteration: 5
      trial_id: 0e65d_00000
  
    == Status ==
    Memory usage on this node: 7.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: -1.4882611298084258 | Iter 2.000: -1.508706409406662 | Iter 1.000: -1.913128999710083
    Resources requested: 12.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00000 | RUNNING    | 172.17.0.2:1491 |           16 |    4 |   32 | 0.00882003  | 1.54126 |     0.4434 |                    5 |
    | DEFAULT_0e65d_00001 | RUNNING    | 172.17.0.2:1481 |            8 |  256 |  128 | 0.00398049  | 1.3041  |     0.5343 |                    2 |
    | DEFAULT_0e65d_00002 | RUNNING    |                 |            2 |  256 |   64 | 0.00922119  |         |            |                      |
    | DEFAULT_0e65d_00006 | RUNNING    | 172.17.0.2:1462 |           16 |   16 |  128 | 0.0107294   | 1.41394 |     0.5016 |                    4 |
    | DEFAULT_0e65d_00007 | RUNNING    |                 |            2 |  128 |   64 | 0.0433275   |         |            |                      |
    | DEFAULT_0e65d_00009 | RUNNING    |                 |            2 |   16 |   64 | 0.0608499   |         |            |                      |
    | DEFAULT_0e65d_00003 | TERMINATED |                 |           16 |   16 |   64 | 0.000883321 | 1.55569 |     0.4232 |                    2 |
    | DEFAULT_0e65d_00004 | TERMINATED |                 |            4 |   64 |  256 | 0.000102859 | 2.06694 |     0.2621 |                    1 |
    | DEFAULT_0e65d_00005 | TERMINATED |                 |            8 |  128 |   64 | 0.000219673 | 2.27414 |     0.1541 |                    1 |
    | DEFAULT_0e65d_00008 | TERMINATED |                 |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_0e65d_00009:
      accuracy: 0.1041
      date: 2021-05-04_19-31-23
      done: true
      experiment_id: 3e2e979d46cd4636bf3bc3bdf643c9fc
      hostname: d26a977e64c3
      iterations_since_restore: 1
      loss: 2.3736762499809263
      node_ip: 172.17.0.2
      pid: 1449
      should_checkpoint: true
      time_since_restore: 108.2111177444458
      time_this_iter_s: 108.2111177444458
      time_total_s: 108.2111177444458
      timestamp: 1620156683
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 0e65d_00009
  
    Result for DEFAULT_0e65d_00006:
      accuracy: 0.4787
      date: 2021-05-04_19-31-23
      done: false
      experiment_id: d4ef0cc3c4f34cf9af14477f8fdb8e88
      hostname: d26a977e64c3
      iterations_since_restore: 5
      loss: 1.466765908718109
      node_ip: 172.17.0.2
      pid: 1462
      should_checkpoint: true
      time_since_restore: 108.3872857093811
      time_this_iter_s: 19.5826575756073
      time_total_s: 108.3872857093811
      timestamp: 1620156683
      timesteps_since_restore: 0
      training_iteration: 5
      trial_id: 0e65d_00006
  
    Result for DEFAULT_0e65d_00001:
      accuracy: 0.5576
      date: 2021-05-04_19-31-24
      done: false
      experiment_id: 63f35ea355be46cf8f5dbffd61170f3b
      hostname: d26a977e64c3
      iterations_since_restore: 3
      loss: 1.2620245999574662
      node_ip: 172.17.0.2
      pid: 1481
      should_checkpoint: true
      time_since_restore: 109.07495045661926
      time_this_iter_s: 32.998905658721924
      time_total_s: 109.07495045661926
      timestamp: 1620156684
      timesteps_since_restore: 0
      training_iteration: 3
      trial_id: 0e65d_00001
  
    [2m[36m(pid=1486)[0m [1, 20000] loss: 0.235
    [2m[36m(pid=1501)[0m [1, 18000] loss: 0.257
    [2m[36m(pid=1481)[0m [4,  2000] loss: 1.132
    [2m[36m(pid=1491)[0m [6,  2000] loss: 1.479
    [2m[36m(pid=1462)[0m [6,  2000] loss: 1.406
    Result for DEFAULT_0e65d_00007:
      accuracy: 0.102
      date: 2021-05-04_19-31-39
      done: true
      experiment_id: eefd5f2f37e04512ac3810de012778d2
      hostname: d26a977e64c3
      iterations_since_restore: 1
      loss: 2.3489015910625457
      node_ip: 172.17.0.2
      pid: 1486
      should_checkpoint: true
      time_since_restore: 124.15368175506592
      time_this_iter_s: 124.15368175506592
      time_total_s: 124.15368175506592
      timestamp: 1620156699
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 0e65d_00007
  
    == Status ==
    Memory usage on this node: 7.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.4882611298084258 | Iter 2.000: -1.508706409406662 | Iter 1.000: -2.066939203310013
    Resources requested: 10.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00000 | RUNNING    | 172.17.0.2:1491 |           16 |    4 |   32 | 0.00882003  | 1.54126 |     0.4434 |                    5 |
    | DEFAULT_0e65d_00001 | RUNNING    | 172.17.0.2:1481 |            8 |  256 |  128 | 0.00398049  | 1.26202 |     0.5576 |                    3 |
    | DEFAULT_0e65d_00002 | RUNNING    |                 |            2 |  256 |   64 | 0.00922119  |         |            |                      |
    | DEFAULT_0e65d_00006 | RUNNING    | 172.17.0.2:1462 |           16 |   16 |  128 | 0.0107294   | 1.46677 |     0.4787 |                    5 |
    | DEFAULT_0e65d_00007 | RUNNING    | 172.17.0.2:1486 |            2 |  128 |   64 | 0.0433275   | 2.3489  |     0.102  |                    1 |
    | DEFAULT_0e65d_00003 | TERMINATED |                 |           16 |   16 |   64 | 0.000883321 | 1.55569 |     0.4232 |                    2 |
    | DEFAULT_0e65d_00004 | TERMINATED |                 |            4 |   64 |  256 | 0.000102859 | 2.06694 |     0.2621 |                    1 |
    | DEFAULT_0e65d_00005 | TERMINATED |                 |            8 |  128 |   64 | 0.000219673 | 2.27414 |     0.1541 |                    1 |
    | DEFAULT_0e65d_00008 | TERMINATED |                 |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    | DEFAULT_0e65d_00009 | TERMINATED |                 |            2 |   16 |   64 | 0.0608499   | 2.37368 |     0.1041 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_0e65d_00000:
      accuracy: 0.4621
      date: 2021-05-04_19-31-41
      done: false
      experiment_id: 1eaf24623d0b4075a5dd1fa933868158
      hostname: d26a977e64c3
      iterations_since_restore: 6
      loss: 1.4863485397338867
      node_ip: 172.17.0.2
      pid: 1491
      should_checkpoint: true
      time_since_restore: 126.0236120223999
      time_this_iter_s: 18.76474952697754
      time_total_s: 126.0236120223999
      timestamp: 1620156701
      timesteps_since_restore: 0
      training_iteration: 6
      trial_id: 0e65d_00000
  
    [2m[36m(pid=1501)[0m [1, 20000] loss: 0.231
    Result for DEFAULT_0e65d_00006:
      accuracy: 0.4826
      date: 2021-05-04_19-31-43
      done: false
      experiment_id: d4ef0cc3c4f34cf9af14477f8fdb8e88
      hostname: d26a977e64c3
      iterations_since_restore: 6
      loss: 1.512270620918274
      node_ip: 172.17.0.2
      pid: 1462
      should_checkpoint: true
      time_since_restore: 127.77107858657837
      time_this_iter_s: 19.383792877197266
      time_total_s: 127.77107858657837
      timestamp: 1620156703
      timesteps_since_restore: 0
      training_iteration: 6
      trial_id: 0e65d_00006
  
    [2m[36m(pid=1481)[0m [4,  4000] loss: 0.566
    Result for DEFAULT_0e65d_00002:
      accuracy: 0.1023
      date: 2021-05-04_19-31-54
      done: true
      experiment_id: d24541ff590847aaaa19e9f5a891572a
      hostname: d26a977e64c3
      iterations_since_restore: 1
      loss: 2.315258004331589
      node_ip: 172.17.0.2
      pid: 1501
      should_checkpoint: true
      time_since_restore: 138.96641421318054
      time_this_iter_s: 138.96641421318054
      time_total_s: 138.96641421318054
      timestamp: 1620156714
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 0e65d_00002
  
    [2m[36m(pid=1491)[0m [7,  2000] loss: 1.470
    == Status ==
    Memory usage on this node: 6.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.4882611298084258 | Iter 2.000: -1.508706409406662 | Iter 1.000: -2.170537517285347
    Resources requested: 8.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00000 | RUNNING    | 172.17.0.2:1491 |           16 |    4 |   32 | 0.00882003  | 1.48635 |     0.4621 |                    6 |
    | DEFAULT_0e65d_00001 | RUNNING    | 172.17.0.2:1481 |            8 |  256 |  128 | 0.00398049  | 1.26202 |     0.5576 |                    3 |
    | DEFAULT_0e65d_00002 | RUNNING    | 172.17.0.2:1501 |            2 |  256 |   64 | 0.00922119  | 2.31526 |     0.1023 |                    1 |
    | DEFAULT_0e65d_00006 | RUNNING    | 172.17.0.2:1462 |           16 |   16 |  128 | 0.0107294   | 1.51227 |     0.4826 |                    6 |
    | DEFAULT_0e65d_00003 | TERMINATED |                 |           16 |   16 |   64 | 0.000883321 | 1.55569 |     0.4232 |                    2 |
    | DEFAULT_0e65d_00004 | TERMINATED |                 |            4 |   64 |  256 | 0.000102859 | 2.06694 |     0.2621 |                    1 |
    | DEFAULT_0e65d_00005 | TERMINATED |                 |            8 |  128 |   64 | 0.000219673 | 2.27414 |     0.1541 |                    1 |
    | DEFAULT_0e65d_00007 | TERMINATED |                 |            2 |  128 |   64 | 0.0433275   | 2.3489  |     0.102  |                    1 |
    | DEFAULT_0e65d_00008 | TERMINATED |                 |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    | DEFAULT_0e65d_00009 | TERMINATED |                 |            2 |   16 |   64 | 0.0608499   | 2.37368 |     0.1041 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_0e65d_00001:
      accuracy: 0.5825
      date: 2021-05-04_19-31-56
      done: false
      experiment_id: 63f35ea355be46cf8f5dbffd61170f3b
      hostname: d26a977e64c3
      iterations_since_restore: 4
      loss: 1.215434804648161
      node_ip: 172.17.0.2
      pid: 1481
      should_checkpoint: true
      time_since_restore: 140.82441306114197
      time_this_iter_s: 31.749462604522705
      time_total_s: 140.82441306114197
      timestamp: 1620156716
      timesteps_since_restore: 0
      training_iteration: 4
      trial_id: 0e65d_00001
  
    [2m[36m(pid=1462)[0m [7,  2000] loss: 1.388
    Result for DEFAULT_0e65d_00000:
      accuracy: 0.4666
      date: 2021-05-04_19-32-00
      done: false
      experiment_id: 1eaf24623d0b4075a5dd1fa933868158
      hostname: d26a977e64c3
      iterations_since_restore: 7
      loss: 1.4724391136169435
      node_ip: 172.17.0.2
      pid: 1491
      should_checkpoint: true
      time_since_restore: 144.531813621521
      time_this_iter_s: 18.508201599121094
      time_total_s: 144.531813621521
      timestamp: 1620156720
      timesteps_since_restore: 0
      training_iteration: 7
      trial_id: 0e65d_00000
  
    == Status ==
    Memory usage on this node: 6.0/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.4139432209014893 | Iter 2.000: -1.508706409406662 | Iter 1.000: -2.170537517285347
    Resources requested: 6.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00000 | RUNNING    | 172.17.0.2:1491 |           16 |    4 |   32 | 0.00882003  | 1.47244 |     0.4666 |                    7 |
    | DEFAULT_0e65d_00001 | RUNNING    | 172.17.0.2:1481 |            8 |  256 |  128 | 0.00398049  | 1.21543 |     0.5825 |                    4 |
    | DEFAULT_0e65d_00006 | RUNNING    | 172.17.0.2:1462 |           16 |   16 |  128 | 0.0107294   | 1.51227 |     0.4826 |                    6 |
    | DEFAULT_0e65d_00002 | TERMINATED |                 |            2 |  256 |   64 | 0.00922119  | 2.31526 |     0.1023 |                    1 |
    | DEFAULT_0e65d_00003 | TERMINATED |                 |           16 |   16 |   64 | 0.000883321 | 1.55569 |     0.4232 |                    2 |
    | DEFAULT_0e65d_00004 | TERMINATED |                 |            4 |   64 |  256 | 0.000102859 | 2.06694 |     0.2621 |                    1 |
    | DEFAULT_0e65d_00005 | TERMINATED |                 |            8 |  128 |   64 | 0.000219673 | 2.27414 |     0.1541 |                    1 |
    | DEFAULT_0e65d_00007 | TERMINATED |                 |            2 |  128 |   64 | 0.0433275   | 2.3489  |     0.102  |                    1 |
    | DEFAULT_0e65d_00008 | TERMINATED |                 |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    | DEFAULT_0e65d_00009 | TERMINATED |                 |            2 |   16 |   64 | 0.0608499   | 2.37368 |     0.1041 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_0e65d_00006:
      accuracy: 0.485
      date: 2021-05-04_19-32-01
      done: false
      experiment_id: d4ef0cc3c4f34cf9af14477f8fdb8e88
      hostname: d26a977e64c3
      iterations_since_restore: 7
      loss: 1.5252561663627624
      node_ip: 172.17.0.2
      pid: 1462
      should_checkpoint: true
      time_since_restore: 146.3997232913971
      time_this_iter_s: 18.628644704818726
      time_total_s: 146.3997232913971
      timestamp: 1620156721
      timesteps_since_restore: 0
      training_iteration: 7
      trial_id: 0e65d_00006
  
    [2m[36m(pid=1481)[0m [5,  2000] loss: 1.044
    [2m[36m(pid=1491)[0m [8,  2000] loss: 1.473
    [2m[36m(pid=1462)[0m [8,  2000] loss: 1.388
    [2m[36m(pid=1481)[0m [5,  4000] loss: 0.524
    Result for DEFAULT_0e65d_00000:
      accuracy: 0.4468
      date: 2021-05-04_19-32-18
      done: false
      experiment_id: 1eaf24623d0b4075a5dd1fa933868158
      hostname: d26a977e64c3
      iterations_since_restore: 8
      loss: 1.5207134387969972
      node_ip: 172.17.0.2
      pid: 1491
      should_checkpoint: true
      time_since_restore: 162.5825333595276
      time_this_iter_s: 18.050719738006592
      time_total_s: 162.5825333595276
      timestamp: 1620156738
      timesteps_since_restore: 0
      training_iteration: 8
      trial_id: 0e65d_00000
  
    == Status ==
    Memory usage on this node: 6.0/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.5207134387969972 | Iter 4.000: -1.4139432209014893 | Iter 2.000: -1.508706409406662 | Iter 1.000: -2.170537517285347
    Resources requested: 6.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00000 | RUNNING    | 172.17.0.2:1491 |           16 |    4 |   32 | 0.00882003  | 1.52071 |     0.4468 |                    8 |
    | DEFAULT_0e65d_00001 | RUNNING    | 172.17.0.2:1481 |            8 |  256 |  128 | 0.00398049  | 1.21543 |     0.5825 |                    4 |
    | DEFAULT_0e65d_00006 | RUNNING    | 172.17.0.2:1462 |           16 |   16 |  128 | 0.0107294   | 1.52526 |     0.485  |                    7 |
    | DEFAULT_0e65d_00002 | TERMINATED |                 |            2 |  256 |   64 | 0.00922119  | 2.31526 |     0.1023 |                    1 |
    | DEFAULT_0e65d_00003 | TERMINATED |                 |           16 |   16 |   64 | 0.000883321 | 1.55569 |     0.4232 |                    2 |
    | DEFAULT_0e65d_00004 | TERMINATED |                 |            4 |   64 |  256 | 0.000102859 | 2.06694 |     0.2621 |                    1 |
    | DEFAULT_0e65d_00005 | TERMINATED |                 |            8 |  128 |   64 | 0.000219673 | 2.27414 |     0.1541 |                    1 |
    | DEFAULT_0e65d_00007 | TERMINATED |                 |            2 |  128 |   64 | 0.0433275   | 2.3489  |     0.102  |                    1 |
    | DEFAULT_0e65d_00008 | TERMINATED |                 |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    | DEFAULT_0e65d_00009 | TERMINATED |                 |            2 |   16 |   64 | 0.0608499   | 2.37368 |     0.1041 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_0e65d_00006:
      accuracy: 0.5013
      date: 2021-05-04_19-32-20
      done: false
      experiment_id: d4ef0cc3c4f34cf9af14477f8fdb8e88
      hostname: d26a977e64c3
      iterations_since_restore: 8
      loss: 1.4262669347763062
      node_ip: 172.17.0.2
      pid: 1462
      should_checkpoint: true
      time_since_restore: 164.8933093547821
      time_this_iter_s: 18.49358606338501
      time_total_s: 164.8933093547821
      timestamp: 1620156740
      timesteps_since_restore: 0
      training_iteration: 8
      trial_id: 0e65d_00006
  
    Result for DEFAULT_0e65d_00001:
      accuracy: 0.5912
      date: 2021-05-04_19-32-27
      done: false
      experiment_id: 63f35ea355be46cf8f5dbffd61170f3b
      hostname: d26a977e64c3
      iterations_since_restore: 5
      loss: 1.2385118064045906
      node_ip: 172.17.0.2
      pid: 1481
      should_checkpoint: true
      time_since_restore: 171.8544566631317
      time_this_iter_s: 31.030043601989746
      time_total_s: 171.8544566631317
      timestamp: 1620156747
      timesteps_since_restore: 0
      training_iteration: 5
      trial_id: 0e65d_00001
  
    == Status ==
    Memory usage on this node: 6.0/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4734901867866517 | Iter 4.000: -1.4139432209014893 | Iter 2.000: -1.508706409406662 | Iter 1.000: -2.170537517285347
    Resources requested: 6.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00000 | RUNNING    | 172.17.0.2:1491 |           16 |    4 |   32 | 0.00882003  | 1.52071 |     0.4468 |                    8 |
    | DEFAULT_0e65d_00001 | RUNNING    | 172.17.0.2:1481 |            8 |  256 |  128 | 0.00398049  | 1.23851 |     0.5912 |                    5 |
    | DEFAULT_0e65d_00006 | RUNNING    | 172.17.0.2:1462 |           16 |   16 |  128 | 0.0107294   | 1.42627 |     0.5013 |                    8 |
    | DEFAULT_0e65d_00002 | TERMINATED |                 |            2 |  256 |   64 | 0.00922119  | 2.31526 |     0.1023 |                    1 |
    | DEFAULT_0e65d_00003 | TERMINATED |                 |           16 |   16 |   64 | 0.000883321 | 1.55569 |     0.4232 |                    2 |
    | DEFAULT_0e65d_00004 | TERMINATED |                 |            4 |   64 |  256 | 0.000102859 | 2.06694 |     0.2621 |                    1 |
    | DEFAULT_0e65d_00005 | TERMINATED |                 |            8 |  128 |   64 | 0.000219673 | 2.27414 |     0.1541 |                    1 |
    | DEFAULT_0e65d_00007 | TERMINATED |                 |            2 |  128 |   64 | 0.0433275   | 2.3489  |     0.102  |                    1 |
    | DEFAULT_0e65d_00008 | TERMINATED |                 |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    | DEFAULT_0e65d_00009 | TERMINATED |                 |            2 |   16 |   64 | 0.0608499   | 2.37368 |     0.1041 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1491)[0m [9,  2000] loss: 1.477
    [2m[36m(pid=1462)[0m [9,  2000] loss: 1.368
    Result for DEFAULT_0e65d_00000:
      accuracy: 0.4518
      date: 2021-05-04_19-32-36
      done: false
      experiment_id: 1eaf24623d0b4075a5dd1fa933868158
      hostname: d26a977e64c3
      iterations_since_restore: 9
      loss: 1.481254469871521
      node_ip: 172.17.0.2
      pid: 1491
      should_checkpoint: true
      time_since_restore: 180.7849245071411
      time_this_iter_s: 18.202391147613525
      time_total_s: 180.7849245071411
      timestamp: 1620156756
      timesteps_since_restore: 0
      training_iteration: 9
      trial_id: 0e65d_00000
  
    == Status ==
    Memory usage on this node: 6.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.4734901867866517 | Iter 4.000: -1.4139432209014893 | Iter 2.000: -1.508706409406662 | Iter 1.000: -2.170537517285347
    Resources requested: 6.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00000 | RUNNING    | 172.17.0.2:1491 |           16 |    4 |   32 | 0.00882003  | 1.48125 |     0.4518 |                    9 |
    | DEFAULT_0e65d_00001 | RUNNING    | 172.17.0.2:1481 |            8 |  256 |  128 | 0.00398049  | 1.23851 |     0.5912 |                    5 |
    | DEFAULT_0e65d_00006 | RUNNING    | 172.17.0.2:1462 |           16 |   16 |  128 | 0.0107294   | 1.42627 |     0.5013 |                    8 |
    | DEFAULT_0e65d_00002 | TERMINATED |                 |            2 |  256 |   64 | 0.00922119  | 2.31526 |     0.1023 |                    1 |
    | DEFAULT_0e65d_00003 | TERMINATED |                 |           16 |   16 |   64 | 0.000883321 | 1.55569 |     0.4232 |                    2 |
    | DEFAULT_0e65d_00004 | TERMINATED |                 |            4 |   64 |  256 | 0.000102859 | 2.06694 |     0.2621 |                    1 |
    | DEFAULT_0e65d_00005 | TERMINATED |                 |            8 |  128 |   64 | 0.000219673 | 2.27414 |     0.1541 |                    1 |
    | DEFAULT_0e65d_00007 | TERMINATED |                 |            2 |  128 |   64 | 0.0433275   | 2.3489  |     0.102  |                    1 |
    | DEFAULT_0e65d_00008 | TERMINATED |                 |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    | DEFAULT_0e65d_00009 | TERMINATED |                 |            2 |   16 |   64 | 0.0608499   | 2.37368 |     0.1041 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1481)[0m [6,  2000] loss: 0.967
    Result for DEFAULT_0e65d_00006:
      accuracy: 0.5065
      date: 2021-05-04_19-32-38
      done: false
      experiment_id: d4ef0cc3c4f34cf9af14477f8fdb8e88
      hostname: d26a977e64c3
      iterations_since_restore: 9
      loss: 1.4430820940017701
      node_ip: 172.17.0.2
      pid: 1462
      should_checkpoint: true
      time_since_restore: 183.35625767707825
      time_this_iter_s: 18.462948322296143
      time_total_s: 183.35625767707825
      timestamp: 1620156758
      timesteps_since_restore: 0
      training_iteration: 9
      trial_id: 0e65d_00006
  
    [2m[36m(pid=1481)[0m [6,  4000] loss: 0.506
    [2m[36m(pid=1491)[0m [10,  2000] loss: 1.463
    [2m[36m(pid=1462)[0m [10,  2000] loss: 1.366
    Result for DEFAULT_0e65d_00000:
      accuracy: 0.4555
      date: 2021-05-04_19-32-54
      done: true
      experiment_id: 1eaf24623d0b4075a5dd1fa933868158
      hostname: d26a977e64c3
      iterations_since_restore: 10
      loss: 1.4898220180511474
      node_ip: 172.17.0.2
      pid: 1491
      should_checkpoint: true
      time_since_restore: 198.93389225006104
      time_this_iter_s: 18.148967742919922
      time_total_s: 198.93389225006104
      timestamp: 1620156774
      timesteps_since_restore: 0
      training_iteration: 10
      trial_id: 0e65d_00000
  
    == Status ==
    Memory usage on this node: 6.2/240.1 GiB
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.4734901867866517 | Iter 4.000: -1.4139432209014893 | Iter 2.000: -1.508706409406662 | Iter 1.000: -2.170537517285347
    Resources requested: 6.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00000 | RUNNING    | 172.17.0.2:1491 |           16 |    4 |   32 | 0.00882003  | 1.48982 |     0.4555 |                   10 |
    | DEFAULT_0e65d_00001 | RUNNING    | 172.17.0.2:1481 |            8 |  256 |  128 | 0.00398049  | 1.23851 |     0.5912 |                    5 |
    | DEFAULT_0e65d_00006 | RUNNING    | 172.17.0.2:1462 |           16 |   16 |  128 | 0.0107294   | 1.44308 |     0.5065 |                    9 |
    | DEFAULT_0e65d_00002 | TERMINATED |                 |            2 |  256 |   64 | 0.00922119  | 2.31526 |     0.1023 |                    1 |
    | DEFAULT_0e65d_00003 | TERMINATED |                 |           16 |   16 |   64 | 0.000883321 | 1.55569 |     0.4232 |                    2 |
    | DEFAULT_0e65d_00004 | TERMINATED |                 |            4 |   64 |  256 | 0.000102859 | 2.06694 |     0.2621 |                    1 |
    | DEFAULT_0e65d_00005 | TERMINATED |                 |            8 |  128 |   64 | 0.000219673 | 2.27414 |     0.1541 |                    1 |
    | DEFAULT_0e65d_00007 | TERMINATED |                 |            2 |  128 |   64 | 0.0433275   | 2.3489  |     0.102  |                    1 |
    | DEFAULT_0e65d_00008 | TERMINATED |                 |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    | DEFAULT_0e65d_00009 | TERMINATED |                 |            2 |   16 |   64 | 0.0608499   | 2.37368 |     0.1041 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_0e65d_00006:
      accuracy: 0.5049
      date: 2021-05-04_19-32-57
      done: true
      experiment_id: d4ef0cc3c4f34cf9af14477f8fdb8e88
      hostname: d26a977e64c3
      iterations_since_restore: 10
      loss: 1.4274191477775573
      node_ip: 172.17.0.2
      pid: 1462
      should_checkpoint: true
      time_since_restore: 202.06366419792175
      time_this_iter_s: 18.707406520843506
      time_total_s: 202.06366419792175
      timestamp: 1620156777
      timesteps_since_restore: 0
      training_iteration: 10
      trial_id: 0e65d_00006
  
    Result for DEFAULT_0e65d_00001:
      accuracy: 0.6009
      date: 2021-05-04_19-32-57
      done: false
      experiment_id: 63f35ea355be46cf8f5dbffd61170f3b
      hostname: d26a977e64c3
      iterations_since_restore: 6
      loss: 1.2152387003123761
      node_ip: 172.17.0.2
      pid: 1481
      should_checkpoint: true
      time_since_restore: 202.52629375457764
      time_this_iter_s: 30.671837091445923
      time_total_s: 202.52629375457764
      timestamp: 1620156777
      timesteps_since_restore: 0
      training_iteration: 6
      trial_id: 0e65d_00001
  
    [2m[36m(pid=1481)[0m [7,  2000] loss: 0.909
    [2m[36m(pid=1481)[0m [7,  4000] loss: 0.484
    Result for DEFAULT_0e65d_00001:
      accuracy: 0.5915
      date: 2021-05-04_19-33-27
      done: false
      experiment_id: 63f35ea355be46cf8f5dbffd61170f3b
      hostname: d26a977e64c3
      iterations_since_restore: 7
      loss: 1.2488551921784878
      node_ip: 172.17.0.2
      pid: 1481
      should_checkpoint: true
      time_since_restore: 231.85702085494995
      time_this_iter_s: 29.330727100372314
      time_total_s: 231.85702085494995
      timestamp: 1620156807
      timesteps_since_restore: 0
      training_iteration: 7
      trial_id: 0e65d_00001
  
    == Status ==
    Memory usage on this node: 4.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4734901867866517 | Iter 4.000: -1.4139432209014893 | Iter 2.000: -1.508706409406662 | Iter 1.000: -2.170537517285347
    Resources requested: 2.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00001 | RUNNING    | 172.17.0.2:1481 |            8 |  256 |  128 | 0.00398049  | 1.24886 |     0.5915 |                    7 |
    | DEFAULT_0e65d_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.00882003  | 1.48982 |     0.4555 |                   10 |
    | DEFAULT_0e65d_00002 | TERMINATED |                 |            2 |  256 |   64 | 0.00922119  | 2.31526 |     0.1023 |                    1 |
    | DEFAULT_0e65d_00003 | TERMINATED |                 |           16 |   16 |   64 | 0.000883321 | 1.55569 |     0.4232 |                    2 |
    | DEFAULT_0e65d_00004 | TERMINATED |                 |            4 |   64 |  256 | 0.000102859 | 2.06694 |     0.2621 |                    1 |
    | DEFAULT_0e65d_00005 | TERMINATED |                 |            8 |  128 |   64 | 0.000219673 | 2.27414 |     0.1541 |                    1 |
    | DEFAULT_0e65d_00006 | TERMINATED |                 |           16 |   16 |  128 | 0.0107294   | 1.42742 |     0.5049 |                   10 |
    | DEFAULT_0e65d_00007 | TERMINATED |                 |            2 |  128 |   64 | 0.0433275   | 2.3489  |     0.102  |                    1 |
    | DEFAULT_0e65d_00008 | TERMINATED |                 |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    | DEFAULT_0e65d_00009 | TERMINATED |                 |            2 |   16 |   64 | 0.0608499   | 2.37368 |     0.1041 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1481)[0m [8,  2000] loss: 0.851
    [2m[36m(pid=1481)[0m [8,  4000] loss: 0.471
    Result for DEFAULT_0e65d_00001:
      accuracy: 0.5863
      date: 2021-05-04_19-33-56
      done: false
      experiment_id: 63f35ea355be46cf8f5dbffd61170f3b
      hostname: d26a977e64c3
      iterations_since_restore: 8
      loss: 1.2764753557324409
      node_ip: 172.17.0.2
      pid: 1481
      should_checkpoint: true
      time_since_restore: 261.10625863075256
      time_this_iter_s: 29.249237775802612
      time_total_s: 261.10625863075256
      timestamp: 1620156836
      timesteps_since_restore: 0
      training_iteration: 8
      trial_id: 0e65d_00001
  
    == Status ==
    Memory usage on this node: 4.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4262669347763062 | Iter 4.000: -1.4139432209014893 | Iter 2.000: -1.508706409406662 | Iter 1.000: -2.170537517285347
    Resources requested: 2.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00001 | RUNNING    | 172.17.0.2:1481 |            8 |  256 |  128 | 0.00398049  | 1.27648 |     0.5863 |                    8 |
    | DEFAULT_0e65d_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.00882003  | 1.48982 |     0.4555 |                   10 |
    | DEFAULT_0e65d_00002 | TERMINATED |                 |            2 |  256 |   64 | 0.00922119  | 2.31526 |     0.1023 |                    1 |
    | DEFAULT_0e65d_00003 | TERMINATED |                 |           16 |   16 |   64 | 0.000883321 | 1.55569 |     0.4232 |                    2 |
    | DEFAULT_0e65d_00004 | TERMINATED |                 |            4 |   64 |  256 | 0.000102859 | 2.06694 |     0.2621 |                    1 |
    | DEFAULT_0e65d_00005 | TERMINATED |                 |            8 |  128 |   64 | 0.000219673 | 2.27414 |     0.1541 |                    1 |
    | DEFAULT_0e65d_00006 | TERMINATED |                 |           16 |   16 |  128 | 0.0107294   | 1.42742 |     0.5049 |                   10 |
    | DEFAULT_0e65d_00007 | TERMINATED |                 |            2 |  128 |   64 | 0.0433275   | 2.3489  |     0.102  |                    1 |
    | DEFAULT_0e65d_00008 | TERMINATED |                 |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    | DEFAULT_0e65d_00009 | TERMINATED |                 |            2 |   16 |   64 | 0.0608499   | 2.37368 |     0.1041 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1481)[0m [9,  2000] loss: 0.840
    [2m[36m(pid=1481)[0m [9,  4000] loss: 0.453
    Result for DEFAULT_0e65d_00001:
      accuracy: 0.5957
      date: 2021-05-04_19-34-25
      done: false
      experiment_id: 63f35ea355be46cf8f5dbffd61170f3b
      hostname: d26a977e64c3
      iterations_since_restore: 9
      loss: 1.296759842377901
      node_ip: 172.17.0.2
      pid: 1481
      should_checkpoint: true
      time_since_restore: 290.0989992618561
      time_this_iter_s: 28.992740631103516
      time_total_s: 290.0989992618561
      timestamp: 1620156865
      timesteps_since_restore: 0
      training_iteration: 9
      trial_id: 0e65d_00001
  
    == Status ==
    Memory usage on this node: 4.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.4262669347763062 | Iter 4.000: -1.4139432209014893 | Iter 2.000: -1.508706409406662 | Iter 1.000: -2.170537517285347
    Resources requested: 2.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00001 | RUNNING    | 172.17.0.2:1481 |            8 |  256 |  128 | 0.00398049  | 1.29676 |     0.5957 |                    9 |
    | DEFAULT_0e65d_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.00882003  | 1.48982 |     0.4555 |                   10 |
    | DEFAULT_0e65d_00002 | TERMINATED |                 |            2 |  256 |   64 | 0.00922119  | 2.31526 |     0.1023 |                    1 |
    | DEFAULT_0e65d_00003 | TERMINATED |                 |           16 |   16 |   64 | 0.000883321 | 1.55569 |     0.4232 |                    2 |
    | DEFAULT_0e65d_00004 | TERMINATED |                 |            4 |   64 |  256 | 0.000102859 | 2.06694 |     0.2621 |                    1 |
    | DEFAULT_0e65d_00005 | TERMINATED |                 |            8 |  128 |   64 | 0.000219673 | 2.27414 |     0.1541 |                    1 |
    | DEFAULT_0e65d_00006 | TERMINATED |                 |           16 |   16 |  128 | 0.0107294   | 1.42742 |     0.5049 |                   10 |
    | DEFAULT_0e65d_00007 | TERMINATED |                 |            2 |  128 |   64 | 0.0433275   | 2.3489  |     0.102  |                    1 |
    | DEFAULT_0e65d_00008 | TERMINATED |                 |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    | DEFAULT_0e65d_00009 | TERMINATED |                 |            2 |   16 |   64 | 0.0608499   | 2.37368 |     0.1041 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1481)[0m [10,  2000] loss: 0.804
    [2m[36m(pid=1481)[0m [10,  4000] loss: 0.447
    Result for DEFAULT_0e65d_00001:
      accuracy: 0.5793
      date: 2021-05-04_19-34-54
      done: true
      experiment_id: 63f35ea355be46cf8f5dbffd61170f3b
      hostname: d26a977e64c3
      iterations_since_restore: 10
      loss: 1.3832154894173145
      node_ip: 172.17.0.2
      pid: 1481
      should_checkpoint: true
      time_since_restore: 319.4930753707886
      time_this_iter_s: 29.394076108932495
      time_total_s: 319.4930753707886
      timestamp: 1620156894
      timesteps_since_restore: 0
      training_iteration: 10
      trial_id: 0e65d_00001
  
    == Status ==
    Memory usage on this node: 4.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.4262669347763062 | Iter 4.000: -1.4139432209014893 | Iter 2.000: -1.508706409406662 | Iter 1.000: -2.170537517285347
    Resources requested: 2.0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00001 | RUNNING    | 172.17.0.2:1481 |            8 |  256 |  128 | 0.00398049  | 1.38322 |     0.5793 |                   10 |
    | DEFAULT_0e65d_00000 | TERMINATED |                 |           16 |    4 |   32 | 0.00882003  | 1.48982 |     0.4555 |                   10 |
    | DEFAULT_0e65d_00002 | TERMINATED |                 |            2 |  256 |   64 | 0.00922119  | 2.31526 |     0.1023 |                    1 |
    | DEFAULT_0e65d_00003 | TERMINATED |                 |           16 |   16 |   64 | 0.000883321 | 1.55569 |     0.4232 |                    2 |
    | DEFAULT_0e65d_00004 | TERMINATED |                 |            4 |   64 |  256 | 0.000102859 | 2.06694 |     0.2621 |                    1 |
    | DEFAULT_0e65d_00005 | TERMINATED |                 |            8 |  128 |   64 | 0.000219673 | 2.27414 |     0.1541 |                    1 |
    | DEFAULT_0e65d_00006 | TERMINATED |                 |           16 |   16 |  128 | 0.0107294   | 1.42742 |     0.5049 |                   10 |
    | DEFAULT_0e65d_00007 | TERMINATED |                 |            2 |  128 |   64 | 0.0433275   | 2.3489  |     0.102  |                    1 |
    | DEFAULT_0e65d_00008 | TERMINATED |                 |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    | DEFAULT_0e65d_00009 | TERMINATED |                 |            2 |   16 |   64 | 0.0608499   | 2.37368 |     0.1041 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    == Status ==
    Memory usage on this node: 4.5/240.1 GiB
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.4262669347763062 | Iter 4.000: -1.4139432209014893 | Iter 2.000: -1.508706409406662 | Iter 1.000: -2.170537517285347
    Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/220.17 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-05-04_19-29-34
    Number of trials: 10/10 (10 TERMINATED)
    +---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc   |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_0e65d_00000 | TERMINATED |       |           16 |    4 |   32 | 0.00882003  | 1.48982 |     0.4555 |                   10 |
    | DEFAULT_0e65d_00001 | TERMINATED |       |            8 |  256 |  128 | 0.00398049  | 1.38322 |     0.5793 |                   10 |
    | DEFAULT_0e65d_00002 | TERMINATED |       |            2 |  256 |   64 | 0.00922119  | 2.31526 |     0.1023 |                    1 |
    | DEFAULT_0e65d_00003 | TERMINATED |       |           16 |   16 |   64 | 0.000883321 | 1.55569 |     0.4232 |                    2 |
    | DEFAULT_0e65d_00004 | TERMINATED |       |            4 |   64 |  256 | 0.000102859 | 2.06694 |     0.2621 |                    1 |
    | DEFAULT_0e65d_00005 | TERMINATED |       |            8 |  128 |   64 | 0.000219673 | 2.27414 |     0.1541 |                    1 |
    | DEFAULT_0e65d_00006 | TERMINATED |       |           16 |   16 |  128 | 0.0107294   | 1.42742 |     0.5049 |                   10 |
    | DEFAULT_0e65d_00007 | TERMINATED |       |            2 |  128 |   64 | 0.0433275   | 2.3489  |     0.102  |                    1 |
    | DEFAULT_0e65d_00008 | TERMINATED |       |            8 |   16 |   16 | 0.0667362   | 2.31539 |     0.1009 |                    1 |
    | DEFAULT_0e65d_00009 | TERMINATED |       |            2 |   16 |   64 | 0.0608499   | 2.37368 |     0.1041 |                    1 |
    +---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+


    Best trial config: {'l1': 256, 'l2': 128, 'lr': 0.003980492641286033, 'batch_size': 8}
    Best trial final validation loss: 1.3832154894173145
    Best trial final validation accuracy: 0.5793
    Files already downloaded and verified
    Files already downloaded and verified
    Best trial test set accuracy: 0.5789


If you run the code, an example output could look like this:

::

    Number of trials: 10 (10 TERMINATED)
    +-----+------+------+-------------+--------------+---------+------------+--------------------+
    | ... |   l1 |   l2 |          lr |   batch_size |    loss |   accuracy | training_iteration |
    |-----+------+------+-------------+--------------+---------+------------+--------------------|
    | ... |   64 |    4 | 0.00011629  |            2 | 1.87273 |     0.244  |                  2 |
    | ... |   32 |   64 | 0.000339763 |            8 | 1.23603 |     0.567  |                  8 |
    | ... |    8 |   16 | 0.00276249  |           16 | 1.1815  |     0.5836 |                 10 |
    | ... |    4 |   64 | 0.000648721 |            4 | 1.31131 |     0.5224 |                  8 |
    | ... |   32 |   16 | 0.000340753 |            8 | 1.26454 |     0.5444 |                  8 |
    | ... |    8 |    4 | 0.000699775 |            8 | 1.99594 |     0.1983 |                  2 |
    | ... |  256 |    8 | 0.0839654   |           16 | 2.3119  |     0.0993 |                  1 |
    | ... |   16 |  128 | 0.0758154   |           16 | 2.33575 |     0.1327 |                  1 |
    | ... |   16 |    8 | 0.0763312   |           16 | 2.31129 |     0.1042 |                  4 |
    | ... |  128 |   16 | 0.000124903 |            4 | 2.26917 |     0.1945 |                  1 |
    +-----+------+------+-------------+--------------+---------+------------+--------------------+


    Best trial config: {'l1': 8, 'l2': 16, 'lr': 0.00276249, 'batch_size': 16, 'data_dir': '...'}
    Best trial final validation loss: 1.181501
    Best trial final validation accuracy: 0.5836
    Best trial test set accuracy: 0.5806

Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 58%, which could
be confirmed on the test set.

So that's it! You can now tune the parameters of your PyTorch models.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 5 minutes  44.992 seconds)


.. _sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: hyperparameter_tuning_tutorial.py <hyperparameter_tuning_tutorial.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: hyperparameter_tuning_tutorial.ipynb <hyperparameter_tuning_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
