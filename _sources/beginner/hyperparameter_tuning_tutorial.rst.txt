.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_hyperparameter_tuning_tutorial.py:


Hyperparameter tuning with Ray Tune
===================================

Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.

Fortunately, there are tools that help with finding the best combination of parameters.
`Ray Tune <https://docs.ray.io/en/latest/tune.html>`_ is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through `Ray's distributed machine learning engine
<https://ray.io/>`_.

In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend `this tutorial from the PyTorch documentation
<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ for training
a CIFAR10 image classifier.

As you will see, we only need to add some slight modifications. In particular, we
need to

1. wrap data loading and training in functions,
2. make some network parameters configurable,
3. add checkpointing (optional),
4. and define the search space for the model tuning

|

To run this tutorial, please make sure the following packages are
installed:

-  ``ray[tune]``: Distributed hyperparameter tuning library
-  ``torchvision``: For the data transformers

Setup / Imports
---------------
Let's start with the imports:


.. code-block:: default

    from functools import partial
    import numpy as np
    import os
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import random_split
    import torchvision
    import torchvision.transforms as transforms
    from ray import tune
    from ray.tune import CLIReporter
    from ray.tune.schedulers import ASHAScheduler







Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.

Data loaders
------------
We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.


.. code-block:: default



    def load_data(data_dir="./data"):
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])

        trainset = torchvision.datasets.CIFAR10(
            root=data_dir, train=True, download=True, transform=transform)

        testset = torchvision.datasets.CIFAR10(
            root=data_dir, train=False, download=True, transform=transform)

        return trainset, testset







Configurable neural network
---------------------------
We can only tune those parameters that are configurable. In this example, we can specify
the layer sizes of the fully connected layers:


.. code-block:: default



    class Net(nn.Module):
        def __init__(self, l1=120, l2=84):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5)
            self.pool = nn.MaxPool2d(2, 2)
            self.conv2 = nn.Conv2d(6, 16, 5)
            self.fc1 = nn.Linear(16 * 5 * 5, l1)
            self.fc2 = nn.Linear(l1, l2)
            self.fc3 = nn.Linear(l2, 10)

        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = x.view(-1, 16 * 5 * 5)
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x







The train function
------------------
Now it gets interesting, because we introduce some changes to the example `from the PyTorch
documentation <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_.

We wrap the training script in a function ``train_cifar(config, checkpoint_dir=None, data_dir=None)``.
As you can guess, the ``config`` parameter will receive the hyperparameters we would like to
train with. The ``checkpoint_dir`` parameter is used to restore checkpoints. The ``data_dir`` specifies
the directory where we load and store the data, so multiple runs can share the same data source.

.. code-block:: python

    net = Net(config["l1"], config["l2"])

    if checkpoint_dir:
        model_state, optimizer_state = torch.load(
            os.path.join(checkpoint_dir, "checkpoint"))
        net.load_state_dict(model_state)
        optimizer.load_state_dict(optimizer_state)

The learning rate of the optimizer is made configurable, too:

.. code-block:: python

    optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.

Adding (multi) GPU support with DataParallel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch's abstractions in Ray Tune. Thus, we can wrap our model in ``nn.DataParallel``
to support data parallel training on multiple GPUs:

.. code-block:: python

    device = "cpu"
    if torch.cuda.is_available():
        device = "cuda:0"
        if torch.cuda.device_count() > 1:
            net = nn.DataParallel(net)
    net.to(device)

By using a ``device`` variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:

.. code-block:: python

    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports `fractional GPUs <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We'll come back
to that later.

Communicating with Ray Tune
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The most interesting part is the communication with Ray Tune:

.. code-block:: python

    with tune.checkpoint_dir(epoch) as checkpoint_dir:
        path = os.path.join(checkpoint_dir, "checkpoint")
        torch.save((net.state_dict(), optimizer.state_dict()), path)

    tune.report(loss=(val_loss / val_steps), accuracy=correct / total)

Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.

The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
`Population Based Training <https://docs.ray.io/en/master/tune/tutorials/tune-advanced-tutorial.html>`_.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set.

Full training function
~~~~~~~~~~~~~~~~~~~~~~

The full code example looks like this:


.. code-block:: default



    def train_cifar(config, checkpoint_dir=None, data_dir=None):
        net = Net(config["l1"], config["l2"])

        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if torch.cuda.device_count() > 1:
                net = nn.DataParallel(net)
        net.to(device)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

        if checkpoint_dir:
            model_state, optimizer_state = torch.load(
                os.path.join(checkpoint_dir, "checkpoint"))
            net.load_state_dict(model_state)
            optimizer.load_state_dict(optimizer_state)

        trainset, testset = load_data(data_dir)

        test_abs = int(len(trainset) * 0.8)
        train_subset, val_subset = random_split(
            trainset, [test_abs, len(trainset) - test_abs])

        trainloader = torch.utils.data.DataLoader(
            train_subset,
            batch_size=int(config["batch_size"]),
            shuffle=True,
            num_workers=8)
        valloader = torch.utils.data.DataLoader(
            val_subset,
            batch_size=int(config["batch_size"]),
            shuffle=True,
            num_workers=8)

        for epoch in range(10):  # loop over the dataset multiple times
            running_loss = 0.0
            epoch_steps = 0
            for i, data in enumerate(trainloader, 0):
                # get the inputs; data is a list of [inputs, labels]
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward + backward + optimize
                outputs = net(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                # print statistics
                running_loss += loss.item()
                epoch_steps += 1
                if i % 2000 == 1999:  # print every 2000 mini-batches
                    print("[%d, %5d] loss: %.3f" % (epoch + 1, i + 1,
                                                    running_loss / epoch_steps))
                    running_loss = 0.0

            # Validation loss
            val_loss = 0.0
            val_steps = 0
            total = 0
            correct = 0
            for i, data in enumerate(valloader, 0):
                with torch.no_grad():
                    inputs, labels = data
                    inputs, labels = inputs.to(device), labels.to(device)

                    outputs = net(inputs)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                    loss = criterion(outputs, labels)
                    val_loss += loss.cpu().numpy()
                    val_steps += 1

            with tune.checkpoint_dir(epoch) as checkpoint_dir:
                path = os.path.join(checkpoint_dir, "checkpoint")
                torch.save((net.state_dict(), optimizer.state_dict()), path)

            tune.report(loss=(val_loss / val_steps), accuracy=correct / total)
        print("Finished Training")







As you can see, most of the code is adapted directly from the original example.

Test set accuracy
-----------------
Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:


.. code-block:: default



    def test_accuracy(net, device="cpu"):
        trainset, testset = load_data()

        testloader = torch.utils.data.DataLoader(
            testset, batch_size=4, shuffle=False, num_workers=2)

        correct = 0
        total = 0
        with torch.no_grad():
            for data in testloader:
                images, labels = data
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return correct / total







The function also expects a ``device`` parameter, so we can do the
test set validation on a GPU.

Configuring the search space
----------------------------
Lastly, we need to define Ray Tune's search space. Here is an example:

.. code-block:: python

    config = {
        "l1": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),
        "l2": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16])
    }

The ``tune.sample_from()`` function makes it possible to define your own sample
methods to obtain hyperparameters. In this example, the ``l1`` and ``l2`` parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.

At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the ``ASHAScheduler`` which will terminate bad
performing trials early.

We wrap the ``train_cifar`` function with ``functools.partial`` to set the constant
``data_dir`` parameter. We can also tell Ray Tune what resources should be
available for each trial:

.. code-block:: python

    gpus_per_trial = 2
    # ...
    result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 8, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
        progress_reporter=reporter,
        checkpoint_at_end=True)

You can specify the number of CPUs, which are then available e.g.
to increase the ``num_workers`` of the PyTorch ``DataLoader`` instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven't been requested for them - so you don't have to care about two trials
using the same set of resources.

Here we can also specify fractional GPUs, so something like ``gpus_per_trial=0.5`` is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.

After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.

The full main function looks like this:


.. code-block:: default



    def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):
        data_dir = os.path.abspath("./data")
        load_data(data_dir)
        config = {
            "l1": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
            "l2": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
            "lr": tune.loguniform(1e-4, 1e-1),
            "batch_size": tune.choice([2, 4, 8, 16])
        }
        scheduler = ASHAScheduler(
            metric="loss",
            mode="min",
            max_t=max_num_epochs,
            grace_period=1,
            reduction_factor=2)
        reporter = CLIReporter(
            # parameter_columns=["l1", "l2", "lr", "batch_size"],
            metric_columns=["loss", "accuracy", "training_iteration"])
        result = tune.run(
            partial(train_cifar, data_dir=data_dir),
            resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
            config=config,
            num_samples=num_samples,
            scheduler=scheduler,
            progress_reporter=reporter)

        best_trial = result.get_best_trial("loss", "min", "last")
        print("Best trial config: {}".format(best_trial.config))
        print("Best trial final validation loss: {}".format(
            best_trial.last_result["loss"]))
        print("Best trial final validation accuracy: {}".format(
            best_trial.last_result["accuracy"]))

        best_trained_model = Net(best_trial.config["l1"], best_trial.config["l2"])
        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if gpus_per_trial > 1:
                best_trained_model = nn.DataParallel(best_trained_model)
        best_trained_model.to(device)

        best_checkpoint_dir = best_trial.checkpoint.value
        model_state, optimizer_state = torch.load(os.path.join(
            best_checkpoint_dir, "checkpoint"))
        best_trained_model.load_state_dict(model_state)

        test_acc = test_accuracy(best_trained_model, device)
        print("Best trial test set accuracy: {}".format(test_acc))


    if __name__ == "__main__":
        # You can change the number of GPUs per trial here:
        main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz
    Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
    Files already downloaded and verified
    == Status ==
    Memory usage on this node: 4.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 1/10 (1 RUNNING)
    +---------------------+----------+-------+--------------+------+------+------------+
    | Trial name          | status   | loc   |   batch_size |   l1 |   l2 |         lr |
    |---------------------+----------+-------+--------------+------+------+------------|
    | DEFAULT_76ecb_00000 | RUNNING  |       |            8 |    4 |  256 | 0.00203823 |
    +---------------------+----------+-------+--------------+------+------+------------+


    [2m[36m(pid=1434)[0m Files already downloaded and verified
    [2m[36m(pid=1472)[0m Files already downloaded and verified
    [2m[36m(pid=1474)[0m Files already downloaded and verified
    [2m[36m(pid=1431)[0m Files already downloaded and verified
    [2m[36m(pid=1480)[0m Files already downloaded and verified
    [2m[36m(pid=1429)[0m Files already downloaded and verified
    [2m[36m(pid=1439)[0m Files already downloaded and verified
    [2m[36m(pid=1430)[0m Files already downloaded and verified
    [2m[36m(pid=1428)[0m Files already downloaded and verified
    [2m[36m(pid=1427)[0m Files already downloaded and verified
    [2m[36m(pid=1434)[0m Files already downloaded and verified
    [2m[36m(pid=1472)[0m Files already downloaded and verified
    [2m[36m(pid=1474)[0m Files already downloaded and verified
    [2m[36m(pid=1431)[0m Files already downloaded and verified
    [2m[36m(pid=1480)[0m Files already downloaded and verified
    [2m[36m(pid=1429)[0m Files already downloaded and verified
    [2m[36m(pid=1439)[0m Files already downloaded and verified
    [2m[36m(pid=1430)[0m Files already downloaded and verified
    [2m[36m(pid=1428)[0m Files already downloaded and verified
    [2m[36m(pid=1427)[0m Files already downloaded and verified
    [2m[36m(pid=1430)[0m [1,  2000] loss: 2.195
    [2m[36m(pid=1474)[0m [1,  2000] loss: 2.413
    [2m[36m(pid=1429)[0m [1,  2000] loss: 2.243
    [2m[36m(pid=1434)[0m [1,  2000] loss: 1.892
    [2m[36m(pid=1431)[0m [1,  2000] loss: 2.006
    [2m[36m(pid=1428)[0m [1,  2000] loss: 2.175
    [2m[36m(pid=1472)[0m [1,  2000] loss: 2.132
    [2m[36m(pid=1480)[0m [1,  2000] loss: 2.001
    [2m[36m(pid=1427)[0m [1,  2000] loss: 1.786
    [2m[36m(pid=1439)[0m [1,  2000] loss: 1.990
    [2m[36m(pid=1430)[0m [1,  4000] loss: 0.977
    [2m[36m(pid=1474)[0m [1,  4000] loss: 1.206
    [2m[36m(pid=1429)[0m [1,  4000] loss: 1.109
    Result for DEFAULT_76ecb_00003:
      accuracy: 0.4376
      date: 2021-04-20_16-50-36
      done: false
      experiment_id: 1f373d5d3f9e4f0a9a7cb6aa7f599881
      hostname: b5df8c714092
      iterations_since_restore: 1
      loss: 1.5139283561706542
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 27.052520751953125
      time_this_iter_s: 27.052520751953125
      time_total_s: 27.052520751953125
      timestamp: 1618937436
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 76ecb_00003
  
    == Status ==
    Memory usage on this node: 9.3/240.1 GiB
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.5139283561706542
    Resources requested: 20/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (10 RUNNING)
    +---------------------+----------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status   | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+----------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00000 | RUNNING  |                 |            8 |    4 |  256 | 0.00203823 |         |            |                      |
    | DEFAULT_76ecb_00001 | RUNNING  |                 |            8 |  128 |   64 | 0.0108614  |         |            |                      |
    | DEFAULT_76ecb_00002 | RUNNING  |                 |           16 |  128 |   64 | 0.0371632  |         |            |                      |
    | DEFAULT_76ecb_00003 | RUNNING  | 172.17.0.2:1427 |           16 |   16 |   16 | 0.011363   | 1.51393 |     0.4376 |                    1 |
    | DEFAULT_76ecb_00004 | RUNNING  |                 |            8 |    4 |   64 | 0.00230503 |         |            |                      |
    | DEFAULT_76ecb_00005 | RUNNING  |                 |            8 |   32 |  256 | 0.0315433  |         |            |                      |
    | DEFAULT_76ecb_00006 | RUNNING  |                 |            2 |    8 |  256 | 0.00111287 |         |            |                      |
    | DEFAULT_76ecb_00007 | RUNNING  |                 |            8 |  256 |   64 | 0.00182312 |         |            |                      |
    | DEFAULT_76ecb_00008 | RUNNING  |                 |            4 |    8 |   16 | 0.0230996  |         |            |                      |
    | DEFAULT_76ecb_00009 | RUNNING  |                 |            2 |    8 |  256 | 0.0956493  |         |            |                      |
    +---------------------+----------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    Result for DEFAULT_76ecb_00002:
      accuracy: 0.2968
      date: 2021-04-20_16-50-37
      done: true
      experiment_id: df533b3d29394e8eb6922b59edfd7831
      hostname: b5df8c714092
      iterations_since_restore: 1
      loss: 1.9380123876571655
      node_ip: 172.17.0.2
      pid: 1439
      should_checkpoint: true
      time_since_restore: 27.469507932662964
      time_this_iter_s: 27.469507932662964
      time_total_s: 27.469507932662964
      timestamp: 1618937437
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 76ecb_00002
  
    [2m[36m(pid=1431)[0m [1,  4000] loss: 0.840
    [2m[36m(pid=1428)[0m [1,  4000] loss: 0.896
    [2m[36m(pid=1434)[0m [1,  4000] loss: 0.849
    [2m[36m(pid=1472)[0m [1,  4000] loss: 1.039
    [2m[36m(pid=1480)[0m [1,  4000] loss: 0.819
    [2m[36m(pid=1430)[0m [1,  6000] loss: 0.612
    [2m[36m(pid=1474)[0m [1,  6000] loss: 0.802
    [2m[36m(pid=1429)[0m [1,  6000] loss: 0.748
    Result for DEFAULT_76ecb_00004:
      accuracy: 0.4057
      date: 2021-04-20_16-50-49
      done: false
      experiment_id: 067b738a4c5646a695ded5153aa49e5f
      hostname: b5df8c714092
      iterations_since_restore: 1
      loss: 1.574723437833786
      node_ip: 172.17.0.2
      pid: 1431
      should_checkpoint: true
      time_since_restore: 39.46945071220398
      time_this_iter_s: 39.46945071220398
      time_total_s: 39.46945071220398
      timestamp: 1618937449
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 76ecb_00004
  
    == Status ==
    Memory usage on this node: 8.7/240.1 GiB
    Using AsyncHyperBand: num_stopped=1
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.574723437833786
    Resources requested: 18/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (9 RUNNING, 1 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00000 | RUNNING    |                 |            8 |    4 |  256 | 0.00203823 |         |            |                      |
    | DEFAULT_76ecb_00001 | RUNNING    |                 |            8 |  128 |   64 | 0.0108614  |         |            |                      |
    | DEFAULT_76ecb_00003 | RUNNING    | 172.17.0.2:1427 |           16 |   16 |   16 | 0.011363   | 1.51393 |     0.4376 |                    1 |
    | DEFAULT_76ecb_00004 | RUNNING    | 172.17.0.2:1431 |            8 |    4 |   64 | 0.00230503 | 1.57472 |     0.4057 |                    1 |
    | DEFAULT_76ecb_00005 | RUNNING    |                 |            8 |   32 |  256 | 0.0315433  |         |            |                      |
    | DEFAULT_76ecb_00006 | RUNNING    |                 |            2 |    8 |  256 | 0.00111287 |         |            |                      |
    | DEFAULT_76ecb_00007 | RUNNING    |                 |            8 |  256 |   64 | 0.00182312 |         |            |                      |
    | DEFAULT_76ecb_00008 | RUNNING    |                 |            4 |    8 |   16 | 0.0230996  |         |            |                      |
    | DEFAULT_76ecb_00009 | RUNNING    |                 |            2 |    8 |  256 | 0.0956493  |         |            |                      |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    Result for DEFAULT_76ecb_00000:
      accuracy: 0.3996
      date: 2021-04-20_16-50-49
      done: true
      experiment_id: cf0c776fde904d5e82dda7c5106b870c
      hostname: b5df8c714092
      iterations_since_restore: 1
      loss: 1.5880825274467467
      node_ip: 172.17.0.2
      pid: 1428
      should_checkpoint: true
      time_since_restore: 39.586052894592285
      time_this_iter_s: 39.586052894592285
      time_total_s: 39.586052894592285
      timestamp: 1618937449
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 76ecb_00000
  
    Result for DEFAULT_76ecb_00001:
      accuracy: 0.3956
      date: 2021-04-20_16-50-49
      done: true
      experiment_id: 7a7a90aac25241e4baff3b0f6bda3b96
      hostname: b5df8c714092
      iterations_since_restore: 1
      loss: 1.641920290517807
      node_ip: 172.17.0.2
      pid: 1434
      should_checkpoint: true
      time_since_restore: 40.15845060348511
      time_this_iter_s: 40.15845060348511
      time_total_s: 40.15845060348511
      timestamp: 1618937449
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 76ecb_00001
  
    Result for DEFAULT_76ecb_00005:
      accuracy: 0.2052
      date: 2021-04-20_16-50-50
      done: true
      experiment_id: ed41c91a209e420b8998064207d4efa7
      hostname: b5df8c714092
      iterations_since_restore: 1
      loss: 2.134618975353241
      node_ip: 172.17.0.2
      pid: 1472
      should_checkpoint: true
      time_since_restore: 40.64821910858154
      time_this_iter_s: 40.64821910858154
      time_total_s: 40.64821910858154
      timestamp: 1618937450
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 76ecb_00005
  
    Result for DEFAULT_76ecb_00007:
      accuracy: 0.4473
      date: 2021-04-20_16-50-51
      done: false
      experiment_id: 70ebc8fa0c694726b89a89472a3a9f46
      hostname: b5df8c714092
      iterations_since_restore: 1
      loss: 1.4949692761898041
      node_ip: 172.17.0.2
      pid: 1480
      should_checkpoint: true
      time_since_restore: 41.868706703186035
      time_this_iter_s: 41.868706703186035
      time_total_s: 41.868706703186035
      timestamp: 1618937451
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 76ecb_00007
  
    [2m[36m(pid=1427)[0m [2,  2000] loss: 1.526
    [2m[36m(pid=1430)[0m [1,  8000] loss: 0.430
    [2m[36m(pid=1474)[0m [1,  8000] loss: 0.604
    [2m[36m(pid=1429)[0m [1,  8000] loss: 0.573
    Result for DEFAULT_76ecb_00003:
      accuracy: 0.4861
      date: 2021-04-20_16-50-57
      done: false
      experiment_id: 1f373d5d3f9e4f0a9a7cb6aa7f599881
      hostname: b5df8c714092
      iterations_since_restore: 2
      loss: 1.4813382904052734
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 48.166407108306885
      time_this_iter_s: 21.11388635635376
      time_total_s: 48.166407108306885
      timestamp: 1618937457
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: 76ecb_00003
  
    == Status ==
    Memory usage on this node: 7.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.4813382904052734 | Iter 1.000: -1.5880825274467467
    Resources requested: 12/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00003 | RUNNING    | 172.17.0.2:1427 |           16 |   16 |   16 | 0.011363   | 1.48134 |     0.4861 |                    2 |
    | DEFAULT_76ecb_00004 | RUNNING    | 172.17.0.2:1431 |            8 |    4 |   64 | 0.00230503 | 1.57472 |     0.4057 |                    1 |
    | DEFAULT_76ecb_00006 | RUNNING    |                 |            2 |    8 |  256 | 0.00111287 |         |            |                      |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.49497 |     0.4473 |                    1 |
    | DEFAULT_76ecb_00008 | RUNNING    |                 |            4 |    8 |   16 | 0.0230996  |         |            |                      |
    | DEFAULT_76ecb_00009 | RUNNING    |                 |            2 |    8 |  256 | 0.0956493  |         |            |                      |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    [2m[36m(pid=1431)[0m [2,  2000] loss: 1.566
    [2m[36m(pid=1430)[0m [1, 10000] loss: 0.332
    [2m[36m(pid=1474)[0m [1, 10000] loss: 0.483
    [2m[36m(pid=1480)[0m [2,  2000] loss: 1.452
    [2m[36m(pid=1429)[0m [1, 10000] loss: 0.463
    [2m[36m(pid=1430)[0m [1, 12000] loss: 0.271
    [2m[36m(pid=1431)[0m [2,  4000] loss: 0.765
    [2m[36m(pid=1474)[0m [1, 12000] loss: 0.403
    Result for DEFAULT_76ecb_00008:
      accuracy: 0.1027
      date: 2021-04-20_16-51-11
      done: true
      experiment_id: 428a41f9c14b4dc28fdcada633da00cf
      hostname: b5df8c714092
      iterations_since_restore: 1
      loss: 2.310563133430481
      node_ip: 172.17.0.2
      pid: 1429
      should_checkpoint: true
      time_since_restore: 61.33395481109619
      time_this_iter_s: 61.33395481109619
      time_total_s: 61.33395481109619
      timestamp: 1618937471
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 76ecb_00008
  
    == Status ==
    Memory usage on this node: 7.2/240.1 GiB
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.4813382904052734 | Iter 1.000: -1.6150014089822768
    Resources requested: 12/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00003 | RUNNING    | 172.17.0.2:1427 |           16 |   16 |   16 | 0.011363   | 1.48134 |     0.4861 |                    2 |
    | DEFAULT_76ecb_00004 | RUNNING    | 172.17.0.2:1431 |            8 |    4 |   64 | 0.00230503 | 1.57472 |     0.4057 |                    1 |
    | DEFAULT_76ecb_00006 | RUNNING    |                 |            2 |    8 |  256 | 0.00111287 |         |            |                      |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.49497 |     0.4473 |                    1 |
    | DEFAULT_76ecb_00008 | RUNNING    | 172.17.0.2:1429 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    | DEFAULT_76ecb_00009 | RUNNING    |                 |            2 |    8 |  256 | 0.0956493  |         |            |                      |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    [2m[36m(pid=1427)[0m [3,  2000] loss: 1.460
    [2m[36m(pid=1480)[0m [2,  4000] loss: 0.679
    [2m[36m(pid=1430)[0m [1, 14000] loss: 0.230
    Result for DEFAULT_76ecb_00003:
      accuracy: 0.4511
      date: 2021-04-20_16-51-17
      done: false
      experiment_id: 1f373d5d3f9e4f0a9a7cb6aa7f599881
      hostname: b5df8c714092
      iterations_since_restore: 3
      loss: 1.4940508912086488
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 67.6159360408783
      time_this_iter_s: 19.44952893257141
      time_total_s: 67.6159360408783
      timestamp: 1618937477
      timesteps_since_restore: 0
      training_iteration: 3
      trial_id: 76ecb_00003
  
    == Status ==
    Memory usage on this node: 6.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=5
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.4813382904052734 | Iter 1.000: -1.6150014089822768
    Resources requested: 10/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00003 | RUNNING    | 172.17.0.2:1427 |           16 |   16 |   16 | 0.011363   | 1.49405 |     0.4511 |                    3 |
    | DEFAULT_76ecb_00004 | RUNNING    | 172.17.0.2:1431 |            8 |    4 |   64 | 0.00230503 | 1.57472 |     0.4057 |                    1 |
    | DEFAULT_76ecb_00006 | RUNNING    |                 |            2 |    8 |  256 | 0.00111287 |         |            |                      |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.49497 |     0.4473 |                    1 |
    | DEFAULT_76ecb_00009 | RUNNING    |                 |            2 |    8 |  256 | 0.0956493  |         |            |                      |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00008 | TERMINATED |                 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    [2m[36m(pid=1474)[0m [1, 14000] loss: 0.345
    Result for DEFAULT_76ecb_00004:
      accuracy: 0.4073
      date: 2021-04-20_16-51-19
      done: true
      experiment_id: 067b738a4c5646a695ded5153aa49e5f
      hostname: b5df8c714092
      iterations_since_restore: 2
      loss: 1.553637916660309
      node_ip: 172.17.0.2
      pid: 1431
      should_checkpoint: true
      time_since_restore: 69.65890431404114
      time_this_iter_s: 30.189453601837158
      time_total_s: 69.65890431404114
      timestamp: 1618937479
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: 76ecb_00004
  
    Result for DEFAULT_76ecb_00007:
      accuracy: 0.5243
      date: 2021-04-20_16-51-23
      done: false
      experiment_id: 70ebc8fa0c694726b89a89472a3a9f46
      hostname: b5df8c714092
      iterations_since_restore: 2
      loss: 1.3211081300258636
      node_ip: 172.17.0.2
      pid: 1480
      should_checkpoint: true
      time_since_restore: 73.6243200302124
      time_this_iter_s: 31.755613327026367
      time_total_s: 73.6243200302124
      timestamp: 1618937483
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: 76ecb_00007
  
    == Status ==
    Memory usage on this node: 6.0/240.1 GiB
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.4813382904052734 | Iter 1.000: -1.6150014089822768
    Resources requested: 8/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00003 | RUNNING    | 172.17.0.2:1427 |           16 |   16 |   16 | 0.011363   | 1.49405 |     0.4511 |                    3 |
    | DEFAULT_76ecb_00006 | RUNNING    |                 |            2 |    8 |  256 | 0.00111287 |         |            |                      |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.32111 |     0.5243 |                    2 |
    | DEFAULT_76ecb_00009 | RUNNING    |                 |            2 |    8 |  256 | 0.0956493  |         |            |                      |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00004 | TERMINATED |                 |            8 |    4 |   64 | 0.00230503 | 1.55364 |     0.4073 |                    2 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00008 | TERMINATED |                 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    [2m[36m(pid=1430)[0m [1, 16000] loss: 0.198
    [2m[36m(pid=1474)[0m [1, 16000] loss: 0.301
    [2m[36m(pid=1427)[0m [4,  2000] loss: 1.432
    [2m[36m(pid=1430)[0m [1, 18000] loss: 0.170
    [2m[36m(pid=1480)[0m [3,  2000] loss: 1.234
    [2m[36m(pid=1474)[0m [1, 18000] loss: 0.268
    Result for DEFAULT_76ecb_00003:
      accuracy: 0.4761
      date: 2021-04-20_16-51-35
      done: false
      experiment_id: 1f373d5d3f9e4f0a9a7cb6aa7f599881
      hostname: b5df8c714092
      iterations_since_restore: 4
      loss: 1.4974650121688842
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 86.24326038360596
      time_this_iter_s: 18.62732434272766
      time_total_s: 86.24326038360596
      timestamp: 1618937495
      timesteps_since_restore: 0
      training_iteration: 4
      trial_id: 76ecb_00003
  
    == Status ==
    Memory usage on this node: 6.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.4974650121688842 | Iter 2.000: -1.4813382904052734 | Iter 1.000: -1.6150014089822768
    Resources requested: 8/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00003 | RUNNING    | 172.17.0.2:1427 |           16 |   16 |   16 | 0.011363   | 1.49747 |     0.4761 |                    4 |
    | DEFAULT_76ecb_00006 | RUNNING    |                 |            2 |    8 |  256 | 0.00111287 |         |            |                      |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.32111 |     0.5243 |                    2 |
    | DEFAULT_76ecb_00009 | RUNNING    |                 |            2 |    8 |  256 | 0.0956493  |         |            |                      |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00004 | TERMINATED |                 |            8 |    4 |   64 | 0.00230503 | 1.55364 |     0.4073 |                    2 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00008 | TERMINATED |                 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    [2m[36m(pid=1430)[0m [1, 20000] loss: 0.154
    [2m[36m(pid=1474)[0m [1, 20000] loss: 0.241
    [2m[36m(pid=1480)[0m [3,  4000] loss: 0.603
    [2m[36m(pid=1427)[0m [5,  2000] loss: 1.416
    Result for DEFAULT_76ecb_00006:
      accuracy: 0.4381
      date: 2021-04-20_16-51-50
      done: false
      experiment_id: 3850c4263510450da3c40498e1810110
      hostname: b5df8c714092
      iterations_since_restore: 1
      loss: 1.5256438520982862
      node_ip: 172.17.0.2
      pid: 1430
      should_checkpoint: true
      time_since_restore: 101.03542709350586
      time_this_iter_s: 101.03542709350586
      time_total_s: 101.03542709350586
      timestamp: 1618937510
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 76ecb_00006
  
    == Status ==
    Memory usage on this node: 6.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.4974650121688842 | Iter 2.000: -1.4813382904052734 | Iter 1.000: -1.5880825274467467
    Resources requested: 8/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00003 | RUNNING    | 172.17.0.2:1427 |           16 |   16 |   16 | 0.011363   | 1.49747 |     0.4761 |                    4 |
    | DEFAULT_76ecb_00006 | RUNNING    | 172.17.0.2:1430 |            2 |    8 |  256 | 0.00111287 | 1.52564 |     0.4381 |                    1 |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.32111 |     0.5243 |                    2 |
    | DEFAULT_76ecb_00009 | RUNNING    |                 |            2 |    8 |  256 | 0.0956493  |         |            |                      |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00004 | TERMINATED |                 |            8 |    4 |   64 | 0.00230503 | 1.55364 |     0.4073 |                    2 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00008 | TERMINATED |                 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    Result for DEFAULT_76ecb_00007:
      accuracy: 0.5876
      date: 2021-04-20_16-51-54
      done: false
      experiment_id: 70ebc8fa0c694726b89a89472a3a9f46
      hostname: b5df8c714092
      iterations_since_restore: 3
      loss: 1.1719338577270508
      node_ip: 172.17.0.2
      pid: 1480
      should_checkpoint: true
      time_since_restore: 104.56895089149475
      time_this_iter_s: 30.94463086128235
      time_total_s: 104.56895089149475
      timestamp: 1618937514
      timesteps_since_restore: 0
      training_iteration: 3
      trial_id: 76ecb_00007
  
    Result for DEFAULT_76ecb_00009:
      accuracy: 0.1015
      date: 2021-04-20_16-51-54
      done: true
      experiment_id: 159bc44d890b41488df9aa2a37b398bd
      hostname: b5df8c714092
      iterations_since_restore: 1
      loss: 2.3790494443655015
      node_ip: 172.17.0.2
      pid: 1474
      should_checkpoint: true
      time_since_restore: 104.72153496742249
      time_this_iter_s: 104.72153496742249
      time_total_s: 104.72153496742249
      timestamp: 1618937514
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 76ecb_00009
  
    Result for DEFAULT_76ecb_00003:
      accuracy: 0.4348
      date: 2021-04-20_16-51-54
      done: false
      experiment_id: 1f373d5d3f9e4f0a9a7cb6aa7f599881
      hostname: b5df8c714092
      iterations_since_restore: 5
      loss: 1.5197840992927552
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 105.01655769348145
      time_this_iter_s: 18.77329730987549
      time_total_s: 105.01655769348145
      timestamp: 1618937514
      timesteps_since_restore: 0
      training_iteration: 5
      trial_id: 76ecb_00003
  
    [2m[36m(pid=1430)[0m [2,  2000] loss: 1.482
    [2m[36m(pid=1480)[0m [4,  2000] loss: 1.096
    [2m[36m(pid=1430)[0m [2,  4000] loss: 0.749
    [2m[36m(pid=1427)[0m [6,  2000] loss: 1.417
    Result for DEFAULT_76ecb_00003:
      accuracy: 0.4977
      date: 2021-04-20_16-52-13
      done: false
      experiment_id: 1f373d5d3f9e4f0a9a7cb6aa7f599881
      hostname: b5df8c714092
      iterations_since_restore: 6
      loss: 1.4395066987991334
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 123.35512661933899
      time_this_iter_s: 18.338568925857544
      time_total_s: 123.35512661933899
      timestamp: 1618937533
      timesteps_since_restore: 0
      training_iteration: 6
      trial_id: 76ecb_00003
  
    == Status ==
    Memory usage on this node: 5.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.4974650121688842 | Iter 2.000: -1.4813382904052734 | Iter 1.000: -1.6150014089822768
    Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00003 | RUNNING    | 172.17.0.2:1427 |           16 |   16 |   16 | 0.011363   | 1.43951 |     0.4977 |                    6 |
    | DEFAULT_76ecb_00006 | RUNNING    | 172.17.0.2:1430 |            2 |    8 |  256 | 0.00111287 | 1.52564 |     0.4381 |                    1 |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.17193 |     0.5876 |                    3 |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00004 | TERMINATED |                 |            8 |    4 |   64 | 0.00230503 | 1.55364 |     0.4073 |                    2 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00008 | TERMINATED |                 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    | DEFAULT_76ecb_00009 | TERMINATED |                 |            2 |    8 |  256 | 0.0956493  | 2.37905 |     0.1015 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    [2m[36m(pid=1430)[0m [2,  6000] loss: 0.499
    [2m[36m(pid=1480)[0m [4,  4000] loss: 0.555
    [2m[36m(pid=1430)[0m [2,  8000] loss: 0.372
    Result for DEFAULT_76ecb_00007:
      accuracy: 0.598
      date: 2021-04-20_16-52-24
      done: false
      experiment_id: 70ebc8fa0c694726b89a89472a3a9f46
      hostname: b5df8c714092
      iterations_since_restore: 4
      loss: 1.1483438033103943
      node_ip: 172.17.0.2
      pid: 1480
      should_checkpoint: true
      time_since_restore: 134.5639123916626
      time_this_iter_s: 29.994961500167847
      time_total_s: 134.5639123916626
      timestamp: 1618937544
      timesteps_since_restore: 0
      training_iteration: 4
      trial_id: 76ecb_00007
  
    == Status ==
    Memory usage on this node: 5.6/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.3229044077396392 | Iter 2.000: -1.4813382904052734 | Iter 1.000: -1.6150014089822768
    Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00003 | RUNNING    | 172.17.0.2:1427 |           16 |   16 |   16 | 0.011363   | 1.43951 |     0.4977 |                    6 |
    | DEFAULT_76ecb_00006 | RUNNING    | 172.17.0.2:1430 |            2 |    8 |  256 | 0.00111287 | 1.52564 |     0.4381 |                    1 |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.14834 |     0.598  |                    4 |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00004 | TERMINATED |                 |            8 |    4 |   64 | 0.00230503 | 1.55364 |     0.4073 |                    2 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00008 | TERMINATED |                 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    | DEFAULT_76ecb_00009 | TERMINATED |                 |            2 |    8 |  256 | 0.0956493  | 2.37905 |     0.1015 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    [2m[36m(pid=1427)[0m [7,  2000] loss: 1.408
    [2m[36m(pid=1430)[0m [2, 10000] loss: 0.297
    Result for DEFAULT_76ecb_00003:
      accuracy: 0.5117
      date: 2021-04-20_16-52-31
      done: false
      experiment_id: 1f373d5d3f9e4f0a9a7cb6aa7f599881
      hostname: b5df8c714092
      iterations_since_restore: 7
      loss: 1.4442075086593629
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 141.63795804977417
      time_this_iter_s: 18.28283143043518
      time_total_s: 141.63795804977417
      timestamp: 1618937551
      timesteps_since_restore: 0
      training_iteration: 7
      trial_id: 76ecb_00003
  
    == Status ==
    Memory usage on this node: 5.7/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.3229044077396392 | Iter 2.000: -1.4813382904052734 | Iter 1.000: -1.6150014089822768
    Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00003 | RUNNING    | 172.17.0.2:1427 |           16 |   16 |   16 | 0.011363   | 1.44421 |     0.5117 |                    7 |
    | DEFAULT_76ecb_00006 | RUNNING    | 172.17.0.2:1430 |            2 |    8 |  256 | 0.00111287 | 1.52564 |     0.4381 |                    1 |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.14834 |     0.598  |                    4 |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00004 | TERMINATED |                 |            8 |    4 |   64 | 0.00230503 | 1.55364 |     0.4073 |                    2 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00008 | TERMINATED |                 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    | DEFAULT_76ecb_00009 | TERMINATED |                 |            2 |    8 |  256 | 0.0956493  | 2.37905 |     0.1015 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    [2m[36m(pid=1480)[0m [5,  2000] loss: 1.011
    [2m[36m(pid=1430)[0m [2, 12000] loss: 0.249
    [2m[36m(pid=1430)[0m [2, 14000] loss: 0.207
    [2m[36m(pid=1427)[0m [8,  2000] loss: 1.403
    [2m[36m(pid=1480)[0m [5,  4000] loss: 0.512
    Result for DEFAULT_76ecb_00003:
      accuracy: 0.5254
      date: 2021-04-20_16-52-49
      done: false
      experiment_id: 1f373d5d3f9e4f0a9a7cb6aa7f599881
      hostname: b5df8c714092
      iterations_since_restore: 8
      loss: 1.406346976852417
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 159.75250816345215
      time_this_iter_s: 18.11455011367798
      time_total_s: 159.75250816345215
      timestamp: 1618937569
      timesteps_since_restore: 0
      training_iteration: 8
      trial_id: 76ecb_00003
  
    == Status ==
    Memory usage on this node: 5.7/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.406346976852417 | Iter 4.000: -1.3229044077396392 | Iter 2.000: -1.4813382904052734 | Iter 1.000: -1.6150014089822768
    Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00003 | RUNNING    | 172.17.0.2:1427 |           16 |   16 |   16 | 0.011363   | 1.40635 |     0.5254 |                    8 |
    | DEFAULT_76ecb_00006 | RUNNING    | 172.17.0.2:1430 |            2 |    8 |  256 | 0.00111287 | 1.52564 |     0.4381 |                    1 |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.14834 |     0.598  |                    4 |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00004 | TERMINATED |                 |            8 |    4 |   64 | 0.00230503 | 1.55364 |     0.4073 |                    2 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00008 | TERMINATED |                 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    | DEFAULT_76ecb_00009 | TERMINATED |                 |            2 |    8 |  256 | 0.0956493  | 2.37905 |     0.1015 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    [2m[36m(pid=1430)[0m [2, 16000] loss: 0.184
    Result for DEFAULT_76ecb_00007:
      accuracy: 0.6034
      date: 2021-04-20_16-52-54
      done: false
      experiment_id: 70ebc8fa0c694726b89a89472a3a9f46
      hostname: b5df8c714092
      iterations_since_restore: 5
      loss: 1.1646805693387985
      node_ip: 172.17.0.2
      pid: 1480
      should_checkpoint: true
      time_since_restore: 164.79668641090393
      time_this_iter_s: 30.232774019241333
      time_total_s: 164.79668641090393
      timestamp: 1618937574
      timesteps_since_restore: 0
      training_iteration: 5
      trial_id: 76ecb_00007
  
    [2m[36m(pid=1430)[0m [2, 18000] loss: 0.163
    [2m[36m(pid=1427)[0m [9,  2000] loss: 1.401
    [2m[36m(pid=1480)[0m [6,  2000] loss: 0.937
    [2m[36m(pid=1430)[0m [2, 20000] loss: 0.144
    Result for DEFAULT_76ecb_00003:
      accuracy: 0.5129
      date: 2021-04-20_16-53-07
      done: false
      experiment_id: 1f373d5d3f9e4f0a9a7cb6aa7f599881
      hostname: b5df8c714092
      iterations_since_restore: 9
      loss: 1.4496946530342103
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 178.1053547859192
      time_this_iter_s: 18.35284662246704
      time_total_s: 178.1053547859192
      timestamp: 1618937587
      timesteps_since_restore: 0
      training_iteration: 9
      trial_id: 76ecb_00003
  
    == Status ==
    Memory usage on this node: 5.7/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.406346976852417 | Iter 4.000: -1.3229044077396392 | Iter 2.000: -1.4813382904052734 | Iter 1.000: -1.6150014089822768
    Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00003 | RUNNING    | 172.17.0.2:1427 |           16 |   16 |   16 | 0.011363   | 1.44969 |     0.5129 |                    9 |
    | DEFAULT_76ecb_00006 | RUNNING    | 172.17.0.2:1430 |            2 |    8 |  256 | 0.00111287 | 1.52564 |     0.4381 |                    1 |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.16468 |     0.6034 |                    5 |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00004 | TERMINATED |                 |            8 |    4 |   64 | 0.00230503 | 1.55364 |     0.4073 |                    2 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00008 | TERMINATED |                 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    | DEFAULT_76ecb_00009 | TERMINATED |                 |            2 |    8 |  256 | 0.0956493  | 2.37905 |     0.1015 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    [2m[36m(pid=1480)[0m [6,  4000] loss: 0.474
    Result for DEFAULT_76ecb_00006:
      accuracy: 0.4854
      date: 2021-04-20_16-53-17
      done: false
      experiment_id: 3850c4263510450da3c40498e1810110
      hostname: b5df8c714092
      iterations_since_restore: 2
      loss: 1.43756989409253
      node_ip: 172.17.0.2
      pid: 1430
      should_checkpoint: true
      time_since_restore: 187.7815282344818
      time_this_iter_s: 86.74610114097595
      time_total_s: 187.7815282344818
      timestamp: 1618937597
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: 76ecb_00006
  
    == Status ==
    Memory usage on this node: 5.8/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.406346976852417 | Iter 4.000: -1.3229044077396392 | Iter 2.000: -1.4594540922489019 | Iter 1.000: -1.6150014089822768
    Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00003 | RUNNING    | 172.17.0.2:1427 |           16 |   16 |   16 | 0.011363   | 1.44969 |     0.5129 |                    9 |
    | DEFAULT_76ecb_00006 | RUNNING    | 172.17.0.2:1430 |            2 |    8 |  256 | 0.00111287 | 1.43757 |     0.4854 |                    2 |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.16468 |     0.6034 |                    5 |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00004 | TERMINATED |                 |            8 |    4 |   64 | 0.00230503 | 1.55364 |     0.4073 |                    2 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00008 | TERMINATED |                 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    | DEFAULT_76ecb_00009 | TERMINATED |                 |            2 |    8 |  256 | 0.0956493  | 2.37905 |     0.1015 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    [2m[36m(pid=1427)[0m [10,  2000] loss: 1.401
    Result for DEFAULT_76ecb_00007:
      accuracy: 0.6147
      date: 2021-04-20_16-53-24
      done: false
      experiment_id: 70ebc8fa0c694726b89a89472a3a9f46
      hostname: b5df8c714092
      iterations_since_restore: 6
      loss: 1.1110263490080834
      node_ip: 172.17.0.2
      pid: 1480
      should_checkpoint: true
      time_since_restore: 194.78450465202332
      time_this_iter_s: 29.987818241119385
      time_total_s: 194.78450465202332
      timestamp: 1618937604
      timesteps_since_restore: 0
      training_iteration: 6
      trial_id: 76ecb_00007
  
    == Status ==
    Memory usage on this node: 5.7/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.406346976852417 | Iter 4.000: -1.3229044077396392 | Iter 2.000: -1.4594540922489019 | Iter 1.000: -1.6150014089822768
    Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00003 | RUNNING    | 172.17.0.2:1427 |           16 |   16 |   16 | 0.011363   | 1.44969 |     0.5129 |                    9 |
    | DEFAULT_76ecb_00006 | RUNNING    | 172.17.0.2:1430 |            2 |    8 |  256 | 0.00111287 | 1.43757 |     0.4854 |                    2 |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.11103 |     0.6147 |                    6 |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00004 | TERMINATED |                 |            8 |    4 |   64 | 0.00230503 | 1.55364 |     0.4073 |                    2 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00008 | TERMINATED |                 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    | DEFAULT_76ecb_00009 | TERMINATED |                 |            2 |    8 |  256 | 0.0956493  | 2.37905 |     0.1015 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    [2m[36m(pid=1430)[0m [3,  2000] loss: 1.386
    Result for DEFAULT_76ecb_00003:
      accuracy: 0.5322
      date: 2021-04-20_16-53-26
      done: true
      experiment_id: 1f373d5d3f9e4f0a9a7cb6aa7f599881
      hostname: b5df8c714092
      iterations_since_restore: 10
      loss: 1.401434113883972
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 196.5750756263733
      time_this_iter_s: 18.4697208404541
      time_total_s: 196.5750756263733
      timestamp: 1618937606
      timesteps_since_restore: 0
      training_iteration: 10
      trial_id: 76ecb_00003
  
    [2m[36m(pid=1430)[0m [3,  4000] loss: 0.716
    [2m[36m(pid=1480)[0m [7,  2000] loss: 0.852
    [2m[36m(pid=1430)[0m [3,  6000] loss: 0.480
    [2m[36m(pid=1480)[0m [7,  4000] loss: 0.441
    [2m[36m(pid=1430)[0m [3,  8000] loss: 0.353
    Result for DEFAULT_76ecb_00007:
      accuracy: 0.609
      date: 2021-04-20_16-53-53
      done: false
      experiment_id: 70ebc8fa0c694726b89a89472a3a9f46
      hostname: b5df8c714092
      iterations_since_restore: 7
      loss: 1.1658197764873504
      node_ip: 172.17.0.2
      pid: 1480
      should_checkpoint: true
      time_since_restore: 224.2309594154358
      time_this_iter_s: 29.446454763412476
      time_total_s: 224.2309594154358
      timestamp: 1618937633
      timesteps_since_restore: 0
      training_iteration: 7
      trial_id: 76ecb_00007
  
    == Status ==
    Memory usage on this node: 5.0/240.1 GiB
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.406346976852417 | Iter 4.000: -1.3229044077396392 | Iter 2.000: -1.4594540922489019 | Iter 1.000: -1.6150014089822768
    Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00006 | RUNNING    | 172.17.0.2:1430 |            2 |    8 |  256 | 0.00111287 | 1.43757 |     0.4854 |                    2 |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.16582 |     0.609  |                    7 |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00003 | TERMINATED |                 |           16 |   16 |   16 | 0.011363   | 1.40143 |     0.5322 |                   10 |
    | DEFAULT_76ecb_00004 | TERMINATED |                 |            8 |    4 |   64 | 0.00230503 | 1.55364 |     0.4073 |                    2 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00008 | TERMINATED |                 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    | DEFAULT_76ecb_00009 | TERMINATED |                 |            2 |    8 |  256 | 0.0956493  | 2.37905 |     0.1015 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    [2m[36m(pid=1430)[0m [3, 10000] loss: 0.281
    [2m[36m(pid=1430)[0m [3, 12000] loss: 0.236
    [2m[36m(pid=1480)[0m [8,  2000] loss: 0.797
    [2m[36m(pid=1430)[0m [3, 14000] loss: 0.198
    [2m[36m(pid=1480)[0m [8,  4000] loss: 0.415
    [2m[36m(pid=1430)[0m [3, 16000] loss: 0.179
    [2m[36m(pid=1430)[0m [3, 18000] loss: 0.160
    Result for DEFAULT_76ecb_00007:
      accuracy: 0.6196
      date: 2021-04-20_16-54-34
      done: false
      experiment_id: 70ebc8fa0c694726b89a89472a3a9f46
      hostname: b5df8c714092
      iterations_since_restore: 8
      loss: 1.1408905649960042
      node_ip: 172.17.0.2
      pid: 1480
      should_checkpoint: true
      time_since_restore: 265.04983353614807
      time_this_iter_s: 40.81887412071228
      time_total_s: 265.04983353614807
      timestamp: 1618937674
      timesteps_since_restore: 0
      training_iteration: 8
      trial_id: 76ecb_00007
  
    == Status ==
    Memory usage on this node: 5.0/240.1 GiB
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.2736187709242106 | Iter 4.000: -1.3229044077396392 | Iter 2.000: -1.4594540922489019 | Iter 1.000: -1.6150014089822768
    Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00006 | RUNNING    | 172.17.0.2:1430 |            2 |    8 |  256 | 0.00111287 | 1.43757 |     0.4854 |                    2 |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.14089 |     0.6196 |                    8 |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00003 | TERMINATED |                 |           16 |   16 |   16 | 0.011363   | 1.40143 |     0.5322 |                   10 |
    | DEFAULT_76ecb_00004 | TERMINATED |                 |            8 |    4 |   64 | 0.00230503 | 1.55364 |     0.4073 |                    2 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00008 | TERMINATED |                 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    | DEFAULT_76ecb_00009 | TERMINATED |                 |            2 |    8 |  256 | 0.0956493  | 2.37905 |     0.1015 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    [2m[36m(pid=1430)[0m [3, 20000] loss: 0.136
    [2m[36m(pid=1480)[0m [9,  2000] loss: 0.717
    Result for DEFAULT_76ecb_00006:
      accuracy: 0.4978
      date: 2021-04-20_16-54-52
      done: false
      experiment_id: 3850c4263510450da3c40498e1810110
      hostname: b5df8c714092
      iterations_since_restore: 3
      loss: 1.411418299393053
      node_ip: 172.17.0.2
      pid: 1430
      should_checkpoint: true
      time_since_restore: 282.8949100971222
      time_this_iter_s: 95.11338186264038
      time_total_s: 282.8949100971222
      timestamp: 1618937692
      timesteps_since_restore: 0
      training_iteration: 3
      trial_id: 76ecb_00006
  
    == Status ==
    Memory usage on this node: 5.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.2736187709242106 | Iter 4.000: -1.3229044077396392 | Iter 2.000: -1.4594540922489019 | Iter 1.000: -1.6150014089822768
    Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00006 | RUNNING    | 172.17.0.2:1430 |            2 |    8 |  256 | 0.00111287 | 1.41142 |     0.4978 |                    3 |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.14089 |     0.6196 |                    8 |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00003 | TERMINATED |                 |           16 |   16 |   16 | 0.011363   | 1.40143 |     0.5322 |                   10 |
    | DEFAULT_76ecb_00004 | TERMINATED |                 |            8 |    4 |   64 | 0.00230503 | 1.55364 |     0.4073 |                    2 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00008 | TERMINATED |                 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    | DEFAULT_76ecb_00009 | TERMINATED |                 |            2 |    8 |  256 | 0.0956493  | 2.37905 |     0.1015 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    [2m[36m(pid=1480)[0m [9,  4000] loss: 0.390
    [2m[36m(pid=1430)[0m [4,  2000] loss: 1.383
    Result for DEFAULT_76ecb_00007:
      accuracy: 0.6194
      date: 2021-04-20_16-55-04
      done: false
      experiment_id: 70ebc8fa0c694726b89a89472a3a9f46
      hostname: b5df8c714092
      iterations_since_restore: 9
      loss: 1.1662948173224925
      node_ip: 172.17.0.2
      pid: 1480
      should_checkpoint: true
      time_since_restore: 294.605046749115
      time_this_iter_s: 29.55521321296692
      time_total_s: 294.605046749115
      timestamp: 1618937704
      timesteps_since_restore: 0
      training_iteration: 9
      trial_id: 76ecb_00007
  
    == Status ==
    Memory usage on this node: 5.0/240.1 GiB
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.2736187709242106 | Iter 4.000: -1.3229044077396392 | Iter 2.000: -1.4594540922489019 | Iter 1.000: -1.6150014089822768
    Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00006 | RUNNING    | 172.17.0.2:1430 |            2 |    8 |  256 | 0.00111287 | 1.41142 |     0.4978 |                    3 |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.16629 |     0.6194 |                    9 |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00003 | TERMINATED |                 |           16 |   16 |   16 | 0.011363   | 1.40143 |     0.5322 |                   10 |
    | DEFAULT_76ecb_00004 | TERMINATED |                 |            8 |    4 |   64 | 0.00230503 | 1.55364 |     0.4073 |                    2 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00008 | TERMINATED |                 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    | DEFAULT_76ecb_00009 | TERMINATED |                 |            2 |    8 |  256 | 0.0956493  | 2.37905 |     0.1015 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    [2m[36m(pid=1430)[0m [4,  4000] loss: 0.687
    [2m[36m(pid=1430)[0m [4,  6000] loss: 0.455
    [2m[36m(pid=1480)[0m [10,  2000] loss: 0.668
    [2m[36m(pid=1430)[0m [4,  8000] loss: 0.342
    [2m[36m(pid=1480)[0m [10,  4000] loss: 0.362
    [2m[36m(pid=1430)[0m [4, 10000] loss: 0.276
    Result for DEFAULT_76ecb_00007:
      accuracy: 0.6275
      date: 2021-04-20_16-55-33
      done: true
      experiment_id: 70ebc8fa0c694726b89a89472a3a9f46
      hostname: b5df8c714092
      iterations_since_restore: 10
      loss: 1.1918752892374993
      node_ip: 172.17.0.2
      pid: 1480
      should_checkpoint: true
      time_since_restore: 323.9693615436554
      time_this_iter_s: 29.364314794540405
      time_total_s: 323.9693615436554
      timestamp: 1618937733
      timesteps_since_restore: 0
      training_iteration: 10
      trial_id: 76ecb_00007
  
    == Status ==
    Memory usage on this node: 5.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.2736187709242106 | Iter 4.000: -1.3229044077396392 | Iter 2.000: -1.4594540922489019 | Iter 1.000: -1.6150014089822768
    Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00006 | RUNNING    | 172.17.0.2:1430 |            2 |    8 |  256 | 0.00111287 | 1.41142 |     0.4978 |                    3 |
    | DEFAULT_76ecb_00007 | RUNNING    | 172.17.0.2:1480 |            8 |  256 |   64 | 0.00182312 | 1.19188 |     0.6275 |                   10 |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00003 | TERMINATED |                 |           16 |   16 |   16 | 0.011363   | 1.40143 |     0.5322 |                   10 |
    | DEFAULT_76ecb_00004 | TERMINATED |                 |            8 |    4 |   64 | 0.00230503 | 1.55364 |     0.4073 |                    2 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00008 | TERMINATED |                 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    | DEFAULT_76ecb_00009 | TERMINATED |                 |            2 |    8 |  256 | 0.0956493  | 2.37905 |     0.1015 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    [2m[36m(pid=1430)[0m [4, 12000] loss: 0.227
    [2m[36m(pid=1430)[0m [4, 14000] loss: 0.194
    [2m[36m(pid=1430)[0m [4, 16000] loss: 0.175
    [2m[36m(pid=1430)[0m [4, 18000] loss: 0.152
    [2m[36m(pid=1430)[0m [4, 20000] loss: 0.137
    Result for DEFAULT_76ecb_00006:
      accuracy: 0.5109
      date: 2021-04-20_16-56-15
      done: true
      experiment_id: 3850c4263510450da3c40498e1810110
      hostname: b5df8c714092
      iterations_since_restore: 4
      loss: 1.3959508232518216
      node_ip: 172.17.0.2
      pid: 1430
      should_checkpoint: true
      time_since_restore: 366.0234327316284
      time_this_iter_s: 83.12852263450623
      time_total_s: 366.0234327316284
      timestamp: 1618937775
      timesteps_since_restore: 0
      training_iteration: 4
      trial_id: 76ecb_00006
  
    == Status ==
    Memory usage on this node: 4.3/240.1 GiB
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.2736187709242106 | Iter 4.000: -1.3959508232518216 | Iter 2.000: -1.4594540922489019 | Iter 1.000: -1.6150014089822768
    Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00006 | RUNNING    | 172.17.0.2:1430 |            2 |    8 |  256 | 0.00111287 | 1.39595 |     0.5109 |                    4 |
    | DEFAULT_76ecb_00000 | TERMINATED |                 |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |                 |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |                 |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00003 | TERMINATED |                 |           16 |   16 |   16 | 0.011363   | 1.40143 |     0.5322 |                   10 |
    | DEFAULT_76ecb_00004 | TERMINATED |                 |            8 |    4 |   64 | 0.00230503 | 1.55364 |     0.4073 |                    2 |
    | DEFAULT_76ecb_00005 | TERMINATED |                 |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00007 | TERMINATED |                 |            8 |  256 |   64 | 0.00182312 | 1.19188 |     0.6275 |                   10 |
    | DEFAULT_76ecb_00008 | TERMINATED |                 |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    | DEFAULT_76ecb_00009 | TERMINATED |                 |            2 |    8 |  256 | 0.0956493  | 2.37905 |     0.1015 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+------------+---------+------------+----------------------+


    == Status ==
    Memory usage on this node: 4.2/240.1 GiB
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.2736187709242106 | Iter 4.000: -1.3959508232518216 | Iter 2.000: -1.4594540922489019 | Iter 1.000: -1.6150014089822768
    Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects (0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2021-04-20_16-50-08
    Number of trials: 10/10 (10 TERMINATED)
    +---------------------+------------+-------+--------------+------+------+------------+---------+------------+----------------------+
    | Trial name          | status     | loc   |   batch_size |   l1 |   l2 |         lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-------+--------------+------+------+------------+---------+------------+----------------------|
    | DEFAULT_76ecb_00000 | TERMINATED |       |            8 |    4 |  256 | 0.00203823 | 1.58808 |     0.3996 |                    1 |
    | DEFAULT_76ecb_00001 | TERMINATED |       |            8 |  128 |   64 | 0.0108614  | 1.64192 |     0.3956 |                    1 |
    | DEFAULT_76ecb_00002 | TERMINATED |       |           16 |  128 |   64 | 0.0371632  | 1.93801 |     0.2968 |                    1 |
    | DEFAULT_76ecb_00003 | TERMINATED |       |           16 |   16 |   16 | 0.011363   | 1.40143 |     0.5322 |                   10 |
    | DEFAULT_76ecb_00004 | TERMINATED |       |            8 |    4 |   64 | 0.00230503 | 1.55364 |     0.4073 |                    2 |
    | DEFAULT_76ecb_00005 | TERMINATED |       |            8 |   32 |  256 | 0.0315433  | 2.13462 |     0.2052 |                    1 |
    | DEFAULT_76ecb_00006 | TERMINATED |       |            2 |    8 |  256 | 0.00111287 | 1.39595 |     0.5109 |                    4 |
    | DEFAULT_76ecb_00007 | TERMINATED |       |            8 |  256 |   64 | 0.00182312 | 1.19188 |     0.6275 |                   10 |
    | DEFAULT_76ecb_00008 | TERMINATED |       |            4 |    8 |   16 | 0.0230996  | 2.31056 |     0.1027 |                    1 |
    | DEFAULT_76ecb_00009 | TERMINATED |       |            2 |    8 |  256 | 0.0956493  | 2.37905 |     0.1015 |                    1 |
    +---------------------+------------+-------+--------------+------+------+------------+---------+------------+----------------------+


    Best trial config: {'l1': 256, 'l2': 64, 'lr': 0.0018231210744505233, 'batch_size': 8}
    Best trial final validation loss: 1.1918752892374993
    Best trial final validation accuracy: 0.6275
    Files already downloaded and verified
    Files already downloaded and verified
    Best trial test set accuracy: 0.623


If you run the code, an example output could look like this:

.. code-block::

    Number of trials: 10 (10 TERMINATED)
    +-----+------+------+-------------+--------------+---------+------------+--------------------+
    | ... |   l1 |   l2 |          lr |   batch_size |    loss |   accuracy | training_iteration |
    |-----+------+------+-------------+--------------+---------+------------+--------------------|
    | ... |   64 |    4 | 0.00011629  |            2 | 1.87273 |     0.244  |                  2 |
    | ... |   32 |   64 | 0.000339763 |            8 | 1.23603 |     0.567  |                  8 |
    | ... |    8 |   16 | 0.00276249  |           16 | 1.1815  |     0.5836 |                 10 |
    | ... |    4 |   64 | 0.000648721 |            4 | 1.31131 |     0.5224 |                  8 |
    | ... |   32 |   16 | 0.000340753 |            8 | 1.26454 |     0.5444 |                  8 |
    | ... |    8 |    4 | 0.000699775 |            8 | 1.99594 |     0.1983 |                  2 |
    | ... |  256 |    8 | 0.0839654   |           16 | 2.3119  |     0.0993 |                  1 |
    | ... |   16 |  128 | 0.0758154   |           16 | 2.33575 |     0.1327 |                  1 |
    | ... |   16 |    8 | 0.0763312   |           16 | 2.31129 |     0.1042 |                  4 |
    | ... |  128 |   16 | 0.000124903 |            4 | 2.26917 |     0.1945 |                  1 |
    +-----+------+------+-------------+--------------+---------+------------+--------------------+


    Best trial config: {'l1': 8, 'l2': 16, 'lr': 0.00276249, 'batch_size': 16, 'data_dir': '...'}
    Best trial final validation loss: 1.181501
    Best trial final validation accuracy: 0.5836
    Best trial test set accuracy: 0.5806

Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 58%, which could
be confirmed on the test set.

So that's it! You can now tune the parameters of your PyTorch models.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 6 minutes  31.507 seconds)


.. _sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: hyperparameter_tuning_tutorial.py <hyperparameter_tuning_tutorial.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: hyperparameter_tuning_tutorial.ipynb <hyperparameter_tuning_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
